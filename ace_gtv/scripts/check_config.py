#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é…ç½®æ£€æŸ¥å·¥å…·
æ£€æŸ¥.env.localæ–‡ä»¶ä¸­çš„é…ç½®æ˜¯å¦æ­£ç¡®
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

def check_config():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    print("ğŸ” é…ç½®æ£€æŸ¥å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶è·¯å¾„
    current_dir = Path(__file__).parent
    project_root = current_dir.parent
    env_local_path = project_root / ".env.local"
    
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶è·¯å¾„: {env_local_path}")
    
    if not env_local_path.exists():
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        print("ğŸ’¡ æç¤º: è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env.local æ–‡ä»¶")
        return False
    
    print("âœ… é…ç½®æ–‡ä»¶å­˜åœ¨")
    
    # åŠ è½½é…ç½®
    load_dotenv(env_local_path)
    print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
    
    # å…¼å®¹æ€§å¤„ç†ï¼šæ”¯æŒAI_PROVIDERå’ŒLLM_PROVIDERä¸¤ç§é…ç½®æ–¹å¼
    ai_provider = os.getenv("AI_PROVIDER", "").lower()
    llm_provider = os.getenv("LLM_PROVIDER", "").upper()
    
    if ai_provider and not llm_provider:
        # å°†AI_PROVIDERæ˜ å°„åˆ°LLM_PROVIDER
        if ai_provider == "openai":
            os.environ["LLM_PROVIDER"] = "OPENAI"
        elif ai_provider == "azure":
            os.environ["LLM_PROVIDER"] = "AZURE"
        elif ai_provider == "anthropic":
            os.environ["LLM_PROVIDER"] = "ANTHROPIC"
        print(f"ğŸ”„ è‡ªåŠ¨æ˜ å°„AI_PROVIDER={ai_provider} -> LLM_PROVIDER={os.environ['LLM_PROVIDER']}")
    
    # å…¼å®¹æ€§å¤„ç†ï¼šæ”¯æŒAZURE_API_KEYå’ŒAZURE_OPENAI_API_KEY
    azure_api_key = os.getenv("AZURE_API_KEY")
    azure_openai_api_key = os.getenv("AZURE_OPENAI_API_KEY")
    if azure_api_key and not azure_openai_api_key:
        os.environ["AZURE_OPENAI_API_KEY"] = azure_api_key
        print("ğŸ”„ è‡ªåŠ¨æ˜ å°„AZURE_API_KEY -> AZURE_OPENAI_API_KEY")
    
    # å…¼å®¹æ€§å¤„ç†ï¼šæ”¯æŒAZURE_OPENAI_DEPLOYMENT_NAMEå’ŒAZURE_OPENAI_DEPLOYMENT
    azure_deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
    azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
    if azure_deployment_name and not azure_deployment:
        os.environ["AZURE_OPENAI_DEPLOYMENT"] = azure_deployment_name
        print(f"ğŸ”„ è‡ªåŠ¨æ˜ å°„AZURE_OPENAI_DEPLOYMENT_NAME -> AZURE_OPENAI_DEPLOYMENT")
    
    # æ£€æŸ¥LLMæä¾›å•†é…ç½®
    provider = os.getenv("LLM_PROVIDER", "").upper()
    print(f"\nğŸ¤– LLMæä¾›å•†: {provider or 'æœªé…ç½®'}")
    
    if not provider:
        print("âŒ æœªé…ç½®LLMæä¾›å•†")
        print("ğŸ’¡ æç¤º: è¯·åœ¨.env.localä¸­è®¾ç½®LLM_PROVIDERæˆ–AI_PROVIDER")
        return False
    
    # æ ¹æ®æä¾›å•†æ£€æŸ¥ç›¸åº”é…ç½®
    if provider == "OPENAI":
        return check_openai_config()
    elif provider == "AZURE":
        return check_azure_config()
    elif provider == "ANTHROPIC":
        return check_anthropic_config()
    else:
        print(f"âŒ ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
        print("ğŸ’¡ æ”¯æŒçš„æä¾›å•†: OPENAI, AZURE, ANTHROPIC")
        return False

def check_openai_config():
    """æ£€æŸ¥OpenAIé…ç½®"""
    print("\nğŸ” æ£€æŸ¥OpenAIé…ç½®...")
    
    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    
    print(f"ğŸ”‘ API Key: {'å·²é…ç½®' if api_key else 'æœªé…ç½®'}")
    print(f"ğŸŒ API Base: {api_base}")
    print(f"ğŸ¤– Model: {model}")
    
    if not api_key:
        print("âŒ æœªé…ç½®OPENAI_API_KEY")
        print("ğŸ’¡ æç¤º: è¯·åœ¨.env.localä¸­è®¾ç½®OPENAI_API_KEY")
        return False
    
    if not api_key.startswith("sk-"):
        print("âš ï¸  API Keyæ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼ˆåº”è¯¥ä»¥'sk-'å¼€å¤´ï¼‰")
    
    print("âœ… OpenAIé…ç½®æ£€æŸ¥é€šè¿‡")
    return True

def check_azure_config():
    """æ£€æŸ¥Azure OpenAIé…ç½®"""
    print("\nğŸ” æ£€æŸ¥Azure OpenAIé…ç½®...")
    
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
    deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
    
    print(f"ğŸŒ Endpoint: {endpoint or 'æœªé…ç½®'}")
    print(f"ğŸ”‘ API Key: {'å·²é…ç½®' if api_key else 'æœªé…ç½®'}")
    print(f"ğŸ“… API Version: {api_version}")
    print(f"ğŸš€ Deployment: {deployment or 'æœªé…ç½®'}")
    
    missing_configs = []
    if not endpoint:
        missing_configs.append("AZURE_OPENAI_ENDPOINT")
    if not api_key:
        missing_configs.append("AZURE_OPENAI_API_KEY")
    if not deployment:
        missing_configs.append("AZURE_OPENAI_DEPLOYMENT")
    
    if missing_configs:
        print(f"âŒ ç¼ºå°‘é…ç½®: {', '.join(missing_configs)}")
        print("ğŸ’¡ æç¤º: è¯·åœ¨.env.localä¸­è®¾ç½®æ‰€æœ‰å¿…éœ€çš„Azureé…ç½®")
        return False
    
    print("âœ… Azure OpenAIé…ç½®æ£€æŸ¥é€šè¿‡")
    return True

def check_anthropic_config():
    """æ£€æŸ¥Anthropicé…ç½®"""
    print("\nğŸ” æ£€æŸ¥Anthropicé…ç½®...")
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    
    print(f"ğŸ”‘ API Key: {'å·²é…ç½®' if api_key else 'æœªé…ç½®'}")
    
    if not api_key:
        print("âŒ æœªé…ç½®ANTHROPIC_API_KEY")
        print("ğŸ’¡ æç¤º: è¯·åœ¨.env.localä¸­è®¾ç½®ANTHROPIC_API_KEY")
        return False
    
    if not api_key.startswith("sk-ant-"):
        print("âš ï¸  API Keyæ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼ˆåº”è¯¥ä»¥'sk-ant-'å¼€å¤´ï¼‰")
    
    print("âœ… Anthropicé…ç½®æ£€æŸ¥é€šè¿‡")
    return True

def check_optional_configs():
    """æ£€æŸ¥å¯é€‰é…ç½®"""
    print("\nğŸ” æ£€æŸ¥å¯é€‰é…ç½®...")
    
    parse_timeout = os.getenv("PARSE_TIMEOUT_SEC", "15")
    llm_timeout = os.getenv("LLM_TIMEOUT_SEC", "45")
    total_timeout = os.getenv("TOTAL_TIMEOUT_SEC", "60")
    log_level = os.getenv("LOG_LEVEL", "INFO")
    
    print(f"â±ï¸  è§£æè¶…æ—¶: {parse_timeout}ç§’")
    print(f"â±ï¸  LLMè¶…æ—¶: {llm_timeout}ç§’")
    print(f"â±ï¸  æ€»è¶…æ—¶: {total_timeout}ç§’")
    print(f"ğŸ“ æ—¥å¿—çº§åˆ«: {log_level}")
    
    print("âœ… å¯é€‰é…ç½®æ£€æŸ¥å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥åŸºæœ¬é…ç½®
        config_ok = check_config()
        
        # æ£€æŸ¥å¯é€‰é…ç½®
        check_optional_configs()
        
        print("\n" + "=" * 50)
        if config_ok:
            print("ğŸ‰ é…ç½®æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥è¿è¡Œæµ‹è¯•äº†ã€‚")
            print("ğŸ’¡ è¿è¡Œå‘½ä»¤: python test_resume_processor.py")
        else:
            print("âŒ é…ç½®æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤é…ç½®åé‡è¯•ã€‚")
            print("ğŸ’¡ å‚è€ƒTEST_README.mdäº†è§£é…ç½®è¯¦æƒ…")
        
        return 0 if config_ok else 1
        
    except Exception as e:
        print(f"âŒ é…ç½®æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
