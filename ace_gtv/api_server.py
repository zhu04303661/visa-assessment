#!/usr/bin/env python3
"""
GTVè¯„ä¼°ç»Ÿä¸€APIæœåŠ¡
èšåˆæ‰€æœ‰åç«¯æœåŠ¡ï¼ˆè¯„ä¼°ã€è¯„åˆ†ã€æ–‡æ¡£åˆ†æï¼‰åˆ°å•ä¸€Flaskåº”ç”¨
è¿è¡Œåœ¨å•ä¸€ç«¯å£ä¸Šï¼ˆé»˜è®¤5005ï¼‰
"""

import os
import json
import logging
import tempfile
from typing import Optional
from pathlib import Path
from datetime import datetime

from flask import Flask, request, jsonify, Response
from flask_cors import CORS
import dotenv

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from logger_config import setup_module_logger

# åˆå§‹åŒ–æ—¥å¿—
logger = setup_module_logger("api_server", os.getenv("LOG_LEVEL", "INFO"))

# å¯¼å…¥Agentå’Œåˆ†æå™¨
try:
    from scoring_agent_lite import ScoringAgent
except ImportError:
    logging.error("æ— æ³•å¯¼å…¥ScoringAgent")
    ScoringAgent = None

try:
    from document_analyzer import KnowledgeExtractor, DocumentExtractor
except ImportError:
    logging.error("æ— æ³•å¯¼å…¥DocumentAnalyzer")
    KnowledgeExtractor = None
    DocumentExtractor = None

# å¯¼å…¥ç®€å†å¤„ç†çš„å¿…è¦å‡½æ•°
try:
    from resume_processor import (
        extract_text_from_file,
        call_ai_for_extraction,
        call_ai_for_gtv_assessment,
        create_personal_knowledge_base,
        update_main_knowledge_base,
        allowed_file,
        generate_gtv_pdf_report,
        safe_preview
    )
    logging.info("âœ… ç®€å†å¤„ç†æ¨¡å—å¯¼å…¥æˆåŠŸ")
    RESUME_PROCESSING_AVAILABLE = True
except ImportError as e:
    logging.warning(f"âš ï¸ ç®€å†å¤„ç†æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    RESUME_PROCESSING_AVAILABLE = False
    # å®šä¹‰å ä½å‡½æ•°
    def allowed_file(f): return True
    def safe_preview(s): return str(s)[:200]
    extract_text_from_file = None
    call_ai_for_extraction = None
    call_ai_for_gtv_assessment = None
    create_personal_knowledge_base = None
    update_main_knowledge_base = None
    generate_gtv_pdf_report = None

# å¯¼å…¥LangGraphè¯„åˆ†Agent
try:
    from langgraph_scoring_agent import LangGraphScoringAgent, KnowledgeBaseManager
    logging.info("âœ… LangGraphè¯„åˆ†Agentå¯¼å…¥æˆåŠŸ")
    LANGGRAPH_SCORING_AVAILABLE = True
except ImportError as e:
    logging.warning(f"âš ï¸ LangGraphè¯„åˆ†Agentå¯¼å…¥å¤±è´¥: {e}")
    LANGGRAPH_SCORING_AVAILABLE = False

# å¯¼å…¥LangGraph OCè¯„ä¼°Agent
LANGGRAPH_OC_AVAILABLE = False  # é»˜è®¤å€¼ï¼Œå¦‚æœå¯¼å…¥æˆåŠŸä¼šè¢«è®¾ç½®ä¸ºTrue
try:
    from langgraph_oc_agent import LangGraphOCAgent
    logging.info("âœ… LangGraph OCè¯„ä¼°Agentå¯¼å…¥æˆåŠŸ")
    LANGGRAPH_OC_AVAILABLE = True
except ImportError as e:
    logging.warning(f"âš ï¸ LangGraph OCè¯„ä¼°Agentå¯¼å…¥å¤±è´¥: {e}")
    LANGGRAPH_OC_AVAILABLE = False
except Exception as e:
    logging.error(f"âŒ LangGraph OCè¯„ä¼°Agentå¯¼å…¥å¼‚å¸¸: {e}", exc_info=True)
    LANGGRAPH_OC_AVAILABLE = False

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
CORS(app)

# é…ç½®ä¸Šä¼ æ–‡ä»¶å¤¹
UPLOAD_FOLDER = os.path.join(os.path.dirname(__file__), 'uploads')
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024  # 10MB

# å…¨å±€Agentå®ä¾‹
scoring_agent: Optional[ScoringAgent] = None
knowledge_extractor: Optional[KnowledgeExtractor] = None
langgraph_scoring_agent: Optional[LangGraphScoringAgent] = None
langgraph_oc_agent: Optional[LangGraphOCAgent] = None
kb_manager: Optional[KnowledgeBaseManager] = None
LANGGRAPH_SCORING_AVAILABLE = False # Initialize LANGGRAPH_SCORING_AVAILABLE
# LANGGRAPH_OC_AVAILABLE å·²åœ¨å¯¼å…¥æ—¶è®¾ç½®ï¼ˆç¬¬70-80è¡Œï¼‰

# ============================================================================
# åˆå§‹åŒ–å’Œé…ç½®
# ============================================================================

@app.before_request
def initialize_services():
    """åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡ - ä»…åœ¨é¦–æ¬¡è¯·æ±‚æ—¶"""
    # å¥åº·æ£€æŸ¥ä¸éœ€è¦åˆå§‹åŒ–
    if request.path == '/health':
        return
    
    global scoring_agent, knowledge_extractor, langgraph_scoring_agent, langgraph_oc_agent, kb_manager, LANGGRAPH_SCORING_AVAILABLE, LANGGRAPH_OC_AVAILABLE
    
    # åˆå§‹åŒ–è¯„åˆ†Agent
    if scoring_agent is None and ScoringAgent is not None:
        try:
            try:
                from langchain_openai import ChatOpenAI
                
                openai_api_key = os.getenv("OPENAI_API_KEY")
                if openai_api_key:
                    llm = ChatOpenAI(
                        api_key=openai_api_key,
                        model="gpt-4-turbo-preview",
                        temperature=0.7,
                    )
                    scoring_agent = ScoringAgent(llm)
                    logger.info("âœ… ScoringAgent åˆå§‹åŒ–æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ OPENAI_API_KEY æœªè®¾ç½®ï¼Œè¯„åˆ†Agentä½¿ç”¨Mockæ¨¡å¼")
            except ImportError as e:
                logger.warning(f"âš ï¸ LangChainå¯¼å…¥å¤±è´¥: {e}ï¼Œè¯„åˆ†Agentä½¿ç”¨Mockæ¨¡å¼")
            
        except Exception as e:
            logger.error(f"âŒ è¯„åˆ†Agentåˆå§‹åŒ–é”™è¯¯: {e}")
    
    # åˆå§‹åŒ–çŸ¥è¯†æå–å™¨
    if knowledge_extractor is None and KnowledgeExtractor is not None:
        try:
            knowledge_extractor = KnowledgeExtractor()
            logger.info("âœ… KnowledgeExtractor åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ KnowledgeExtractoråˆå§‹åŒ–é”™è¯¯: {e}")

    if langgraph_scoring_agent is None and LANGGRAPH_SCORING_AVAILABLE:
        try:
            # åˆå§‹åŒ–çŸ¥è¯†åº“ç®¡ç†å™¨
            if kb_manager is None:
                kb_manager = KnowledgeBaseManager(kb_dir="./public")
            
            # åˆå§‹åŒ–LangGraphè¯„åˆ†Agent
            langgraph_scoring_agent = LangGraphScoringAgent(
                llm=llm if 'llm' in locals() else None,
                kb_manager=kb_manager
            )
            logger.info("âœ… LangGraphè¯„åˆ†Agentåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ LangGraphè¯„åˆ†Agentåˆå§‹åŒ–å¤±è´¥: {e}")
            LANGGRAPH_SCORING_AVAILABLE = False

    if langgraph_oc_agent is None and LANGGRAPH_OC_AVAILABLE:
        try:
            logger.info("ğŸ”§ å¼€å§‹åˆå§‹åŒ–LangGraph OCè¯„ä¼°Agent...")
            # åˆå§‹åŒ–çŸ¥è¯†åº“ç®¡ç†å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
            if kb_manager is None:
                kb_manager = KnowledgeBaseManager(kb_dir="./public")
                logger.info(f"âœ… çŸ¥è¯†åº“ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼Œè§„åˆ™æ•°: {len(kb_manager.rules)}")
            
            # åˆå§‹åŒ–LLMï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
            oc_llm = None
            try:
                from langchain_openai import ChatOpenAI
                openai_api_key = os.getenv("OPENAI_API_KEY")
                if openai_api_key:
                    oc_llm = ChatOpenAI(
                        api_key=openai_api_key,
                        model="gpt-4-turbo-preview",
                        temperature=0.3,
                    )
                    logger.info("âœ… LLMåˆå§‹åŒ–æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ OPENAI_API_KEYæœªè®¾ç½®ï¼ŒOCè¯„ä¼°Agentä½¿ç”¨Mockæ¨¡å¼ï¼ˆæ— LLMï¼‰")
            except ImportError as e:
                logger.warning(f"âš ï¸ LangChainå¯¼å…¥å¤±è´¥: {e}ï¼ŒOCè¯„ä¼°Agentä½¿ç”¨Mockæ¨¡å¼ï¼ˆæ— LLMï¼‰")
                oc_llm = None
            
            # åˆå§‹åŒ–LangGraph OCè¯„ä¼°Agent
            logger.info("ğŸ”§ åˆ›å»ºLangGraphOCAgentå®ä¾‹...")
            langgraph_oc_agent = LangGraphOCAgent(
                llm=oc_llm,
                kb_manager=kb_manager
            )
            logger.info("âœ… LangGraph OCè¯„ä¼°Agentåˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"âœ… OCè¯„ä¼°AgentçŠ¶æ€: llm={oc_llm is not None}, kb_manager={kb_manager is not None}")
        except Exception as e:
            logger.error(f"âŒ LangGraph OCè¯„ä¼°Agentåˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            LANGGRAPH_OC_AVAILABLE = False
            langgraph_oc_agent = None


# ============================================================================
# å¥åº·æ£€æŸ¥
# ============================================================================

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥ - è¿”å›æ‰€æœ‰æœåŠ¡çš„çŠ¶æ€"""
    return jsonify({
        'status': 'healthy',
        'message': 'GTVç»Ÿä¸€APIæœåŠ¡è¿è¡Œä¸­',
        'services': {
            'scoring_agent': 'enabled' if scoring_agent else 'disabled',
            'document_analyzer': 'enabled' if knowledge_extractor else 'disabled',
        }
    }), 200


# ============================================================================
# è¯„åˆ†åˆ†æAPIç«¯ç‚¹
# ============================================================================

@app.route('/api/scoring/analyze-item', methods=['POST'])
def analyze_item():
    """åˆ†æå•ä¸ªè¯„åˆ†é¡¹"""
    try:
        if scoring_agent is None:
            return jsonify({'error': 'è¯„åˆ†æœåŠ¡ä¸å¯ç”¨'}), 503
        
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'è¯·æ±‚ä½“ä¸ºç©º'}), 400
        
        required_fields = ['item_name', 'item_value', 'score', 'max_score', 'percentage', 'applicant_background']
        missing_fields = [f for f in required_fields if f not in data]
        if missing_fields:
            return jsonify({
                'error': f'ç¼ºå°‘å¿…éœ€å­—æ®µ: {", ".join(missing_fields)}'
            }), 400
        
        logger.info(f"ğŸ“Š å¼€å§‹åˆ†æé¡¹ç›®: {data['item_name']}")
        
        result = scoring_agent.analyze_item(
            item_name=data['item_name'],
            item_value=data['item_value'],
            score=data['score'],
            max_score=data['max_score'],
            percentage=data['percentage'],
            applicant_background=data['applicant_background'],
        )
        
        logger.info(f"âœ… åˆ†æå®Œæˆ: {data['item_name']}")
        
        return jsonify(result), 200
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {e}", exc_info=True)
        return jsonify({'error': str(e)}), 500


@app.route('/api/scoring/analyze-stream', methods=['POST'])
def analyze_stream():
    """æµå¼åˆ†æå•ä¸ªè¯„åˆ†é¡¹"""
    try:
        if scoring_agent is None:
            return jsonify({'error': 'è¯„åˆ†æœåŠ¡ä¸å¯ç”¨'}), 503
        
        data = request.get_json()
        
        required_fields = ['item_name', 'item_value', 'score', 'max_score', 'percentage', 'applicant_background']
        missing_fields = [f for f in required_fields if f not in data]
        if missing_fields:
            return jsonify({
                'error': f'ç¼ºå°‘å¿…éœ€å­—æ®µ: {", ".join(missing_fields)}'
            }), 400
        
        def generate():
            """ç”Ÿæˆæµå¼å“åº”"""
            yield f"data: {json.dumps({'status': 'starting', 'message': 'å¼€å§‹åˆ†æ...'})}\n\n"
            
            try:
                item_name = data.get("item_name", "æœªçŸ¥é¡¹ç›®")
                status_data_1 = {'status': 'analyzing_official', 'message': f'åˆ†æå®˜æ–¹è¦æ±‚: {item_name}'}
                yield f"data: {json.dumps(status_data_1)}\n\n"
                
                status_data_2 = {'status': 'analyzing_deviation', 'message': 'åˆ†æåå·®ç¨‹åº¦'}
                yield f"data: {json.dumps(status_data_2)}\n\n"
                
                result = scoring_agent.analyze_item(
                    item_name=data['item_name'],
                    item_value=data['item_value'],
                    score=data['score'],
                    max_score=data['max_score'],
                    percentage=data['percentage'],
                    applicant_background=data['applicant_background'],
                )
                
                yield f"data: {json.dumps({'status': 'complete', 'result': result})}\n\n"
                
            except Exception as e:
                logger.error(f"âŒ æµå¼åˆ†æå¤±è´¥: {e}")
                yield f"data: {json.dumps({'status': 'error', 'message': str(e)})}\n\n"
        
        return Response(generate(), mimetype='text/event-stream')
        
    except Exception as e:
        logger.error(f"âŒ æµå¼åˆ†æç«¯ç‚¹é”™è¯¯: {e}")
        return jsonify({'error': str(e)}), 500


# ============================================================================
# LangGraphè¯„åˆ†Agentç«¯ç‚¹
# ============================================================================

@app.route('/api/scoring/langgraph-analyze', methods=['POST'])
def langgraph_analyze():
    """ä½¿ç”¨LangGraph Agentè¿›è¡Œå¤šè½®äº¤äº’è¯„åˆ†åˆ†æ"""
    
    if not LANGGRAPH_SCORING_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'LangGraphè¯„åˆ†æœåŠ¡ä¸å¯ç”¨'
        }), 503
    
    request_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    logger.info(f"[{request_id}] å¼€å§‹LangGraphå¤šè½®åˆ†æè¯·æ±‚")
    
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'è¯·æ±‚ä½“ä¸ºç©º'}), 400
        
        # æå–ç”³è¯·äººæ•°æ®
        applicant_data = data.get('applicant_data', {})
        
        logger.info(f"[{request_id}] ç”³è¯·äººæ•°æ®: {applicant_data.get('name', 'N/A')}")
        
        # æ‰§è¡Œå¤šè½®åˆ†æ
        start_time = datetime.now()
        result = langgraph_scoring_agent.analyze(applicant_data)
        execution_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"[{request_id}] åˆ†æå®Œæˆï¼Œæœ€ç»ˆè¯„åˆ†: {result['score']:.1f}")
        logger.info(f"[{request_id}] LLMè°ƒç”¨æ¬¡æ•°: {result['llm_interactions']}")
        logger.info(f"[{request_id}] æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        
        return jsonify({
            'success': True,
            'data': result,
            'message': f"å¤šè½®åˆ†æå®Œæˆï¼Œè¯„åˆ†: {result['score']:.1f}/100"
        }), 200
        
    except Exception as e:
        logger.error(f"[{request_id}] LangGraphåˆ†æå¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/knowledge-base/rules', methods=['GET'])
def get_knowledge_base_rules():
    """è·å–çŸ¥è¯†åº“è§„åˆ™ç»Ÿè®¡ä¿¡æ¯"""
    
    if not kb_manager:
        return jsonify({
            'success': False,
            'error': 'çŸ¥è¯†åº“ç®¡ç†å™¨ä¸å¯ç”¨'
        }), 503
    
    try:
        # ç»Ÿè®¡è§„åˆ™ä¿¡æ¯
        total_rules = len(kb_manager.rules)
        
        # æŒ‰ç»´åº¦ç»Ÿè®¡
        dimension_stats = {}
        for dimension, rule_ids in kb_manager.rule_index.items():
            if dimension not in dimension_stats and len(rule_ids) > 0:
                if any(rid in kb_manager.rules for rid in rule_ids):
                    dimension_stats[dimension] = len(rule_ids)
        
        return jsonify({
            'success': True,
            'data': {
                'total_rules': total_rules,
                'dimension_stats': dimension_stats,
                'last_updated': datetime.now().isoformat()
            }
        }), 200
        
    except Exception as e:
        logger.error(f"è·å–çŸ¥è¯†åº“è§„åˆ™å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/knowledge-base/search', methods=['POST'])
def search_knowledge_base():
    """æœç´¢çŸ¥è¯†åº“è§„åˆ™"""
    
    if not kb_manager:
        return jsonify({
            'success': False,
            'error': 'çŸ¥è¯†åº“ç®¡ç†å™¨ä¸å¯ç”¨'
        }), 503
    
    try:
        data = request.get_json()
        
        # æå–æœç´¢å‚æ•°
        dimension = data.get('dimension')
        category = data.get('category')
        keywords = data.get('keywords', [])
        
        # æœç´¢è§„åˆ™
        rules = kb_manager.search_rules(dimension, category, keywords)
        
        return jsonify({
            'success': True,
            'data': {
                'rules_found': len(rules),
                'rules': [
                    {
                        'title': r.get('title'),
                        'dimension': r.get('dimension'),
                        'category': r.get('category'),
                        'content': r.get('content', '')[:300] + '...'
                    } for r in rules
                ]
            }
        }), 200
        
    except Exception as e:
        logger.error(f"çŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ============================================================================
# OCè¯„ä¼°APIç«¯ç‚¹
# ============================================================================

@app.route('/api/assessment/oc-evaluation', methods=['POST'])
def oc_evaluation():
    """ä½¿ç”¨LangGraphå’ŒLLMè¿›è¡ŒOCè¯„ä¼°"""
    
    logger.info(f"ğŸ” OCè¯„ä¼°ç«¯ç‚¹æ£€æŸ¥: LANGGRAPH_OC_AVAILABLE={LANGGRAPH_OC_AVAILABLE}, langgraph_oc_agent={langgraph_oc_agent is not None}")
    
    if not LANGGRAPH_OC_AVAILABLE:
        logger.warning("âš ï¸ LANGGRAPH_OC_AVAILABLEä¸ºFalse")
        return jsonify({
            'success': False,
            'error': 'OCè¯„ä¼°æœåŠ¡ä¸å¯ç”¨ï¼ˆLANGGRAPH_OC_AVAILABLE=Falseï¼‰'
        }), 503
    
    if not langgraph_oc_agent:
        logger.warning("âš ï¸ langgraph_oc_agentä¸ºNone")
        return jsonify({
            'success': False,
            'error': 'OCè¯„ä¼°æœåŠ¡ä¸å¯ç”¨ï¼ˆlanggraph_oc_agentæœªåˆå§‹åŒ–ï¼‰'
        }), 503
    
    request_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    logger.info(f"[{request_id}] å¼€å§‹OCè¯„ä¼°è¯·æ±‚")
    
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'è¯·æ±‚ä½“ä¸ºç©º'}), 400
        
        applicant_data = data.get('applicantData', {})
        assessment_data = data.get('assessmentData', {})
        
        logger.info(f"[{request_id}] ç”³è¯·äºº: {applicant_data.get('name', 'N/A')}")
        
        # æ‰§è¡ŒOCè¯„ä¼°
        start_time = datetime.now()
        result = langgraph_oc_agent.assess(applicant_data, assessment_data)
        execution_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"[{request_id}] OCè¯„ä¼°å®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
        logger.info(f"[{request_id}] OCç»“æœæ•°: {len(result.get('oc_results', []))}")
        
        return jsonify(result), 200
        
    except Exception as e:
        logger.error(f"[{request_id}] OCè¯„ä¼°å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ============================================================================
# æ–‡æ¡£åˆ†æAPIç«¯ç‚¹
# ============================================================================

@app.route('/api/documents/analyze', methods=['POST'])
def analyze_document():
    """åˆ†æä¸Šä¼ çš„æ–‡æ¡£ï¼ˆExcel/Word/TXTï¼‰"""
    try:
        if knowledge_extractor is None:
            return jsonify({'error': 'æ–‡æ¡£åˆ†ææœåŠ¡ä¸å¯ç”¨'}), 503
        
        if 'file' not in request.files:
            return jsonify({'error': 'æœªæä¾›æ–‡ä»¶'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'error': 'æ–‡ä»¶åä¸ºç©º'}), 400
        
        # å…è®¸çš„æ–‡ä»¶ç±»å‹
        ALLOWED_EXTENSIONS = {'xlsx', 'xls', 'docx', 'doc', 'txt'}
        file_ext = file.filename.rsplit('.', 1)[1].lower() if '.' in file.filename else ''
        
        if file_ext not in ALLOWED_EXTENSIONS:
            return jsonify({
                'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒ: {",".join(ALLOWED_EXTENSIONS)}'
            }), 400
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_dir = tempfile.gettempdir()
        temp_path = os.path.join(temp_dir, f"analysis_{file.filename}")
        file.save(temp_path)
        
        logger.info(f"ğŸ“„ åˆ†ææ–‡æ¡£: {file.filename}")
        
        try:
            result = knowledge_extractor.analyze_and_extract(temp_path)
            return jsonify(result), 200
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_path)
            except:
                pass
        
    except Exception as e:
        logger.error(f"âŒ æ–‡æ¡£åˆ†æå¤±è´¥: {e}", exc_info=True)
        return jsonify({'error': str(e)}), 500


@app.route('/api/documents/extract', methods=['POST'])
def extract_document_text():
    """ä»…æå–æ–‡æ¡£æ–‡æœ¬å†…å®¹"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æœªæä¾›æ–‡ä»¶'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'error': 'æ–‡ä»¶åä¸ºç©º'}), 400
        
        ALLOWED_EXTENSIONS = {'xlsx', 'xls', 'docx', 'doc', 'txt'}
        file_ext = file.filename.rsplit('.', 1)[1].lower() if '.' in file.filename else ''
        
        if file_ext not in ALLOWED_EXTENSIONS:
            return jsonify({
                'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒ: {",".join(ALLOWED_EXTENSIONS)}'
            }), 400
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_dir = tempfile.gettempdir()
        temp_path = os.path.join(temp_dir, f"extract_{file.filename}")
        file.save(temp_path)
        
        try:
            content = DocumentExtractor.extract_from_file(temp_path)
            return jsonify({
                'success': True,
                'filename': file.filename,
                'content': content,
                'content_length': len(content)
            }), 200
        finally:
            try:
                os.remove(temp_path)
            except:
                pass
        
    except Exception as e:
        logger.error(f"âŒ æ–‡æœ¬æå–å¤±è´¥: {e}", exc_info=True)
        return jsonify({'error': str(e)}), 500


@app.route('/api/documents/formats', methods=['GET'])
def supported_formats():
    """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
    return jsonify({
        'formats': ['xlsx', 'xls', 'docx', 'doc', 'txt'],
        'max_size_mb': 10,
        'description': {
            'xlsx': 'Excel å·¥ä½œç°¿ (2007+)',
            'xls': 'Excel å·¥ä½œç°¿ (97-2003)',
            'docx': 'Word æ–‡æ¡£ (2007+)',
            'doc': 'Word æ–‡æ¡£ (97-2003)',
            'txt': 'çº¯æ–‡æœ¬æ–‡ä»¶'
        }
    }), 200


# ============================================================================
# ç®€å†å¤„ç†APIç«¯ç‚¹
# ============================================================================

@app.route('/api/resume/upload', methods=['POST'])
def upload_resume():
    """å¤„ç†ç®€å†ä¸Šä¼ """
    if not RESUME_PROCESSING_AVAILABLE:
        return jsonify({'success': False, 'error': 'ç®€å†å¤„ç†æœåŠ¡ä¸å¯ç”¨'}), 503
    
    request_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    logger.info(f"[{request_id}] å¼€å§‹å¤„ç†ç®€å†ä¸Šä¼ è¯·æ±‚")
    
    try:
        # è·å–è¡¨å•æ•°æ®
        form_name = request.form.get('name', '').strip()
        form_email = request.form.get('email', '').strip()
        form_field = request.form.get('field', 'digital-technology').strip()
        form_additional_info = request.form.get('additionalInfo', '').strip()
        
        logger.info(f"[{request_id}] è¡¨å•æ•°æ® - å§“å: {form_name}, é‚®ç®±: {form_email}, é¢†åŸŸ: {form_field}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if 'resume' not in request.files:
            logger.error(f"[{request_id}] é”™è¯¯: æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
            return jsonify({"success": False, "error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"}), 400
            
        file = request.files['resume']
        if file.filename == '':
            logger.error(f"[{request_id}] é”™è¯¯: æ²¡æœ‰é€‰æ‹©æ–‡ä»¶")
            return jsonify({"success": False, "error": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400
            
        logger.info(f"[{request_id}] ä¸Šä¼ æ–‡ä»¶å: {file.filename}")
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not allowed_file(file.filename):
            logger.error(f"[{request_id}] é”™è¯¯: ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ {file.filename}")
            return jsonify({"success": False, "error": "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"}), 400
            
        logger.info(f"[{request_id}] æ–‡ä»¶ç±»å‹æ£€æŸ¥é€šè¿‡")
        
        # ä¿å­˜æ–‡ä»¶
        from werkzeug.utils import secure_filename
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{filename}"
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        logger.info(f"[{request_id}] ä¿å­˜æ–‡ä»¶åˆ°: {file_path}")
        file.save(file_path)
        logger.info(f"[{request_id}] æ–‡ä»¶ä¿å­˜æˆåŠŸ")
        
        # æå–æ–‡æœ¬å†…å®¹
        logger.info(f"[{request_id}] å¼€å§‹æå–æ–‡ä»¶æ–‡æœ¬å†…å®¹")
        content = extract_text_from_file(file_path)
        if not content:
            logger.error(f"[{request_id}] é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹")
            return jsonify({"success": False, "error": "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹"}), 400
            
        logger.info(f"[{request_id}] æ–‡æœ¬æå–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
        # ä½¿ç”¨AIæå–ä¿¡æ¯
        logger.info(f"[{request_id}] å¼€å§‹AIä¿¡æ¯æå–")
        extracted_info = call_ai_for_extraction(content)
        if not extracted_info:
            logger.error(f"[{request_id}] é”™è¯¯: AIä¿¡æ¯æå–å¤±è´¥")
            return jsonify({"success": False, "error": "ä¿¡æ¯æå–å¤±è´¥"}), 500
            
        logger.info(f"[{request_id}] AIä¿¡æ¯æå–æˆåŠŸ")
        
        # ä¼˜å…ˆä½¿ç”¨è¡¨å•ä¸­çš„å§“å
        ai_name = extracted_info.get("name", "").strip()
        final_name = form_name if form_name else ai_name
        if not final_name:
            final_name = "æœªçŸ¥ç”¨æˆ·"
            
        logger.info(f"[{request_id}] æœ€ç»ˆä½¿ç”¨çš„å§“å: {final_name}")
        
        # å¦‚æœè¡¨å•æä¾›äº†é‚®ç®±ï¼Œæ›´æ–°åˆ°æå–ä¿¡æ¯ä¸­
        if form_email:
            extracted_info["email"] = form_email
            
        # åˆ›å»ºä¸ªäººçŸ¥è¯†åº“
        logger.info(f"[{request_id}] å¼€å§‹åˆ›å»ºä¸ªäººçŸ¥è¯†åº“")
        personal_kb_path = create_personal_knowledge_base(final_name, extracted_info)
        if not personal_kb_path:
            logger.error(f"[{request_id}] é”™è¯¯: åˆ›å»ºä¸ªäººçŸ¥è¯†åº“å¤±è´¥")
            return jsonify({"success": False, "error": "åˆ›å»ºä¸ªäººçŸ¥è¯†åº“å¤±è´¥"}), 500
            
        logger.info(f"[{request_id}] ä¸ªäººçŸ¥è¯†åº“åˆ›å»ºæˆåŠŸ: {personal_kb_path}")
            
        # æ›´æ–°ä¸»çŸ¥è¯†åº“
        logger.info(f"[{request_id}] å¼€å§‹æ›´æ–°ä¸»çŸ¥è¯†åº“")
        update_result = update_main_knowledge_base(personal_kb_path, final_name)
        logger.info(f"[{request_id}] ä¸»çŸ¥è¯†åº“æ›´æ–°ç»“æœ: {update_result}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(file_path)
            logger.info(f"[{request_id}] ä¸´æ—¶æ–‡ä»¶æ¸…ç†æˆåŠŸ: {file_path}")
        except Exception as cleanup_error:
            logger.warning(f"[{request_id}] ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {cleanup_error}")
            
        logger.info(f"[{request_id}] ç®€å†ä¸Šä¼ å¤„ç†å®Œæˆ")
        return jsonify({
            "success": True,
            "analysis": extracted_info,
            "personal_kb_path": personal_kb_path,
            "message": f"ç®€å†åˆ†æå®Œæˆï¼Œå·²ä¸º {final_name} åˆ›å»ºä¸ªäººçŸ¥è¯†åº“"
        })
        
    except Exception as e:
        logger.error(f"[{request_id}] ç®€å†ä¸Šä¼ å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/resume/gtv-assessment', methods=['POST'])
def gtv_assessment():
    """GTVèµ„æ ¼è¯„ä¼°"""
    if not RESUME_PROCESSING_AVAILABLE:
        return jsonify({'success': False, 'error': 'GTVè¯„ä¼°æœåŠ¡ä¸å¯ç”¨'}), 503
    
    request_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    logger.info(f"[{request_id}] å¼€å§‹GTVèµ„æ ¼è¯„ä¼°è¯·æ±‚")
    
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data:
            logger.error(f"[{request_id}] é”™è¯¯: æ²¡æœ‰æä¾›è¯„ä¼°æ•°æ®")
            return jsonify({"success": False, "error": "æ²¡æœ‰æä¾›è¯„ä¼°æ•°æ®"}), 400
            
        # æå–å¿…è¦å‚æ•°
        extracted_info = data.get('extracted_info', {})
        field = data.get('field', 'digital-technology')
        form_name = data.get('name', '').strip()
        form_email = data.get('email', '').strip()
        
        # ä¼˜å…ˆä½¿ç”¨è¡¨å•ä¸­çš„å§“å
        ai_name = extracted_info.get("name", "").strip()
        final_name = form_name if form_name else ai_name
        if not final_name:
            final_name = "æœªçŸ¥ç”¨æˆ·"
            
        logger.info(f"[{request_id}] è¯„ä¼°å‚æ•° - æœ€ç»ˆå§“å: {final_name}, é‚®ç®±: {form_email}, é¢†åŸŸ: {field}")
        
        # å¦‚æœè¡¨å•æä¾›äº†å§“åï¼Œæ›´æ–°åˆ°æå–ä¿¡æ¯ä¸­
        if form_name:
            extracted_info["name"] = form_name
        
        # å¦‚æœè¡¨å•æä¾›äº†é‚®ç®±ï¼Œæ›´æ–°åˆ°æå–ä¿¡æ¯ä¸­
        if form_email:
            extracted_info["email"] = form_email
        
        # ä½¿ç”¨AIè¿›è¡ŒGTVè¯„ä¼°
        logger.info(f"[{request_id}] å¼€å§‹AI GTVè¯„ä¼°")
        gtv_analysis = call_ai_for_gtv_assessment(extracted_info, field)
        
        logger.info(f"[{request_id}] GTVè¯„ä¼°å®Œæˆ")
        
        # è¯„ä¼°å®Œæˆåè‡ªåŠ¨ç”ŸæˆPDF
        pdf_file_path = None
        pdf_filename = None
        try:
            logger.info(f"[{request_id}] å¼€å§‹è‡ªåŠ¨ç”ŸæˆPDFæŠ¥å‘Š...")
            if generate_gtv_pdf_report:
                pdf_file_path = generate_gtv_pdf_report(gtv_analysis)
                pdf_filename = os.path.basename(pdf_file_path)
                logger.info(f"[{request_id}] PDFæŠ¥å‘Šè‡ªåŠ¨ç”ŸæˆæˆåŠŸ: {pdf_filename}")
            else:
                logger.warning(f"[{request_id}] PDFæŠ¥å‘Šç”Ÿæˆå™¨æœªå¯ç”¨ï¼Œè·³è¿‡è‡ªåŠ¨ç”Ÿæˆ")
        except Exception as pdf_error:
            logger.error(f"[{request_id}] è‡ªåŠ¨ç”ŸæˆPDFæŠ¥å‘Šå¤±è´¥: {pdf_error}")
            # PDFç”Ÿæˆå¤±è´¥ä¸å½±å“è¯„ä¼°ç»“æœè¿”å›
        
        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "success": True,
            "gtvAnalysis": gtv_analysis,
            "message": f"GTVèµ„æ ¼è¯„ä¼°å®Œæˆ"
        }
        
        # å¦‚æœPDFç”ŸæˆæˆåŠŸï¼Œæ·»åŠ åˆ°å“åº”ä¸­
        if pdf_file_path and pdf_filename:
            response_data["pdf_file_path"] = pdf_file_path
            response_data["pdf_filename"] = pdf_filename
            response_data["message"] = f"GTVèµ„æ ¼è¯„ä¼°å®Œæˆï¼ŒPDFæŠ¥å‘Šå·²è‡ªåŠ¨ç”Ÿæˆ"
        
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"[{request_id}] GTVè¯„ä¼°å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "error": str(e)}), 500


# ============================================================================
# é”™è¯¯å¤„ç†
# ============================================================================

@app.errorhandler(404)
def not_found(error):
    """404å¤„ç†"""
    return jsonify({'error': 'Endpoint not found'}), 404


@app.errorhandler(500)
def internal_error(error):
    """500å¤„ç†"""
    return jsonify({'error': 'Internal server error'}), 500


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5005))
    debug = os.getenv('DEBUG', 'False') == 'True'
    
    logger.info(f"ğŸš€ å¯åŠ¨GTVç»Ÿä¸€APIæœåŠ¡")
    logger.info(f"   ç«¯å£: {port}")
    logger.info(f"   è°ƒè¯•æ¨¡å¼: {debug}")
    logger.info(f"   åŒ…å«æœåŠ¡:")
    logger.info(f"     - è¯„åˆ†åˆ†æ (/api/scoring/*)")
    logger.info(f"     - æ–‡æ¡£åˆ†æ (/api/documents/*)")
    
    app.run(
        host='0.0.0.0',
        port=port,
        debug=debug,
        use_reloader=False,
    )
