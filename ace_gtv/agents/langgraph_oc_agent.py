#!/usr/bin/env python3
"""
LangGraph OCè¯„ä¼°Agent - åŸºäºçŸ¥è¯†åº“è§„åˆ™å’ŒLLMçš„çœŸå®OCè¯„ä¼°
ä½¿ç”¨å¤šè½®LLMè°ƒç”¨ï¼Œæ ¹æ®çŸ¥è¯†åº“ä¸­çš„OCè§„åˆ™ï¼Œå¯¹ç®€å†å†…å®¹è¿›è¡Œè¯¦ç»†åŒ¹é…å’Œåˆ†æ
"""

import json
import logging
import os
from typing import Any, Dict, List, Optional, TypedDict
from datetime import datetime
import time

try:
    from langgraph.graph import StateGraph, START, END
    HAS_LANGGRAPH = True
except ImportError:
    HAS_LANGGRAPH = False
    logging.warning("âš ï¸ LangGraph not installed, using fallback mode")

try:
    from langchain_openai import ChatOpenAI
    from langchain.tools import tool
    HAS_LANGCHAIN = True
except ImportError:
    HAS_LANGCHAIN = False
    logging.warning("âš ï¸ LangChain not installed")

from langgraph_scoring_agent import KnowledgeBaseManager
from utils.logger_config import setup_module_logger, log_execution_time, log_step, log_oc_assessment_start, log_oc_assessment_complete, log_llm_call

# ============================================================================
# æ—¥å¿—é…ç½®
# ============================================================================

logger = setup_module_logger("oc_agent", os.getenv("LOG_LEVEL", "INFO"))

# ============================================================================
# çŠ¶æ€å®šä¹‰
# ============================================================================

class OCAssessmentState(TypedDict):
    """OCè¯„ä¼°çŠ¶æ€"""
    # è¾“å…¥æ•°æ®
    applicant_data: Dict[str, Any]  # ç”³è¯·äººåŸºæœ¬ä¿¡æ¯
    resume_content: Dict[str, Any]  # ç®€å†å†…å®¹ï¼ˆä»assessmentDataæå–ï¼‰
    
    # çŸ¥è¯†åº“çŠ¶æ€
    oc_rules: List[Dict[str, Any]]  # 4ä¸ªOCè§„åˆ™
    current_oc_index: int  # å½“å‰è¯„ä¼°çš„OCç´¢å¼•
    
    # åˆ†æç»“æœ
    oc_assessments: List[Dict[str, Any]]  # æ¯ä¸ªOCçš„è¯„ä¼°ç»“æœ
    current_assessment: Optional[Dict[str, Any]]  # å½“å‰OCçš„è¯¦ç»†åˆ†æ
    
    # LLMäº¤äº’
    conversation_history: List[Dict[str, str]]  # LLMäº¤äº’å†å²
    llm_calls: List[Dict[str, Any]]  # LLMè°ƒç”¨è®°å½•
    
    # æœ€ç»ˆç»“æœ
    final_summary: Dict[str, Any]
    execution_time: float

# ============================================================================
# LangGraph OCè¯„ä¼°Agent
# ============================================================================

class LangGraphOCAgent:
    """åŸºäºLangGraphçš„OCè¯„ä¼°Agent"""
    
    def __init__(self, llm=None, kb_manager: Optional[KnowledgeBaseManager] = None):
        """åˆå§‹åŒ–Agent"""
        self.llm = llm or self._init_llm()
        self.kb_manager = kb_manager or KnowledgeBaseManager(kb_dir="./public")
        self.tools = self._create_tools()
        
        if HAS_LANGGRAPH:
            self.graph = self._build_langgraph()
        else:
            logger.warning("âš ï¸ LangGraph æœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–æ¨¡å¼")
        
        logger.info("âœ… LangGraph OCè¯„ä¼°Agentåˆå§‹åŒ–å®Œæˆ")
    
    def _init_llm(self):
        """åˆå§‹åŒ–LLM"""
        if not HAS_LANGCHAIN:
            logger.warning("âš ï¸ LangChainæœªå®‰è£…")
            return None
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.warning("âš ï¸ OPENAI_API_KEYæœªè®¾ç½®")
            return None
        
        return ChatOpenAI(
            api_key=api_key,
            model="gpt-4-turbo-preview",
            temperature=0.3  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„åˆ†æ
        )
    
    def _create_tools(self) -> List:
        """åˆ›å»ºLLMå¯ç”¨çš„å·¥å…·"""
        tools = []
        
        if not HAS_LANGCHAIN:
            # å¦‚æœæ²¡æœ‰LangChainï¼Œè¿”å›ç©ºå·¥å…·åˆ—è¡¨
            logger.warning("âš ï¸ LangChainæœªå®‰è£…ï¼Œå·¥å…·åŠŸèƒ½ä¸å¯ç”¨")
            return tools
        
        try:
            @tool
            def get_oc_rules() -> str:
                """è·å–æ‰€æœ‰OCè§„åˆ™ï¼ˆOC 1-4ï¼‰"""
                # ä»çŸ¥è¯†åº“ä¸­è·å–OCè§„åˆ™
                rules = self.kb_manager.search_rules(
                    category="Optional",
                    keywords=["OC", "å¯é€‰è¦æ±‚", "åˆ›æ–°", "è¡Œä¸šè´¡çŒ®", "æŠ€æœ¯è´¡çŒ®", "å­¦æœ¯ç ”ç©¶"]
                )
                
                # ç­›é€‰å‡ºOC 1-4
                oc_rules = []
                for rule in rules:
                    title = rule.get("title", "").lower()
                    if any(f"oc {i}" in title or f"oc-{i}" in title for i in range(1, 5)):
                        oc_rules.append(rule)
                
                return json.dumps(oc_rules, ensure_ascii=False, indent=2)
            
            tools.append(get_oc_rules)
            
            @tool
            def get_specific_oc_rule(oc_number: int) -> str:
                """è·å–ç‰¹å®šOCè§„åˆ™çš„è¯¦ç»†å†…å®¹"""
                rules = self.kb_manager.search_rules(
                    category="Optional",
                    keywords=[f"OC {oc_number}", f"OC-{oc_number}"]
                )
                if rules:
                    return json.dumps(rules[0], ensure_ascii=False, indent=2)
                return f"OC {oc_number} è§„åˆ™æœªæ‰¾åˆ°"
            
            tools.append(get_specific_oc_rule)
        except NameError as e:
            logger.warning(f"âš ï¸ å·¥å…·åˆ›å»ºå¤±è´¥: {e}")
        
        return tools
    
    def _build_langgraph(self) -> StateGraph:
        """æ„å»ºLangGraphå·¥ä½œæµ"""
        if not HAS_LANGGRAPH:
            logger.warning("âš ï¸ LangGraphä¸å¯ç”¨")
            return None
        
        graph = StateGraph(OCAssessmentState)
        
        # å®šä¹‰èŠ‚ç‚¹
        graph.add_node("load_oc_rules", self._load_oc_rules_node)
        graph.add_node("extract_resume_evidence", self._extract_evidence_node)
        graph.add_node("assess_oc1", self._assess_oc_node)
        graph.add_node("assess_oc2", self._assess_oc_node)
        graph.add_node("assess_oc3", self._assess_oc_node)
        graph.add_node("assess_oc4", self._assess_oc_node)
        graph.add_node("generate_summary", self._generate_summary_node)
        
        # å®šä¹‰è¾¹
        graph.add_edge(START, "load_oc_rules")
        graph.add_edge("load_oc_rules", "extract_resume_evidence")
        graph.add_edge("extract_resume_evidence", "assess_oc1")
        graph.add_edge("assess_oc1", "assess_oc2")
        graph.add_edge("assess_oc2", "assess_oc3")
        graph.add_edge("assess_oc3", "assess_oc4")
        graph.add_edge("assess_oc4", "generate_summary")
        graph.add_edge("generate_summary", END)
        
        return graph.compile()
    
    def _load_oc_rules_node(self, state: OCAssessmentState) -> OCAssessmentState:
        """åŠ è½½OCè§„åˆ™èŠ‚ç‚¹"""
        logger.info("ğŸ“š å¼€å§‹åŠ è½½OCè§„åˆ™...")
        
        # ä»çŸ¥è¯†åº“è·å–OCè§„åˆ™
        all_rules = self.kb_manager.search_rules(
            category="Optional",
            keywords=["OC", "å¯é€‰è¦æ±‚"]
        )
        
        # ç­›é€‰å‡ºOC 1-4å¹¶æ’åº
        oc_rules = []
        for i in range(1, 5):
            for rule in all_rules:
                title = rule.get("title", "")
                if f"OC {i}" in title or f"OC-{i}" in title:
                    oc_rules.append(rule)
                    break
        
        state["oc_rules"] = oc_rules
        state["oc_assessments"] = []
        state["current_oc_index"] = 0
        
        logger.info(f"âœ… åŠ è½½äº† {len(oc_rules)} ä¸ªOCè§„åˆ™")
        return state
    
    def _extract_evidence_node(self, state: OCAssessmentState) -> OCAssessmentState:
        """æå–ç®€å†è¯æ®èŠ‚ç‚¹"""
        logger.info("ğŸ“„ æå–ç®€å†è¯æ®...")
        
        resume_content = state.get("resume_content", {})
        
        # ç»“æ„åŒ–æå–è¯æ®
        evidence = {
            "education": resume_content.get("educationBackground", {}).get("degrees", []),
            "experience": resume_content.get("workExperience", {}).get("positions", []),
            "projects": resume_content.get("workExperience", {}).get("projectImpact", []),
            "certifications": resume_content.get("technicalExpertise", {}).get("specializations", []),
            "skills": resume_content.get("technicalExpertise", {}).get("coreSkills", []),
            "achievements": [],
            "publications": [],
            "awards": [],
            "strengths": resume_content.get("strengths", []),
        }
        
        # ä»strengthsä¸­æå–æ›´å¤šä¿¡æ¯
        for strength in resume_content.get("strengths", []):
            area = strength.get("area", "").lower()
            desc = strength.get("description", "")
            if "award" in area or "award" in desc.lower():
                evidence["awards"].append(desc)
            if "publication" in area or "paper" in desc.lower():
                evidence["publications"].append(desc)
            if "achievement" in area:
                evidence["achievements"].append(desc)
        
        state["resume_content"] = evidence
        logger.info(f"âœ… æå–äº† {sum(len(v) if isinstance(v, list) else 1 for v in evidence.values())} æ¡è¯æ®")
        
        return state
    
    def _assess_oc_node(self, state: OCAssessmentState) -> OCAssessmentState:
        """è¯„ä¼°å•ä¸ªOCèŠ‚ç‚¹"""
        current_index = state.get("current_oc_index", 0)
        oc_rules = state.get("oc_rules", [])
        
        if current_index >= len(oc_rules):
            return state
        
        oc_rule = oc_rules[current_index]
        oc_number = current_index + 1
        
        logger.info(f"ğŸ” å¼€å§‹è¯„ä¼° OC {oc_number}: {oc_rule.get('title', '')}")
        
        # ä½¿ç”¨LLMè¿›è¡Œè¯¦ç»†åˆ†æ
        assessment = self._llm_assess_oc(oc_rule, state.get("resume_content", {}), state.get("applicant_data", {}), state, oc_number)
        
        state["current_assessment"] = assessment
        state["oc_assessments"].append(assessment)
        state["current_oc_index"] = current_index + 1
        
        logger.info(f"âœ… OC {oc_number} è¯„ä¼°å®Œæˆ: {assessment.get('status', 'æœªçŸ¥')}")
        
        return state
    
    def _llm_assess_oc(self, oc_rule: Dict[str, Any], evidence: Dict[str, Any], applicant_data: Dict[str, Any], state: OCAssessmentState, oc_number: int = 1) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¯„ä¼°å•ä¸ªOC"""
        llm_start = time.time()
        
        if not self.llm:
            # Fallback: ç®€å•è§„åˆ™åŒ¹é…
            logger.debug(f"ğŸ¤– OC {oc_number} æ—  LLM å¯ç”¨ï¼Œä½¿ç”¨è§„åˆ™åŒ¹é…")
            return self._simple_oc_assessment(oc_rule, evidence, oc_number)
        
        # æ„å»ºprompt
        oc_title = oc_rule.get("title", "")
        oc_content = oc_rule.get("content", "")
        
        logger.debug(f"ğŸ¤– OC {oc_number} æ„å»º LLM prompt...")
        
        prompt = f"""ä½ æ˜¯ä¸€ä½GTVç­¾è¯è¯„ä¼°ä¸“å®¶ã€‚è¯·æ ¹æ®çŸ¥è¯†åº“ä¸­çš„OCè§„åˆ™ï¼Œè¯¦ç»†è¯„ä¼°ç”³è¯·äººæ˜¯å¦æ»¡è¶³è¯¥OCè¦æ±‚ã€‚

## OCè§„åˆ™ä¿¡æ¯
æ ‡é¢˜: {oc_title}

è§„åˆ™å†…å®¹:
{oc_content[:2000]}  # é™åˆ¶é•¿åº¦é¿å…tokenè¿‡å¤š

## ç”³è¯·äººç®€å†è¯æ®
æ•™è‚²èƒŒæ™¯: {', '.join(evidence.get('education', []))}
å·¥ä½œç»éªŒ: {', '.join(evidence.get('experience', []))}
é¡¹ç›®ç»å†: {', '.join(evidence.get('projects', []))}
è®¤è¯è¯ä¹¦: {', '.join(evidence.get('certifications', []))}
æŠ€èƒ½: {', '.join(evidence.get('skills', []))}
æˆå°±: {', '.join(evidence.get('achievements', []))}
å¥–é¡¹: {', '.join(evidence.get('awards', []))}
å‡ºç‰ˆç‰©: {', '.join(evidence.get('publications', []))}
ä¼˜åŠ¿: {json.dumps(evidence.get('strengths', []), ensure_ascii=False)[:500]}

## è¯„ä¼°ä»»åŠ¡
è¯·è¯¦ç»†åˆ†æï¼š
1. ç”³è¯·äººçš„ç®€å†è¯æ®ä¸OCè§„åˆ™çš„å…·ä½“è¦æ±‚å¦‚ä½•åŒ¹é…ï¼Ÿ
2. å“ªäº›è¯æ®æ˜ç¡®æ”¯æŒæ»¡è¶³è¯¥OCï¼Ÿ
3. å“ªäº›è¯æ®ç¼ºå¤±æˆ–ä¸è¶³ï¼Ÿ
4. åŒ¹é…ç¨‹åº¦å¦‚ä½•ï¼Ÿï¼ˆå®Œå…¨æ»¡è¶³/éƒ¨åˆ†æ»¡è¶³/ä¸æ»¡è¶³ï¼‰
5. è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
6. å…·ä½“çš„æ”¹è¿›å»ºè®®

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
  "ocId": "oc-{oc_number}",
  "title": "{oc_title}",
  "category": "{oc_rule.get('category', '')}",
  "status": "æ»¡è¶³" | "éƒ¨åˆ†æ»¡è¶³" | "ä¸æ»¡è¶³",
  "score": 0-100,
  "maxScore": 100,
  "percentage": 0-1,
  "evidence": ["åŒ¹é…çš„è¯æ®åˆ—è¡¨"],
  "reasoning": "è¯¦ç»†çš„åŒ¹é…åˆ†æï¼Œè¯´æ˜ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªçŠ¶æ€ï¼Œå…·ä½“å“ªäº›è¯æ®åŒ¹é…äº†å“ªäº›è¦æ±‚",
  "improvement_suggestions": ["å…·ä½“çš„æ”¹è¿›å»ºè®®"],
  "matched_keywords": ["åŒ¹é…çš„å…³é”®è¯"],
  "llm_analysis": "LLMçš„è¯¦ç»†åˆ†æè¿‡ç¨‹"
}}
"""
        
        try:
            logger.debug(f"ğŸ¤– OC {oc_number} è°ƒç”¨ LLM API...")
            llm_call_start = time.time()
            response = self.llm.invoke(prompt)
            llm_response_time = time.time() - llm_call_start
            
            logger.debug(f"ğŸ¤– OC {oc_number} LLM å“åº”è€—æ—¶: {llm_response_time:.2f}ç§’")
            log_llm_call(logger, "OpenAI", "gpt-4-turbo-preview", response_time=llm_response_time)
            
            content = response.content if hasattr(response, 'content') else str(response)
            logger.debug(f"ğŸ¤– OC {oc_number} LLM å“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # è§£æJSONå“åº”
            parse_start = time.time()
            try:
                # å°è¯•æå–JSON
                import re
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    assessment = json.loads(json_match.group())
                else:
                    assessment = json.loads(content)
                parse_time = time.time() - parse_start
                logger.debug(f"ğŸ¤– OC {oc_number} JSON è§£ææˆåŠŸï¼Œè€—æ—¶: {parse_time:.2f}ç§’")
            except Exception as parse_err:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•è¯„ä¼°
                parse_time = time.time() - parse_start
                logger.warning(f"âš ï¸ OC {oc_number} LLM å“åº”è§£æå¤±è´¥ (è€—æ—¶: {parse_time:.2f}ç§’): {str(parse_err)[:100]}")
                logger.warning(f"âš ï¸ OC {oc_number} å“åº”å†…å®¹é¢„è§ˆ: {content[:200]}")
                assessment = self._simple_oc_assessment(oc_rule, evidence, oc_number)
                assessment["llm_analysis"] = content[:500]
            
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            assessment.setdefault("ocId", f"oc-{oc_number}")
            assessment.setdefault("title", oc_title)
            assessment.setdefault("category", oc_rule.get("category", "Optional"))
            assessment.setdefault("status", "ä¸æ»¡è¶³")
            assessment.setdefault("score", 0)
            assessment.setdefault("maxScore", 100)
            assessment.setdefault("percentage", 0.0)
            assessment.setdefault("evidence", [])
            assessment.setdefault("reasoning", "è¯„ä¼°ä¸­...")
            assessment.setdefault("improvement_suggestions", [])
            assessment.setdefault("matched_keywords", [])
            
            total_llm_time = time.time() - llm_start
            logger.debug(f"âœ… OC {oc_number} LLM è¯„ä¼°å®Œæˆï¼Œæ€»è€—æ—¶: {total_llm_time:.2f}ç§’")
            
            return assessment
            
        except Exception as e:
            elapsed = time.time() - llm_start
            logger.error(f"âŒ OC {oc_number} LLM è¯„ä¼°å¤±è´¥ (è€—æ—¶: {elapsed:.2f}ç§’): {str(e)}")
            return self._simple_oc_assessment(oc_rule, evidence, oc_number)
    
    def _simple_oc_assessment(self, oc_rule: Dict[str, Any], evidence: Dict[str, Any], oc_number: int = 1) -> Dict[str, Any]:
        """ç®€å•è§„åˆ™åŒ¹é…è¯„ä¼°ï¼ˆfallbackï¼‰"""
        oc_title = oc_rule.get("title", f"OC {oc_number}")
        category = oc_rule.get("category", "Optional")
        content = oc_rule.get("content", "").lower()
        
        # ç®€å•å…³é”®è¯åŒ¹é…
        status = "ä¸æ»¡è¶³"
        score = 0
        evidence_list = []
        reasoning = "æœªæ‰¾åˆ°åŒ¹é…çš„è¯æ®"
        
        # OC 1: åˆ›æ–°è®°å½•
        if "oc 1" in oc_title.lower() or "åˆ›æ–°" in oc_title.lower():
            if evidence.get("projects") or evidence.get("achievements"):
                status = "éƒ¨åˆ†æ»¡è¶³"
                score = 60
                evidence_list = evidence.get("projects", [])[:3]
                reasoning = "å‘ç°é¡¹ç›®ç»å†ï¼Œä½†éœ€è¦æ›´å¤šè´¢åŠ¡å’Œå•†ä¸šæˆåŠŸè¯æ˜"
        
        # OC 2: è¡Œä¸šè´¡çŒ®
        elif "oc 2" in oc_title.lower() or "è¡Œä¸šè´¡çŒ®" in oc_title.lower():
            if evidence.get("projects") or evidence.get("certifications"):
                status = "éƒ¨åˆ†æ»¡è¶³"
                score = 50
                evidence_list = evidence.get("certifications", [])[:2]
                reasoning = "å‘ç°è®¤è¯å’ŒæŠ€èƒ½ï¼Œä½†éœ€è¦å¼€æºè´¡çŒ®æˆ–ä¼šè®®æ¼”è®²è¯æ˜"
        
        # OC 3: æŠ€æœ¯è´¡çŒ®
        elif "oc 3" in oc_title.lower() or "æŠ€æœ¯è´¡çŒ®" in oc_title.lower():
            if evidence.get("skills") or evidence.get("projects"):
                status = "éƒ¨åˆ†æ»¡è¶³"
                score = 55
                evidence_list = evidence.get("skills", [])[:3]
                reasoning = "å‘ç°æŠ€æœ¯æŠ€èƒ½ï¼Œä½†éœ€è¦GitHubè´¡çŒ®æˆ–æŠ€æœ¯æ¶æ„è¯æ˜"
        
        # OC 4: å­¦æœ¯ç ”ç©¶
        elif "oc 4" in oc_title.lower() or "å­¦æœ¯ç ”ç©¶" in oc_title.lower():
            if evidence.get("publications") or evidence.get("education"):
                status = "éƒ¨åˆ†æ»¡è¶³"
                score = 40
                evidence_list = evidence.get("publications", [])[:2]
                reasoning = "å‘ç°æ•™è‚²èƒŒæ™¯ï¼Œä½†éœ€è¦é¡¶çº§æœŸåˆŠè®ºæ–‡æˆ–ç ”ç©¶èµ„åŠ©è¯æ˜"
        
        return {
            "ocId": f"oc-{oc_number}",
            "title": oc_title,
            "category": category,
            "status": status,
            "score": score,
            "maxScore": 100,
            "percentage": score / 100.0,
            "evidence": evidence_list,
            "reasoning": reasoning,
            "improvement_suggestions": ["è·å–æ›´å¤šç›¸å…³è¯æ®ä»¥æ»¡è¶³OCè¦æ±‚"],
            "matched_keywords": [],
            "llm_analysis": "ä½¿ç”¨ç®€å•è§„åˆ™åŒ¹é…ï¼ˆLLMä¸å¯ç”¨ï¼‰"
        }
    
    def _generate_summary_node(self, state: OCAssessmentState) -> OCAssessmentState:
        """ç”Ÿæˆæ±‡æ€»èŠ‚ç‚¹"""
        logger.info("ğŸ“Š ç”ŸæˆOCè¯„ä¼°æ±‡æ€»...")
        
        oc_assessments = state.get("oc_assessments", [])
        
        satisfied = sum(1 for a in oc_assessments if a.get("status") == "æ»¡è¶³")
        partially_satisfied = sum(1 for a in oc_assessments if a.get("status") == "éƒ¨åˆ†æ»¡è¶³")
        unsatisfied = sum(1 for a in oc_assessments if a.get("status") == "ä¸æ»¡è¶³")
        
        total_score = sum(a.get("score", 0) for a in oc_assessments)
        average_score = total_score / len(oc_assessments) if oc_assessments else 0
        
        fulfillment_rate = round((satisfied / len(oc_assessments) * 100)) if oc_assessments else 0
        
        # ç”Ÿæˆå»ºè®®
        if self.llm:
            recommendation = self._generate_llm_recommendation(oc_assessments)
        else:
            recommendation = f"ç”³è¯·äººæ»¡è¶³ {satisfied} ä¸ªOCï¼Œéƒ¨åˆ†æ»¡è¶³ {partially_satisfied} ä¸ªOCã€‚å»ºè®®æ ¹æ®ç¼ºå¤±çš„è¯æ®ç±»å‹è¿›è¡Œè¡¥å……ã€‚"
        
        state["final_summary"] = {
            "total": len(oc_assessments),
            "satisfied": satisfied,
            "partially_satisfied": partially_satisfied,
            "unsatisfied": unsatisfied,
            "average_score": round(average_score),
            "fulfillment_rate": f"{fulfillment_rate}%",
            "recommendation": recommendation
        }
        
        logger.info(f"âœ… æ±‡æ€»å®Œæˆ: {satisfied}æ»¡è¶³, {partially_satisfied}éƒ¨åˆ†æ»¡è¶³, {unsatisfied}ä¸æ»¡è¶³")
        
        return state
    
    def _generate_llm_recommendation(self, oc_assessments: List[Dict[str, Any]]) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆå»ºè®®"""
        if not self.llm:
            return "å»ºè®®æ ¹æ®è¯„ä¼°ç»“æœè¡¥å……ç›¸å…³è¯æ®ã€‚"
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹OCè¯„ä¼°ç»“æœï¼Œç”Ÿæˆä¸€ä»½é’ˆå¯¹æ€§çš„æ”¹è¿›å»ºè®®ï¼š

{json.dumps(oc_assessments, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆä¸€æ®µä¸­æ–‡å»ºè®®ï¼Œè¯´æ˜ï¼š
1. æ•´ä½“OCæ»¡è¶³æƒ…å†µ
2. å“ªäº›OCéœ€è¦é‡ç‚¹å…³æ³¨
3. å…·ä½“çš„æ”¹è¿›æ–¹å‘

æ§åˆ¶åœ¨100å­—ä»¥å†…ã€‚"""
        
        try:
            response = self.llm.invoke(prompt)
            return response.content if hasattr(response, 'content') else str(response)
        except:
            return "å»ºè®®æ ¹æ®è¯„ä¼°ç»“æœè¡¥å……ç›¸å…³è¯æ®ã€‚"
    
    def assess(self, applicant_data: Dict[str, Any], assessment_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„OCè¯„ä¼°"""
        start_time = datetime.now()
        overall_start = time.time()
        request_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        
        log_oc_assessment_start(logger, request_id, applicant_data.get('name', 'N/A'), 4)
        logger.info(f"[{request_id}] ç”³è¯·äººå­—æ®µ: {applicant_data.get('field', 'N/A')}")
        logger.info(f"[{request_id}] è¯„ä¼°æ•°æ®é”®: {list(assessment_data.keys())}")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state: OCAssessmentState = {
            "applicant_data": applicant_data,
            "resume_content": assessment_data,
            "oc_rules": [],
            "current_oc_index": 0,
            "oc_assessments": [],
            "current_assessment": None,
            "conversation_history": [],
            "llm_calls": [],
            "final_summary": {},
            "execution_time": 0.0
        }
        
        try:
            # åŠ è½½ OC è§„åˆ™
            logger.debug(f"[{request_id}] å¼€å§‹åŠ è½½ OC è§„åˆ™...")
            load_rules_start = time.time()
            if HAS_LANGGRAPH and self.graph:
                # ä½¿ç”¨LangGraphæ‰§è¡Œ
                logger.info(f"[{request_id}] ä½¿ç”¨ LangGraph æ¨¡å¼æ‰§è¡Œ OC è¯„ä¼°")
                final_state = self.graph.invoke(initial_state)
            else:
                # ç®€åŒ–æ¨¡å¼ï¼šç›´æ¥æ‰§è¡ŒèŠ‚ç‚¹
                logger.warning(f"[{request_id}] âš ï¸ ä½¿ç”¨ç®€åŒ–æ¨¡å¼æ‰§è¡ŒOCè¯„ä¼° (LangGraph={HAS_LANGGRAPH})")
                final_state = initial_state
                
                # åŠ è½½è§„åˆ™
                logger.debug(f"[{request_id}] æ‰§è¡Œ _load_oc_rules_node...")
                final_state = self._load_oc_rules_node(final_state)
                load_rules_time = time.time() - load_rules_start
                logger.info(f"[{request_id}] âœ… åŠ è½½ OC è§„åˆ™å®Œæˆï¼Œè€—æ—¶: {load_rules_time:.2f}ç§’")
                
                # æå–è¯æ®
                logger.debug(f"[{request_id}] æ‰§è¡Œ _extract_evidence_node...")
                extract_start = time.time()
                final_state = self._extract_evidence_node(final_state)
                extract_time = time.time() - extract_start
                logger.info(f"[{request_id}] âœ… æå–è¯æ®å®Œæˆï¼Œè€—æ—¶: {extract_time:.2f}ç§’")
                
                # è¯„ä¼°4ä¸ªOC
                oc_rules_count = len(final_state.get("oc_rules", []))
                logger.info(f"[{request_id}] å¼€å§‹è¯„ä¼° {oc_rules_count} ä¸ª OC...")
                
                for i in range(oc_rules_count):
                    oc_start = time.time()
                    log_step(logger, i + 1, oc_rules_count, f"è¯„ä¼° OC {i + 1}")
                    
                    final_state["current_oc_index"] = i
                    logger.debug(f"[{request_id}] å¼€å§‹è¯„ä¼° OC {i + 1}...")
                    
                    final_state = self._assess_oc_node(final_state)
                    
                    oc_time = time.time() - oc_start
                    assessment = final_state.get("oc_assessments", [{}])[-1] if final_state.get("oc_assessments") else {}
                    status = assessment.get("status", "æœªçŸ¥")
                    score = assessment.get("score", 0)
                    log_step(logger, i + 1, oc_rules_count, f"OC {i + 1} å®Œæˆ | çŠ¶æ€: {status} | è¯„åˆ†: {score} | è€—æ—¶: {oc_time:.2f}ç§’", "success")
                
                # ç”Ÿæˆæ€»ç»“
                logger.debug(f"[{request_id}] æ‰§è¡Œ _generate_summary_node...")
                summary_start = time.time()
                final_state = self._generate_summary_node(final_state)
                summary_time = time.time() - summary_start
                logger.info(f"[{request_id}] âœ… ç”Ÿæˆæ€»ç»“å®Œæˆï¼Œè€—æ—¶: {summary_time:.2f}ç§’")
            
            execution_time = (datetime.now() - start_time).total_seconds()
            overall_time = time.time() - overall_start
            final_state["execution_time"] = execution_time
            
            oc_results = final_state.get("oc_assessments", [])
            llm_calls = final_state.get("llm_calls", [])
            
            log_oc_assessment_complete(
                logger, 
                request_id, 
                overall_time, 
                len(oc_results),
                errors=0
            )
            
            logger.info(f"[{request_id}] ğŸ“Š è¯„ä¼°ç»Ÿè®¡:")
            logger.info(f"[{request_id}]   - æ€»è€—æ—¶: {overall_time:.2f}ç§’")
            logger.info(f"[{request_id}]   - OC ç»“æœæ•°: {len(oc_results)}")
            logger.info(f"[{request_id}]   - LLM è°ƒç”¨æ•°: {len(llm_calls)}")
            
            # ç»Ÿè®¡çŠ¶æ€
            status_counts = {}
            for result in oc_results:
                status = result.get("status", "æœªçŸ¥")
                status_counts[status] = status_counts.get(status, 0) + 1
            logger.info(f"[{request_id}]   - çŠ¶æ€åˆ†å¸ƒ: {status_counts}")
            
            return {
                "success": True,
                "oc_results": oc_results,
                "summary": final_state.get("final_summary", {}),
                "execution_time": overall_time,
                "llm_calls": len(llm_calls),
                "request_id": request_id
            }
            
        except Exception as e:
            elapsed = time.time() - overall_start
            logger.error(f"[{request_id}] âŒ OCè¯„ä¼°å¤±è´¥: {str(e)}", exc_info=True)
            logger.error(f"[{request_id}] é”™è¯¯å‘ç”Ÿæ—¶å·²è€—æ—¶: {elapsed:.2f}ç§’")
            return {
                "success": False,
                "error": str(e),
                "oc_results": [],
                "summary": {},
                "request_id": request_id
            }

