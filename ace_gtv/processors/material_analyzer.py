#!/usr/bin/env python3
"""
GTVææ–™æ™ºèƒ½åˆ†æå™¨
åˆ†æå®¢æˆ·æäº¤çš„æ‰€æœ‰ææ–™ï¼Œç”ŸæˆGTVé€’äº¤æ¡†æ¶è„‘å›¾
"""

import os
import json
import sqlite3
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path

from utils.logger_config import setup_module_logger

logger = setup_module_logger("material_analyzer", os.getenv("LOG_LEVEL", "INFO"))

# GTVé€’äº¤æ¡†æ¶æ¨¡æ¿
GTV_FRAMEWORK = {
    "é¢†åŸŸå®šä½": {
        "id": "domain",
        "description": "ç¡®å®šç”³è¯·äººçš„ä¸“ä¸šé¢†åŸŸå’Œç”³è¯·ç±»åˆ«",
        "children": {
            "è¯„ä¼°æœºæ„": "Tech Nation",
            "ç»†åˆ†é¢†åŸŸ": "",
            "å²—ä½å®šä½": "",
            "æ ¸å¿ƒè®ºç‚¹": ""
        }
    },
    "MC_å¿…é€‰æ ‡å‡†": {
        "id": "mc",
        "description": "Mandatory Criteria - å¿…é¡»æ»¡è¶³çš„æ ‡å‡†",
        "children": {
            "MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›": {
                "description": "é¢†å¯¼äº§å“ã€å›¢é˜Ÿæˆ–å…¬å¸å¢é•¿çš„è¯æ®",
                "evidence_types": ["æ¨èä¿¡", "äº§å“æè¿°", "æ–°é—»æŠ¥é“", "ä»£ç è´¡çŒ®"],
                "collected": []
            },
            "MC2_å•†ä¸šå‘å±•": {
                "description": "å•†ä¸šå‘å±•ã€è¥é”€ã€æ”¶å…¥å¢é•¿çš„è¯æ®",
                "evidence_types": ["é”€å”®åˆåŒ", "å®¢æˆ·åè®®", "æ”¶å…¥è¯æ˜"],
                "collected": []
            },
            "MC3_éè¥åˆ©/ç¤¾ä¼šä¼ä¸š": {
                "description": "é¢†å¯¼æ•°å­—ç§‘æŠ€é¢†åŸŸéè¥åˆ©ç»„ç»‡çš„è¯æ®",
                "evidence_types": ["è˜ä¹¦", "æ´»åŠ¨è¯æ˜", "åª’ä½“æŠ¥é“"],
                "collected": []
            },
            "MC4_ä¸“å®¶è¯„å®¡è§’è‰²": {
                "description": "è¯„å®¡åŒè¡Œå·¥ä½œçš„ä¸“å®¶è§’è‰²è¯æ®",
                "evidence_types": ["è¯„å®¡é‚€è¯·", "è¯„å§”è¯ä¹¦", "ä¸“å®¶è˜ä¹¦"],
                "collected": []
            }
        }
    },
    "OC_å¯é€‰æ ‡å‡†": {
        "id": "oc",
        "description": "Optional Criteria - è‡³å°‘æ»¡è¶³2é¡¹",
        "children": {
            "OC1_åˆ›æ–°": {
                "description": "åˆ›æ–°/äº§å“å¼€å‘åŠå¸‚åœºéªŒè¯è¯æ®",
                "evidence_types": ["ä¸“åˆ©è¯ä¹¦", "äº§å“æˆªå›¾", "è´¢åŠ¡æŠ¥è¡¨", "é‡‡è´­åˆåŒ"],
                "collected": []
            },
            "OC2_è¡Œä¸šè®¤å¯": {
                "description": "ä½œä¸ºé¢†åŸŸä¸“å®¶çš„è®¤å¯è¯æ®",
                "evidence_types": ["æ¼”è®²é‚€è¯·", "åª’ä½“é‡‡è®¿", "è¡Œä¸šå¥–é¡¹", "è®ºæ–‡å‘è¡¨"],
                "collected": []
            },
            "OC3_é‡å¤§è´¡çŒ®": {
                "description": "å¯¹æ•°å­—æŠ€æœ¯äº§å“çš„é‡å¤§æŠ€æœ¯è´¡çŒ®",
                "evidence_types": ["ä»£ç è´¡çŒ®", "æŠ€æœ¯æ–‡æ¡£", "ç³»ç»Ÿæ¶æ„", "ä¸“åˆ©"],
                "collected": []
            },
            "OC4_å­¦æœ¯è´¡çŒ®": {
                "description": "åœ¨æ•°å­—æŠ€æœ¯é¢†åŸŸçš„å­¦æœ¯è´¡çŒ®",
                "evidence_types": ["è®ºæ–‡", "å¼•ç”¨æ•°æ®", "å­¦æœ¯ä¼šè®®", "ç ”ç©¶é¡¹ç›®"],
                "collected": []
            }
        }
    },
    "æ¨èä¿¡": {
        "id": "reference",
        "description": "3å°æ¨èä¿¡",
        "children": {
            "æ¨èäºº1": {"name": "", "title": "", "relationship": "", "status": ""},
            "æ¨èäºº2": {"name": "", "title": "", "relationship": "", "status": ""},
            "æ¨èäºº3": {"name": "", "title": "", "relationship": "", "status": ""}
        }
    },
    "ä¸ªäººé™ˆè¿°": {
        "id": "statement",
        "description": "Personal Statement",
        "content": ""
    }
}


class MaterialAnalyzer:
    """ææ–™åˆ†æå™¨"""
    
    def __init__(self, db_path: str = "copywriting.db"):
        self.db_path = db_path
        self.llm_client = None
        self._init_llm()
        logger.info("ææ–™åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_llm(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
            
            api_key = os.getenv("ENNCLOUD_API_KEY") or os.getenv("OPENAI_API_KEY")
            base_url = os.getenv("ENNCLOUD_BASE_URL") or os.getenv("OPENAI_BASE_URL")
            
            if api_key and base_url:
                self.llm_client = OpenAI(api_key=api_key, base_url=base_url)
                self.model = os.getenv("ENNCLOUD_MODEL", "glm-4.6-no-think")
                logger.info(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {base_url}")
            else:
                logger.warning("æœªé…ç½®LLMï¼Œå°†ä½¿ç”¨è§„åˆ™åˆ†æ")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–LLMå¤±è´¥: {e}")
    
    def analyze_project_materials(self, project_id: str) -> Dict[str, Any]:
        """
        åˆ†æé¡¹ç›®çš„æ‰€æœ‰ææ–™ï¼Œç”ŸæˆGTVæ¡†æ¶
        """
        try:
            # 1. è·å–é¡¹ç›®ä¿¡æ¯
            project_info = self._get_project_info(project_id)
            if not project_info:
                return {"success": False, "error": "é¡¹ç›®ä¸å­˜åœ¨"}
            
            # 2. è·å–æ‰€æœ‰å·²æ”¶é›†çš„ææ–™
            materials = self._get_collected_materials(project_id)
            
            # 3. è·å–æ‰€æœ‰è¡¨å•æ•°æ®
            forms = self._get_form_data(project_id)
            
            # 4. æå–ææ–™å†…å®¹
            material_contents = self._extract_material_contents(materials)
            
            # 5. ä½¿ç”¨AIåˆ†æææ–™å¹¶åŒ¹é…åˆ°GTVæ¡†æ¶
            framework = self._analyze_and_map_to_framework(
                project_info, materials, forms, material_contents
            )
            
            # 6. ç”Ÿæˆåˆ†ææŠ¥å‘Š
            report = self._generate_analysis_report(framework)
            
            # 7. ä¿å­˜åˆ†æç»“æœ
            self._save_analysis_result(project_id, framework, report)
            
            return {
                "success": True,
                "data": {
                    "project_id": project_id,
                    "project_name": project_info.get("client_name", ""),
                    "framework": framework,
                    "report": report,
                    "statistics": self._calculate_statistics(framework),
                    "analyzed_at": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logger.error(f"åˆ†æé¡¹ç›®ææ–™å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def _get_project_info(self, project_id: str) -> Optional[Dict]:
        """è·å–é¡¹ç›®ä¿¡æ¯"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # å°è¯•ä¸åŒçš„è¡¨å
            for table in ["copywriting_projects", "projects"]:
                try:
                    cursor.execute(
                        f"SELECT * FROM {table} WHERE project_id = ?",
                        (project_id,)
                    )
                    row = cursor.fetchone()
                    if row:
                        conn.close()
                        return dict(row)
                except:
                    continue
            
            conn.close()
            return None
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _get_collected_materials(self, project_id: str) -> List[Dict]:
        """è·å–æ‰€æœ‰å·²æ”¶é›†çš„ææ–™"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT mf.*, mc.category_id, mc.item_id, mc.status
                FROM material_files mf
                LEFT JOIN material_collection mc ON mf.project_id = mc.project_id 
                    AND mf.category_id = mc.category_id AND mf.item_id = mc.item_id
                WHERE mf.project_id = ?
                ORDER BY mf.uploaded_at DESC
            """, (project_id,))
            
            rows = cursor.fetchall()
            conn.close()
            
            return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"è·å–ææ–™æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _get_form_data(self, project_id: str) -> List[Dict]:
        """è·å–æ‰€æœ‰è¡¨å•æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT * FROM collection_forms
                WHERE project_id = ?
            """, (project_id,))
            
            rows = cursor.fetchall()
            conn.close()
            
            result = []
            for row in rows:
                data = dict(row)
                if data.get("form_data"):
                    data["form_data"] = json.loads(data["form_data"])
                result.append(data)
            
            return result
        except Exception as e:
            logger.error(f"è·å–è¡¨å•æ•°æ®å¤±è´¥: {e}")
            return []
    
    def _extract_material_contents(self, materials: List[Dict]) -> Dict[str, str]:
        """æå–ææ–™æ–‡ä»¶çš„æ–‡æœ¬å†…å®¹"""
        contents = {}
        
        for material in materials:
            file_path = material.get("file_path")
            file_type = material.get("file_type", "").lower()
            file_id = material.get("id")
            
            if not file_path or not os.path.exists(file_path):
                continue
            
            try:
                content = None
                
                if file_type == "txt":
                    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                        content = f.read()
                
                elif file_type == "docx":
                    try:
                        from docx import Document
                        doc = Document(file_path)
                        content = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
                    except:
                        pass
                
                elif file_type == "pdf":
                    try:
                        from pdfminer.high_level import extract_text
                        content = extract_text(file_path)
                    except:
                        pass
                
                if content and len(content) > 50:
                    # é™åˆ¶å†…å®¹é•¿åº¦
                    contents[str(file_id)] = content[:5000]
                    
            except Exception as e:
                logger.warning(f"æå–æ–‡ä»¶å†…å®¹å¤±è´¥ {file_path}: {e}")
        
        return contents
    
    def _analyze_and_map_to_framework(
        self, 
        project_info: Dict, 
        materials: List[Dict], 
        forms: List[Dict],
        contents: Dict[str, str]
    ) -> Dict:
        """åˆ†æææ–™å¹¶æ˜ å°„åˆ°GTVæ¡†æ¶"""
        
        import copy
        framework = copy.deepcopy(GTV_FRAMEWORK)
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡ææ–™
        category_materials = {}
        for m in materials:
            cat_id = m.get("category_id", "unknown")
            if cat_id not in category_materials:
                category_materials[cat_id] = []
            category_materials[cat_id].append(m)
        
        # æ˜ å°„åˆ°æ¡†æ¶
        # folder_1: ä¸ªäººèµ„æ–™ -> åŸºæœ¬ä¿¡æ¯
        # folder_2: ç°é›‡ä¸» -> MC1/MC2
        # folder_3: è¿‡å¾€é›‡ä¸» -> MC1/MC2/MC3
        # folder_4: é‡å¤§ä¸šç»© -> OC1/OC2/OC3/OC4
        # folder_5: é¡¹ç›®è¯æ® -> MC1/OC1/OC3
        # folder_6: æ¨èäºº -> æ¨èä¿¡
        
        # æå–æ¨èäººä¿¡æ¯
        if "folder_6" in category_materials:
            for m in category_materials["folder_6"]:
                item_id = m.get("item_id", "")
                if "recommender_1" in item_id:
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº1"]["status"] = "å·²æ”¶é›†"
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº1"]["files"] = [m.get("file_name")]
                elif "recommender_2" in item_id:
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº2"]["status"] = "å·²æ”¶é›†"
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº2"]["files"] = [m.get("file_name")]
                elif "recommender_3" in item_id:
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº3"]["status"] = "å·²æ”¶é›†"
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº3"]["files"] = [m.get("file_name")]
        
        # å¤„ç†ä¸šç»©è¯æ®
        if "folder_4" in category_materials:
            for m in category_materials["folder_4"]:
                item_id = m.get("item_id", "")
                file_name = m.get("file_name", "")
                
                evidence = {
                    "file_name": file_name,
                    "file_id": m.get("id"),
                    "category": item_id
                }
                
                # ä¸“åˆ© -> OC1/OC3
                if "patent" in item_id or "ä¸“åˆ©" in file_name:
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC1_åˆ›æ–°"]["collected"].append(evidence)
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC3_é‡å¤§è´¡çŒ®"]["collected"].append(evidence)
                
                # è®ºæ–‡ -> OC2/OC4
                elif "publication" in item_id or "è®ºæ–‡" in file_name:
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC2_è¡Œä¸šè®¤å¯"]["collected"].append(evidence)
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC4_å­¦æœ¯è´¡çŒ®"]["collected"].append(evidence)
                
                # å¥–é¡¹ -> OC2
                elif "award" in item_id or "å¥–" in file_name:
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC2_è¡Œä¸šè®¤å¯"]["collected"].append(evidence)
                
                # è´¡çŒ®è¡¨ -> MC1
                elif "contribution" in item_id:
                    framework["MC_å¿…é€‰æ ‡å‡†"]["children"]["MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›"]["collected"].append(evidence)
        
        # å¤„ç†é¡¹ç›®è¯æ®
        if "folder_5" in category_materials:
            for m in category_materials["folder_5"]:
                evidence = {
                    "file_name": m.get("file_name", ""),
                    "file_id": m.get("id"),
                    "category": m.get("item_id", "")
                }
                framework["MC_å¿…é€‰æ ‡å‡†"]["children"]["MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›"]["collected"].append(evidence)
                framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC1_åˆ›æ–°"]["collected"].append(evidence)
        
        # å¤„ç†é›‡ä¸»ææ–™
        for folder in ["folder_2", "folder_3"]:
            if folder in category_materials:
                for m in category_materials[folder]:
                    evidence = {
                        "file_name": m.get("file_name", ""),
                        "file_id": m.get("id"),
                        "category": m.get("item_id", "")
                    }
                    item_id = m.get("item_id", "")
                    
                    if "employment" in item_id or "å°±èŒ" in m.get("file_name", ""):
                        framework["MC_å¿…é€‰æ ‡å‡†"]["children"]["MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›"]["collected"].append(evidence)
                    elif "award" in item_id:
                        framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC2_è¡Œä¸šè®¤å¯"]["collected"].append(evidence)
        
        # ä½¿ç”¨AIè¿›è¡Œæ›´æ·±å…¥çš„åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.llm_client and contents:
            framework = self._ai_enhanced_analysis(framework, contents, project_info)
        
        return framework
    
    def _ai_enhanced_analysis(self, framework: Dict, contents: Dict, project_info: Dict) -> Dict:
        """ä½¿ç”¨AIå¢å¼ºåˆ†æ"""
        try:
            # æ„å»ºæç¤º
            content_summary = "\n\n".join([
                f"æ–‡ä»¶{fid}å†…å®¹æ‘˜è¦:\n{content[:1000]}..."
                for fid, content in list(contents.items())[:5]
            ])
            
            prompt = f"""
åˆ†æä»¥ä¸‹GTVç­¾è¯ç”³è¯·ææ–™ï¼Œæå–å…³é”®ä¿¡æ¯ï¼š

ç”³è¯·äººï¼š{project_info.get('client_name', 'æœªçŸ¥')}

ææ–™å†…å®¹æ‘˜è¦ï¼š
{content_summary}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
1. ç”³è¯·äººçš„ä¸“ä¸šé¢†åŸŸï¼ˆdomainï¼‰
2. ä¸»è¦å·¥ä½œæˆå°±ï¼ˆachievementsï¼‰- åˆ—è¡¨
3. æŠ€æœ¯è´¡çŒ®ï¼ˆtechnical_contributionsï¼‰- åˆ—è¡¨
4. é¢†å¯¼åŠ›è¯æ®ï¼ˆleadershipï¼‰- åˆ—è¡¨
5. åˆ›æ–°æˆæœï¼ˆinnovationsï¼‰- åˆ—è¡¨
6. å»ºè®®çš„ç”³è¯·ç­–ç•¥ï¼ˆstrategyï¼‰

è¿”å›JSONæ ¼å¼ã€‚
"""
            
            response = self.llm_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000
            )
            
            ai_result = response.choices[0].message.content
            
            # å°è¯•è§£æJSON
            try:
                import re
                json_match = re.search(r'\{[\s\S]*\}', ai_result)
                if json_match:
                    ai_data = json.loads(json_match.group())
                    
                    # æ›´æ–°æ¡†æ¶
                    if ai_data.get("domain"):
                        framework["é¢†åŸŸå®šä½"]["children"]["ç»†åˆ†é¢†åŸŸ"] = ai_data["domain"]
                    
                    if ai_data.get("strategy"):
                        framework["åˆ†æå»ºè®®"] = {
                            "id": "suggestion",
                            "content": ai_data["strategy"]
                        }
            except:
                pass
                
        except Exception as e:
            logger.warning(f"AIå¢å¼ºåˆ†æå¤±è´¥: {e}")
        
        return framework
    
    def _generate_analysis_report(self, framework: Dict) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = {
            "summary": "",
            "mc_status": {},
            "oc_status": {},
            "recommendations": [],
            "missing_items": [],
            "strength_points": []
        }
        
        # åˆ†æMCçŠ¶æ€
        mc = framework.get("MC_å¿…é€‰æ ‡å‡†", {}).get("children", {})
        for mc_key, mc_data in mc.items():
            collected = mc_data.get("collected", [])
            report["mc_status"][mc_key] = {
                "count": len(collected),
                "status": "å……è¶³" if len(collected) >= 2 else ("ä¸è¶³" if len(collected) == 0 else "åŸºæœ¬"),
                "files": [c.get("file_name") for c in collected[:5]]
            }
        
        # åˆ†æOCçŠ¶æ€
        oc = framework.get("OC_å¯é€‰æ ‡å‡†", {}).get("children", {})
        oc_satisfied = 0
        for oc_key, oc_data in oc.items():
            collected = oc_data.get("collected", [])
            status = "å……è¶³" if len(collected) >= 2 else ("ä¸è¶³" if len(collected) == 0 else "åŸºæœ¬")
            if len(collected) >= 2:
                oc_satisfied += 1
            report["oc_status"][oc_key] = {
                "count": len(collected),
                "status": status,
                "files": [c.get("file_name") for c in collected[:5]]
            }
        
        # åˆ†ææ¨èä¿¡
        refs = framework.get("æ¨èä¿¡", {}).get("children", {})
        ref_count = sum(1 for r in refs.values() if r.get("status") == "å·²æ”¶é›†")
        
        # ç”Ÿæˆå»ºè®®
        if ref_count < 3:
            report["missing_items"].append(f"æ¨èä¿¡è¿˜éœ€è¦{3-ref_count}å°")
        
        if oc_satisfied < 2:
            report["missing_items"].append(f"å¯é€‰æ ‡å‡†(OC)éœ€è¦è‡³å°‘æ»¡è¶³2é¡¹ï¼Œå½“å‰ä»…æ»¡è¶³{oc_satisfied}é¡¹")
        
        # æ€»ç»“
        mc_ok = any(s["count"] >= 2 for s in report["mc_status"].values())
        report["summary"] = f"""
ææ–™åˆ†æå®Œæˆã€‚
- å¿…é€‰æ ‡å‡†(MC)ï¼š{"åŸºæœ¬æ»¡è¶³" if mc_ok else "éœ€è¦è¡¥å……ææ–™"}
- å¯é€‰æ ‡å‡†(OC)ï¼šæ»¡è¶³{oc_satisfied}/4é¡¹ï¼ˆéœ€è‡³å°‘2é¡¹ï¼‰
- æ¨èä¿¡ï¼šå·²æ”¶é›†{ref_count}/3å°
        """.strip()
        
        return report
    
    def _calculate_statistics(self, framework: Dict) -> Dict:
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        stats = {
            "total_files": 0,
            "mc_coverage": 0,
            "oc_coverage": 0,
            "reference_count": 0
        }
        
        # MCç»Ÿè®¡
        mc = framework.get("MC_å¿…é€‰æ ‡å‡†", {}).get("children", {})
        mc_with_evidence = sum(1 for v in mc.values() if len(v.get("collected", [])) > 0)
        stats["mc_coverage"] = round(mc_with_evidence / len(mc) * 100) if mc else 0
        
        for v in mc.values():
            stats["total_files"] += len(v.get("collected", []))
        
        # OCç»Ÿè®¡
        oc = framework.get("OC_å¯é€‰æ ‡å‡†", {}).get("children", {})
        oc_with_evidence = sum(1 for v in oc.values() if len(v.get("collected", [])) >= 2)
        stats["oc_coverage"] = round(oc_with_evidence / 2 * 100)  # éœ€è¦æ»¡è¶³2é¡¹
        stats["oc_coverage"] = min(stats["oc_coverage"], 100)
        
        for v in oc.values():
            stats["total_files"] += len(v.get("collected", []))
        
        # æ¨èä¿¡
        refs = framework.get("æ¨èä¿¡", {}).get("children", {})
        stats["reference_count"] = sum(1 for r in refs.values() if r.get("status") == "å·²æ”¶é›†")
        
        return stats
    
    def _save_analysis_result(self, project_id: str, framework: Dict, report: Dict):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºåˆ†æç»“æœè¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS material_analysis (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    project_id TEXT NOT NULL,
                    framework TEXT,
                    report TEXT,
                    analyzed_at TEXT,
                    UNIQUE(project_id)
                )
            """)
            
            cursor.execute("""
                INSERT OR REPLACE INTO material_analysis (project_id, framework, report, analyzed_at)
                VALUES (?, ?, ?, ?)
            """, (
                project_id,
                json.dumps(framework, ensure_ascii=False),
                json.dumps(report, ensure_ascii=False),
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def get_analysis_result(self, project_id: str) -> Optional[Dict]:
        """è·å–å·²ä¿å­˜çš„åˆ†æç»“æœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute(
                "SELECT * FROM material_analysis WHERE project_id = ?",
                (project_id,)
            )
            row = cursor.fetchone()
            conn.close()
            
            if row:
                return {
                    "framework": json.loads(row["framework"]),
                    "report": json.loads(row["report"]),
                    "analyzed_at": row["analyzed_at"]
                }
            return None
        except Exception as e:
            logger.error(f"è·å–åˆ†æç»“æœå¤±è´¥: {e}")
            return None
    
    def generate_mindmap_data(self, framework: Dict, project_name: str = "", materials: List[Dict] = None) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„æ€ç»´å¯¼å›¾æ•°æ®ç»“æ„"""
        
        def get_status(collected_count: int) -> str:
            if collected_count >= 2:
                return "success"
            elif collected_count > 0:
                return "warning"
            return "error"
        
        mindmap = {
            "id": "root",
            "label": project_name or "GTVç”³è¯·æ¡†æ¶",
            "type": "root",
            "children": []
        }
        
        # 1. é¢†åŸŸå®šä½
        domain_node = {
            "id": "domain",
            "label": "ğŸ¯ é¢†åŸŸå®šä½",
            "type": "category",
            "status": "info",
            "children": []
        }
        domain_data = framework.get("é¢†åŸŸå®šä½", {}).get("children", {})
        domain_items = [
            ("è¯„ä¼°æœºæ„", "Tech Nation"),
            ("ç»†åˆ†é¢†åŸŸ", domain_data.get("ç»†åˆ†é¢†åŸŸ", "å¾…ç¡®å®š")),
            ("å²—ä½å®šä½", domain_data.get("å²—ä½å®šä½", "å¾…ç¡®å®š")),
            ("æ ¸å¿ƒè®ºç‚¹", domain_data.get("æ ¸å¿ƒè®ºç‚¹", "å¾…ç¡®å®š"))
        ]
        for key, value in domain_items:
            domain_node["children"].append({
                "id": f"domain_{key}",
                "label": key,
                "type": "criteria",
                "details": value if value else "å¾…å¡«å†™"
            })
        mindmap["children"].append(domain_node)
        
        # 2. MCå¿…é€‰æ ‡å‡†ï¼ˆé€’äº¤ææ–™æ¡†æ¶ï¼‰
        mc_node = {
            "id": "mc",
            "label": "ğŸ“‹ MCå¿…é€‰æ ‡å‡† (Mandatory Criteria)",
            "type": "category",
            "children": []
        }
        
        mc_definitions = {
            "MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›": {
                "full_name": "MC1: äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›",
                "description": "é¢†å¯¼äº§å“å¯¼å‘çš„æ•°å­—ç§‘æŠ€å…¬å¸/äº§å“/å›¢é˜Ÿå¢é•¿çš„è¯æ®",
                "evidence_hints": ["æ¨èä¿¡", "äº§å“æè¿°", "æ–°é—»æŠ¥é“", "ä»£ç è´¡çŒ®"]
            },
            "MC2_å•†ä¸šå‘å±•": {
                "full_name": "MC2: å•†ä¸š/è¥é”€å‘å±•",
                "description": "é¢†å¯¼è¥é”€æˆ–ä¸šåŠ¡å¼€å‘ï¼Œå®ç°æ”¶å…¥/å®¢æˆ·å¢é•¿çš„è¯æ®",
                "evidence_hints": ["é”€å”®åˆåŒ", "å®¢æˆ·åè®®", "æ”¶å…¥å¢é•¿æ•°æ®"]
            },
            "MC3_éè¥åˆ©/ç¤¾ä¼šä¼ä¸š": {
                "full_name": "MC3: éè¥åˆ©ç»„ç»‡é¢†å¯¼",
                "description": "é¢†å¯¼æ•°å­—ç§‘æŠ€é¢†åŸŸéè¥åˆ©ç»„ç»‡æˆ–ç¤¾ä¼šä¼ä¸šçš„è¯æ®",
                "evidence_hints": ["è˜ä¹¦", "æ´»åŠ¨è¯æ˜", "åª’ä½“æŠ¥é“"]
            },
            "MC4_ä¸“å®¶è¯„å®¡è§’è‰²": {
                "full_name": "MC4: ä¸“å®¶è¯„å®¡è§’è‰²",
                "description": "æ‹…ä»»è¯„å®¡åŒè¡Œå·¥ä½œçš„é‡è¦ä¸“å®¶è§’è‰²çš„è¯æ®",
                "evidence_hints": ["è¯„å®¡é‚€è¯·", "è¯„å§”è¯ä¹¦", "ä¸“å®¶è˜ä¹¦"]
            }
        }
        
        mc_data = framework.get("MC_å¿…é€‰æ ‡å‡†", {}).get("children", {})
        for key, definition in mc_definitions.items():
            data = mc_data.get(key, {})
            collected = data.get("collected", [])
            status = get_status(len(collected))
            
            child = {
                "id": f"mc_{key}",
                "label": definition["full_name"],
                "type": "criteria",
                "status": status,
                "details": definition["description"],
                "fileCount": len(collected),
                "children": []
            }
            
            # æ·»åŠ è¯æ®æ–‡ä»¶
            for ev in collected[:8]:
                child["children"].append({
                    "id": f"mc_{key}_{ev.get('file_id', '')}",
                    "label": ev.get("file_name", "æœªçŸ¥æ–‡ä»¶")[:50],
                    "type": "file",
                    "details": f"åˆ†ç±»: {ev.get('category', '')}"
                })
            
            if len(collected) > 8:
                child["children"].append({
                    "id": f"mc_{key}_more",
                    "label": f"+{len(collected) - 8} æ›´å¤šæ–‡ä»¶",
                    "type": "file"
                })
            
            mc_node["children"].append(child)
        
        mindmap["children"].append(mc_node)
        
        # 3. OCå¯é€‰æ ‡å‡†
        oc_node = {
            "id": "oc",
            "label": "ğŸ“Š OCå¯é€‰æ ‡å‡† (Optional Criteria)",
            "type": "category",
            "children": []
        }
        
        oc_definitions = {
            "OC1_åˆ›æ–°": {
                "full_name": "OC1: åˆ›æ–°/äº§å“å¼€å‘",
                "description": "åˆ›æ–°/äº§å“å¼€å‘è¯æ®ï¼Œå¸‚åœºéªŒè¯åŠæ”¶å…¥è¯æ˜",
                "evidence_hints": ["ä¸“åˆ©è¯ä¹¦", "äº§å“æˆªå›¾", "è´¢åŠ¡æŠ¥è¡¨", "é‡‡è´­åˆåŒ"]
            },
            "OC2_è¡Œä¸šè®¤å¯": {
                "full_name": "OC2: è¡Œä¸šä¸“å®¶è®¤å¯",
                "description": "ä½œä¸ºé¢†åŸŸä¸“å®¶è·å¾—çš„è®¤å¯è¯æ®",
                "evidence_hints": ["æ¼”è®²é‚€è¯·", "åª’ä½“é‡‡è®¿", "è¡Œä¸šå¥–é¡¹", "è®ºæ–‡å‘è¡¨"]
            },
            "OC3_é‡å¤§è´¡çŒ®": {
                "full_name": "OC3: é‡å¤§æŠ€æœ¯/å•†ä¸šè´¡çŒ®",
                "description": "å¯¹æ•°å­—æŠ€æœ¯äº§å“çš„é‡å¤§æŠ€æœ¯ã€å•†ä¸šæˆ–åˆ›ä¸šè´¡çŒ®",
                "evidence_hints": ["ä»£ç è´¡çŒ®", "æŠ€æœ¯æ–‡æ¡£", "æŠ•èµ„å†³ç­–", "å•†ä¸šæˆæœ"]
            },
            "OC4_å­¦æœ¯è´¡çŒ®": {
                "full_name": "OC4: å­¦æœ¯è´¡çŒ®",
                "description": "åœ¨æ•°å­—æŠ€æœ¯é¢†åŸŸçš„å­¦æœ¯è´¡çŒ®",
                "evidence_hints": ["è®ºæ–‡", "å¼•ç”¨æ•°æ®", "å­¦æœ¯ä¼šè®®", "ç ”ç©¶é¡¹ç›®"]
            }
        }
        
        oc_data = framework.get("OC_å¯é€‰æ ‡å‡†", {}).get("children", {})
        for key, definition in oc_definitions.items():
            data = oc_data.get(key, {})
            collected = data.get("collected", [])
            status = get_status(len(collected))
            
            child = {
                "id": f"oc_{key}",
                "label": definition["full_name"],
                "type": "criteria",
                "status": status,
                "details": definition["description"],
                "fileCount": len(collected),
                "children": []
            }
            
            for ev in collected[:8]:
                child["children"].append({
                    "id": f"oc_{key}_{ev.get('file_id', '')}",
                    "label": ev.get("file_name", "æœªçŸ¥æ–‡ä»¶")[:50],
                    "type": "file",
                    "details": f"åˆ†ç±»: {ev.get('category', '')}"
                })
            
            if len(collected) > 8:
                child["children"].append({
                    "id": f"oc_{key}_more",
                    "label": f"+{len(collected) - 8} æ›´å¤šæ–‡ä»¶",
                    "type": "file"
                })
            
            oc_node["children"].append(child)
        
        mindmap["children"].append(oc_node)
        
        # 4. æ¨èä¿¡
        ref_node = {
            "id": "reference",
            "label": "âœ‰ï¸ ä¸‰å°æ¨èä¿¡",
            "type": "category",
            "children": []
        }
        ref_data = framework.get("æ¨èä¿¡", {}).get("children", {})
        
        recommenders = [
            ("æ¨èäºº1", "è¡Œä¸šä¸“å®¶æ¨è"),
            ("æ¨èäºº2", "å­¦æœ¯/æŠ€æœ¯æ¨è"),
            ("æ¨èäºº3", "å•†ä¸š/åˆä½œæ¨è")
        ]
        
        for key, hint in recommenders:
            data = ref_data.get(key, {})
            status = "success" if data.get("status") == "å·²æ”¶é›†" else "error"
            files = data.get("files", [])
            
            ref_child = {
                "id": f"ref_{key}",
                "label": key,
                "type": "criteria",
                "status": status,
                "details": f"{hint} - {data.get('name', 'å¾…ç¡®å®š')}",
                "children": []
            }
            
            if files:
                for f in files[:3]:
                    ref_child["children"].append({
                        "id": f"ref_{key}_{f}",
                        "label": f,
                        "type": "file"
                    })
            
            ref_node["children"].append(ref_child)
        
        mindmap["children"].append(ref_node)
        
        return mindmap


# æµ‹è¯•
if __name__ == "__main__":
    analyzer = MaterialAnalyzer()
    result = analyzer.analyze_project_materials("TEST001")
    print(json.dumps(result, ensure_ascii=False, indent=2))
