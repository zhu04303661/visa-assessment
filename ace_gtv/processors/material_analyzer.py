#!/usr/bin/env python3
"""
GTVææ–™æ™ºèƒ½åˆ†æå™¨
åˆ†æå®¢æˆ·æäº¤çš„æ‰€æœ‰ææ–™ï¼Œç”ŸæˆGTVé€’äº¤æ¡†æ¶è„‘å›¾
"""

import os
import json
import sqlite3
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path

from utils.logger_config import setup_module_logger

logger = setup_module_logger("material_analyzer", os.getenv("LOG_LEVEL", "INFO"))

# GTVé€’äº¤æ¡†æ¶æ¨¡æ¿
GTV_FRAMEWORK = {
    "é¢†åŸŸå®šä½": {
        "id": "domain",
        "description": "ç¡®å®šç”³è¯·äººçš„ä¸“ä¸šé¢†åŸŸå’Œç”³è¯·ç±»åˆ«",
        "children": {
            "è¯„ä¼°æœºæ„": "Tech Nation",
            "ç»†åˆ†é¢†åŸŸ": "",
            "å²—ä½å®šä½": "",
            "æ ¸å¿ƒè®ºç‚¹": ""
        }
    },
    "MC_å¿…é€‰æ ‡å‡†": {
        "id": "mc",
        "description": "Mandatory Criteria - å¿…é¡»æ»¡è¶³çš„æ ‡å‡†",
        "children": {
            "MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›": {
                "description": "é¢†å¯¼äº§å“ã€å›¢é˜Ÿæˆ–å…¬å¸å¢é•¿çš„è¯æ®",
                "evidence_types": ["æ¨èä¿¡", "äº§å“æè¿°", "æ–°é—»æŠ¥é“", "ä»£ç è´¡çŒ®"],
                "collected": []
            },
            "MC2_å•†ä¸šå‘å±•": {
                "description": "å•†ä¸šå‘å±•ã€è¥é”€ã€æ”¶å…¥å¢é•¿çš„è¯æ®",
                "evidence_types": ["é”€å”®åˆåŒ", "å®¢æˆ·åè®®", "æ”¶å…¥è¯æ˜"],
                "collected": []
            },
            "MC3_éè¥åˆ©/ç¤¾ä¼šä¼ä¸š": {
                "description": "é¢†å¯¼æ•°å­—ç§‘æŠ€é¢†åŸŸéè¥åˆ©ç»„ç»‡çš„è¯æ®",
                "evidence_types": ["è˜ä¹¦", "æ´»åŠ¨è¯æ˜", "åª’ä½“æŠ¥é“"],
                "collected": []
            },
            "MC4_ä¸“å®¶è¯„å®¡è§’è‰²": {
                "description": "è¯„å®¡åŒè¡Œå·¥ä½œçš„ä¸“å®¶è§’è‰²è¯æ®",
                "evidence_types": ["è¯„å®¡é‚€è¯·", "è¯„å§”è¯ä¹¦", "ä¸“å®¶è˜ä¹¦"],
                "collected": []
            }
        }
    },
    "OC_å¯é€‰æ ‡å‡†": {
        "id": "oc",
        "description": "Optional Criteria - è‡³å°‘æ»¡è¶³2é¡¹",
        "children": {
            "OC1_åˆ›æ–°": {
                "description": "åˆ›æ–°/äº§å“å¼€å‘åŠå¸‚åœºéªŒè¯è¯æ®",
                "evidence_types": ["ä¸“åˆ©è¯ä¹¦", "äº§å“æˆªå›¾", "è´¢åŠ¡æŠ¥è¡¨", "é‡‡è´­åˆåŒ"],
                "collected": []
            },
            "OC2_è¡Œä¸šè®¤å¯": {
                "description": "ä½œä¸ºé¢†åŸŸä¸“å®¶çš„è®¤å¯è¯æ®",
                "evidence_types": ["æ¼”è®²é‚€è¯·", "åª’ä½“é‡‡è®¿", "è¡Œä¸šå¥–é¡¹", "è®ºæ–‡å‘è¡¨"],
                "collected": []
            },
            "OC3_é‡å¤§è´¡çŒ®": {
                "description": "å¯¹æ•°å­—æŠ€æœ¯äº§å“çš„é‡å¤§æŠ€æœ¯è´¡çŒ®",
                "evidence_types": ["ä»£ç è´¡çŒ®", "æŠ€æœ¯æ–‡æ¡£", "ç³»ç»Ÿæ¶æ„", "ä¸“åˆ©"],
                "collected": []
            },
            "OC4_å­¦æœ¯è´¡çŒ®": {
                "description": "åœ¨æ•°å­—æŠ€æœ¯é¢†åŸŸçš„å­¦æœ¯è´¡çŒ®",
                "evidence_types": ["è®ºæ–‡", "å¼•ç”¨æ•°æ®", "å­¦æœ¯ä¼šè®®", "ç ”ç©¶é¡¹ç›®"],
                "collected": []
            }
        }
    },
    "æ¨èä¿¡": {
        "id": "reference",
        "description": "3å°æ¨èä¿¡",
        "children": {
            "æ¨èäºº1": {"name": "", "title": "", "relationship": "", "status": ""},
            "æ¨èäºº2": {"name": "", "title": "", "relationship": "", "status": ""},
            "æ¨èäºº3": {"name": "", "title": "", "relationship": "", "status": ""}
        }
    },
    "ä¸ªäººé™ˆè¿°": {
        "id": "statement",
        "description": "Personal Statement",
        "content": ""
    }
}


class MaterialAnalyzer:
    """ææ–™åˆ†æå™¨"""
    
    def __init__(self, db_path: str = "copywriting.db"):
        self.db_path = db_path
        self.llm_client = None
        self._init_llm()
        logger.info("ææ–™åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_llm(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
            
            api_key = os.getenv("ENNCLOUD_API_KEY") or os.getenv("OPENAI_API_KEY")
            base_url = os.getenv("ENNCLOUD_BASE_URL") or os.getenv("OPENAI_BASE_URL")
            
            if api_key and base_url:
                self.llm_client = OpenAI(api_key=api_key, base_url=base_url)
                self.model = os.getenv("ENNCLOUD_MODEL", "glm-4.6-no-think")
                logger.info(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {base_url}")
            else:
                logger.warning("æœªé…ç½®LLMï¼Œå°†ä½¿ç”¨è§„åˆ™åˆ†æ")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–LLMå¤±è´¥: {e}")
    
    def analyze_project_materials(self, project_id: str) -> Dict[str, Any]:
        """
        åˆ†æé¡¹ç›®çš„æ‰€æœ‰ææ–™ï¼Œç”ŸæˆGTVæ¡†æ¶
        """
        try:
            # 1. è·å–é¡¹ç›®ä¿¡æ¯
            project_info = self._get_project_info(project_id)
            if not project_info:
                return {"success": False, "error": "é¡¹ç›®ä¸å­˜åœ¨"}
            
            # 2. è·å–æ‰€æœ‰å·²æ”¶é›†çš„ææ–™
            materials = self._get_collected_materials(project_id)
            
            # 3. è·å–æ‰€æœ‰è¡¨å•æ•°æ®
            forms = self._get_form_data(project_id)
            
            # 4. æå–ææ–™å†…å®¹
            material_contents = self._extract_material_contents(materials)
            
            # 5. ä½¿ç”¨AIåˆ†æææ–™å¹¶åŒ¹é…åˆ°GTVæ¡†æ¶
            framework = self._analyze_and_map_to_framework(
                project_info, materials, forms, material_contents
            )
            
            # 6. ç”Ÿæˆåˆ†ææŠ¥å‘Š
            report = self._generate_analysis_report(framework)
            
            # 7. ä¿å­˜åˆ†æç»“æœ
            self._save_analysis_result(project_id, framework, report)
            
            return {
                "success": True,
                "data": {
                    "project_id": project_id,
                    "project_name": project_info.get("client_name", ""),
                    "framework": framework,
                    "report": report,
                    "statistics": self._calculate_statistics(framework),
                    "analyzed_at": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logger.error(f"åˆ†æé¡¹ç›®ææ–™å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def _get_project_info(self, project_id: str) -> Optional[Dict]:
        """è·å–é¡¹ç›®ä¿¡æ¯"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # å°è¯•ä¸åŒçš„è¡¨å
            for table in ["copywriting_projects", "projects"]:
                try:
                    cursor.execute(
                        f"SELECT * FROM {table} WHERE project_id = ?",
                        (project_id,)
                    )
                    row = cursor.fetchone()
                    if row:
                        conn.close()
                        return dict(row)
                except:
                    continue
            
            conn.close()
            return None
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _get_collected_materials(self, project_id: str) -> List[Dict]:
        """è·å–æ‰€æœ‰å·²æ”¶é›†çš„ææ–™"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT mf.*, mc.category_id, mc.item_id, mc.status
                FROM material_files mf
                LEFT JOIN material_collection mc ON mf.project_id = mc.project_id 
                    AND mf.category_id = mc.category_id AND mf.item_id = mc.item_id
                WHERE mf.project_id = ?
                ORDER BY mf.uploaded_at DESC
            """, (project_id,))
            
            rows = cursor.fetchall()
            conn.close()
            
            return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"è·å–ææ–™æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _get_form_data(self, project_id: str) -> List[Dict]:
        """è·å–æ‰€æœ‰è¡¨å•æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT * FROM collection_forms
                WHERE project_id = ?
            """, (project_id,))
            
            rows = cursor.fetchall()
            conn.close()
            
            result = []
            for row in rows:
                data = dict(row)
                if data.get("form_data"):
                    data["form_data"] = json.loads(data["form_data"])
                result.append(data)
            
            return result
        except Exception as e:
            logger.error(f"è·å–è¡¨å•æ•°æ®å¤±è´¥: {e}")
            return []
    
    def _extract_material_contents(self, materials: List[Dict]) -> Dict[str, str]:
        """æå–ææ–™æ–‡ä»¶çš„æ–‡æœ¬å†…å®¹"""
        contents = {}
        
        for material in materials:
            file_path = material.get("file_path")
            file_type = material.get("file_type", "").lower()
            file_id = material.get("id")
            
            if not file_path or not os.path.exists(file_path):
                continue
            
            try:
                content = None
                
                if file_type == "txt":
                    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                        content = f.read()
                
                elif file_type == "docx":
                    try:
                        from docx import Document
                        doc = Document(file_path)
                        content = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
                    except:
                        pass
                
                elif file_type == "pdf":
                    try:
                        from pdfminer.high_level import extract_text
                        content = extract_text(file_path)
                    except:
                        pass
                
                if content and len(content) > 50:
                    # é™åˆ¶å†…å®¹é•¿åº¦
                    contents[str(file_id)] = content[:5000]
                    
            except Exception as e:
                logger.warning(f"æå–æ–‡ä»¶å†…å®¹å¤±è´¥ {file_path}: {e}")
        
        return contents
    
    def _analyze_and_map_to_framework(
        self, 
        project_info: Dict, 
        materials: List[Dict], 
        forms: List[Dict],
        contents: Dict[str, str]
    ) -> Dict:
        """åˆ†æææ–™å¹¶æ˜ å°„åˆ°GTVæ¡†æ¶"""
        
        import copy
        framework = copy.deepcopy(GTV_FRAMEWORK)
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡ææ–™
        category_materials = {}
        for m in materials:
            cat_id = m.get("category_id", "unknown")
            if cat_id not in category_materials:
                category_materials[cat_id] = []
            category_materials[cat_id].append(m)
        
        # æ˜ å°„åˆ°æ¡†æ¶
        # folder_1: ä¸ªäººèµ„æ–™ -> åŸºæœ¬ä¿¡æ¯
        # folder_2: ç°é›‡ä¸» -> MC1/MC2
        # folder_3: è¿‡å¾€é›‡ä¸» -> MC1/MC2/MC3
        # folder_4: é‡å¤§ä¸šç»© -> OC1/OC2/OC3/OC4
        # folder_5: é¡¹ç›®è¯æ® -> MC1/OC1/OC3
        # folder_6: æ¨èäºº -> æ¨èä¿¡
        
        # æå–æ¨èäººä¿¡æ¯
        if "folder_6" in category_materials:
            for m in category_materials["folder_6"]:
                item_id = m.get("item_id", "")
                if "recommender_1" in item_id:
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº1"]["status"] = "å·²æ”¶é›†"
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº1"]["files"] = [m.get("file_name")]
                elif "recommender_2" in item_id:
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº2"]["status"] = "å·²æ”¶é›†"
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº2"]["files"] = [m.get("file_name")]
                elif "recommender_3" in item_id:
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº3"]["status"] = "å·²æ”¶é›†"
                    framework["æ¨èä¿¡"]["children"]["æ¨èäºº3"]["files"] = [m.get("file_name")]
        
        # å¤„ç†ä¸šç»©è¯æ®
        if "folder_4" in category_materials:
            for m in category_materials["folder_4"]:
                item_id = m.get("item_id", "")
                file_name = m.get("file_name", "")
                
                evidence = {
                    "file_name": file_name,
                    "file_id": m.get("id"),
                    "category": item_id
                }
                
                # ä¸“åˆ© -> OC1/OC3
                if "patent" in item_id or "ä¸“åˆ©" in file_name:
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC1_åˆ›æ–°"]["collected"].append(evidence)
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC3_é‡å¤§è´¡çŒ®"]["collected"].append(evidence)
                
                # è®ºæ–‡ -> OC2/OC4
                elif "publication" in item_id or "è®ºæ–‡" in file_name:
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC2_è¡Œä¸šè®¤å¯"]["collected"].append(evidence)
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC4_å­¦æœ¯è´¡çŒ®"]["collected"].append(evidence)
                
                # å¥–é¡¹ -> OC2
                elif "award" in item_id or "å¥–" in file_name:
                    framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC2_è¡Œä¸šè®¤å¯"]["collected"].append(evidence)
                
                # è´¡çŒ®è¡¨ -> MC1
                elif "contribution" in item_id:
                    framework["MC_å¿…é€‰æ ‡å‡†"]["children"]["MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›"]["collected"].append(evidence)
        
        # å¤„ç†é¡¹ç›®è¯æ®
        if "folder_5" in category_materials:
            for m in category_materials["folder_5"]:
                evidence = {
                    "file_name": m.get("file_name", ""),
                    "file_id": m.get("id"),
                    "category": m.get("item_id", "")
                }
                framework["MC_å¿…é€‰æ ‡å‡†"]["children"]["MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›"]["collected"].append(evidence)
                framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC1_åˆ›æ–°"]["collected"].append(evidence)
        
        # å¤„ç†é›‡ä¸»ææ–™
        for folder in ["folder_2", "folder_3"]:
            if folder in category_materials:
                for m in category_materials[folder]:
                    evidence = {
                        "file_name": m.get("file_name", ""),
                        "file_id": m.get("id"),
                        "category": m.get("item_id", "")
                    }
                    item_id = m.get("item_id", "")
                    
                    if "employment" in item_id or "å°±èŒ" in m.get("file_name", ""):
                        framework["MC_å¿…é€‰æ ‡å‡†"]["children"]["MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›"]["collected"].append(evidence)
                    elif "award" in item_id:
                        framework["OC_å¯é€‰æ ‡å‡†"]["children"]["OC2_è¡Œä¸šè®¤å¯"]["collected"].append(evidence)
        
        # ä½¿ç”¨AIè¿›è¡Œæ›´æ·±å…¥çš„åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.llm_client and contents:
            framework = self._ai_enhanced_analysis(framework, contents, project_info)
        
        return framework
    
    def _ai_enhanced_analysis(self, framework: Dict, contents: Dict, project_info: Dict) -> Dict:
        """ä½¿ç”¨AIå¢å¼ºåˆ†æ"""
        try:
            # æ„å»ºæç¤º
            content_summary = "\n\n".join([
                f"æ–‡ä»¶{fid}å†…å®¹æ‘˜è¦:\n{content[:1000]}..."
                for fid, content in list(contents.items())[:5]
            ])
            
            prompt = f"""
åˆ†æä»¥ä¸‹GTVç­¾è¯ç”³è¯·ææ–™ï¼Œæå–å…³é”®ä¿¡æ¯ï¼š

ç”³è¯·äººï¼š{project_info.get('client_name', 'æœªçŸ¥')}

ææ–™å†…å®¹æ‘˜è¦ï¼š
{content_summary}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
1. ç”³è¯·äººçš„ä¸“ä¸šé¢†åŸŸï¼ˆdomainï¼‰
2. ä¸»è¦å·¥ä½œæˆå°±ï¼ˆachievementsï¼‰- åˆ—è¡¨
3. æŠ€æœ¯è´¡çŒ®ï¼ˆtechnical_contributionsï¼‰- åˆ—è¡¨
4. é¢†å¯¼åŠ›è¯æ®ï¼ˆleadershipï¼‰- åˆ—è¡¨
5. åˆ›æ–°æˆæœï¼ˆinnovationsï¼‰- åˆ—è¡¨
6. å»ºè®®çš„ç”³è¯·ç­–ç•¥ï¼ˆstrategyï¼‰

è¿”å›JSONæ ¼å¼ã€‚
"""
            
            response = self.llm_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000
            )
            
            ai_result = response.choices[0].message.content
            
            # å°è¯•è§£æJSON
            try:
                import re
                json_match = re.search(r'\{[\s\S]*\}', ai_result)
                if json_match:
                    ai_data = json.loads(json_match.group())
                    
                    # æ›´æ–°æ¡†æ¶
                    if ai_data.get("domain"):
                        framework["é¢†åŸŸå®šä½"]["children"]["ç»†åˆ†é¢†åŸŸ"] = ai_data["domain"]
                    
                    if ai_data.get("strategy"):
                        framework["åˆ†æå»ºè®®"] = {
                            "id": "suggestion",
                            "content": ai_data["strategy"]
                        }
            except:
                pass
                
        except Exception as e:
            logger.warning(f"AIå¢å¼ºåˆ†æå¤±è´¥: {e}")
        
        return framework
    
    def _generate_analysis_report(self, framework: Dict) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = {
            "summary": "",
            "mc_status": {},
            "oc_status": {},
            "recommendations": [],
            "missing_items": [],
            "strength_points": []
        }
        
        # åˆ†æMCçŠ¶æ€
        mc = framework.get("MC_å¿…é€‰æ ‡å‡†", {}).get("children", {})
        for mc_key, mc_data in mc.items():
            collected = mc_data.get("collected", [])
            report["mc_status"][mc_key] = {
                "count": len(collected),
                "status": "å……è¶³" if len(collected) >= 2 else ("ä¸è¶³" if len(collected) == 0 else "åŸºæœ¬"),
                "files": [c.get("file_name") for c in collected[:5]]
            }
        
        # åˆ†æOCçŠ¶æ€
        oc = framework.get("OC_å¯é€‰æ ‡å‡†", {}).get("children", {})
        oc_satisfied = 0
        for oc_key, oc_data in oc.items():
            collected = oc_data.get("collected", [])
            status = "å……è¶³" if len(collected) >= 2 else ("ä¸è¶³" if len(collected) == 0 else "åŸºæœ¬")
            if len(collected) >= 2:
                oc_satisfied += 1
            report["oc_status"][oc_key] = {
                "count": len(collected),
                "status": status,
                "files": [c.get("file_name") for c in collected[:5]]
            }
        
        # åˆ†ææ¨èä¿¡
        refs = framework.get("æ¨èä¿¡", {}).get("children", {})
        ref_count = sum(1 for r in refs.values() if r.get("status") == "å·²æ”¶é›†")
        
        # ç”Ÿæˆå»ºè®®
        if ref_count < 3:
            report["missing_items"].append(f"æ¨èä¿¡è¿˜éœ€è¦{3-ref_count}å°")
        
        if oc_satisfied < 2:
            report["missing_items"].append(f"å¯é€‰æ ‡å‡†(OC)éœ€è¦è‡³å°‘æ»¡è¶³2é¡¹ï¼Œå½“å‰ä»…æ»¡è¶³{oc_satisfied}é¡¹")
        
        # æ€»ç»“
        mc_ok = any(s["count"] >= 2 for s in report["mc_status"].values())
        report["summary"] = f"""
ææ–™åˆ†æå®Œæˆã€‚
- å¿…é€‰æ ‡å‡†(MC)ï¼š{"åŸºæœ¬æ»¡è¶³" if mc_ok else "éœ€è¦è¡¥å……ææ–™"}
- å¯é€‰æ ‡å‡†(OC)ï¼šæ»¡è¶³{oc_satisfied}/4é¡¹ï¼ˆéœ€è‡³å°‘2é¡¹ï¼‰
- æ¨èä¿¡ï¼šå·²æ”¶é›†{ref_count}/3å°
        """.strip()
        
        return report
    
    def _calculate_statistics(self, framework: Dict) -> Dict:
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        stats = {
            "total_files": 0,
            "mc_coverage": 0,
            "oc_coverage": 0,
            "reference_count": 0
        }
        
        # MCç»Ÿè®¡
        mc = framework.get("MC_å¿…é€‰æ ‡å‡†", {}).get("children", {})
        mc_with_evidence = sum(1 for v in mc.values() if len(v.get("collected", [])) > 0)
        stats["mc_coverage"] = round(mc_with_evidence / len(mc) * 100) if mc else 0
        
        for v in mc.values():
            stats["total_files"] += len(v.get("collected", []))
        
        # OCç»Ÿè®¡
        oc = framework.get("OC_å¯é€‰æ ‡å‡†", {}).get("children", {})
        oc_with_evidence = sum(1 for v in oc.values() if len(v.get("collected", [])) >= 2)
        stats["oc_coverage"] = round(oc_with_evidence / 2 * 100)  # éœ€è¦æ»¡è¶³2é¡¹
        stats["oc_coverage"] = min(stats["oc_coverage"], 100)
        
        for v in oc.values():
            stats["total_files"] += len(v.get("collected", []))
        
        # æ¨èä¿¡
        refs = framework.get("æ¨èä¿¡", {}).get("children", {})
        stats["reference_count"] = sum(1 for r in refs.values() if r.get("status") == "å·²æ”¶é›†")
        
        return stats
    
    def _save_analysis_result(self, project_id: str, framework: Dict, report: Dict):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºåˆ†æç»“æœè¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS material_analysis (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    project_id TEXT NOT NULL,
                    framework TEXT,
                    report TEXT,
                    analyzed_at TEXT,
                    UNIQUE(project_id)
                )
            """)
            
            cursor.execute("""
                INSERT OR REPLACE INTO material_analysis (project_id, framework, report, analyzed_at)
                VALUES (?, ?, ?, ?)
            """, (
                project_id,
                json.dumps(framework, ensure_ascii=False),
                json.dumps(report, ensure_ascii=False),
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def get_analysis_result(self, project_id: str) -> Optional[Dict]:
        """è·å–å·²ä¿å­˜çš„åˆ†æç»“æœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute(
                "SELECT * FROM material_analysis WHERE project_id = ?",
                (project_id,)
            )
            row = cursor.fetchone()
            conn.close()
            
            if row:
                return {
                    "framework": json.loads(row["framework"]),
                    "report": json.loads(row["report"]),
                    "analyzed_at": row["analyzed_at"]
                }
            return None
        except Exception as e:
            logger.error(f"è·å–åˆ†æç»“æœå¤±è´¥: {e}")
            return None
    
    def generate_client_profile_map(self, project_id: str, context: str) -> Dict[str, Any]:
        """
        åŸºäºæå–çš„å†…å®¹ç”Ÿæˆå®¢æˆ·ä¿¡æ¯è„‰ç»œå›¾
        
        Args:
            project_id: é¡¹ç›®ID
            context: å¸¦å‡ºå¤„æ ‡æ³¨çš„ä¸Šä¸‹æ–‡å†…å®¹
            
        Returns:
            å®¢æˆ·ä¿¡æ¯è„‰ç»œå›¾æ•°æ®
        """
        try:
            if not context or len(context.strip()) < 100:
                return {"success": False, "error": "ä¸Šä¸‹æ–‡å†…å®¹ä¸è¶³ï¼Œè¯·å…ˆä¸Šä¼ å¹¶æå–ææ–™"}
            
            # è·å–é¡¹ç›®ä¿¡æ¯
            project_info = self._get_project_info(project_id)
            client_name = project_info.get("client_name", "ç”³è¯·äºº") if project_info else "ç”³è¯·äºº"
            
            # ä½¿ç”¨AIåˆ†æç”Ÿæˆä¿¡æ¯è„‰ç»œå›¾
            profile_data = self._ai_generate_profile_map(context, client_name)
            
            if profile_data:
                # ç”Ÿæˆæ€ç»´å¯¼å›¾å¯è§†åŒ–æ•°æ®
                mindmap_data = self._generate_profile_mindmap(profile_data, client_name)
                profile_data["mindmap_data"] = mindmap_data
                
                return {
                    "success": True,
                    "data": profile_data
                }
            else:
                # å›é€€åˆ°è§„åˆ™åˆ†æ
                profile_data = self._rule_based_profile_analysis(context, client_name)
                mindmap_data = self._generate_profile_mindmap(profile_data, client_name)
                profile_data["mindmap_data"] = mindmap_data
                
                return {
                    "success": True,
                    "data": profile_data
                }
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆå®¢æˆ·ä¿¡æ¯è„‰ç»œå›¾å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def _ai_generate_profile_map(self, context: str, client_name: str) -> Optional[Dict]:
        """ä½¿ç”¨AIç”Ÿæˆå®¢æˆ·ä¿¡æ¯è„‰ç»œå›¾"""
        if not self.llm_client:
            return None
        
        try:
            # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
            max_context = context[:20000] if len(context) > 20000 else context
            
            prompt = f"""
è¯·ä»”ç»†åˆ†æä»¥ä¸‹ç”³è¯·äººçš„ææ–™å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„å®¢æˆ·ä¿¡æ¯è„‰ç»œå›¾ã€‚
è¯·ä¿ç•™æ¯ä¸ªä¿¡æ¯ç‚¹çš„å‡ºå¤„æ ‡æ³¨ï¼ˆå¦‚[æ¥æº: xxx]ï¼‰ã€‚

ç”³è¯·äººå§“åï¼š{client_name}

ææ–™å†…å®¹ï¼š
{max_context}

è¯·ä»¥JSONæ ¼å¼è¿”å›ä»¥ä¸‹ç»“æ„çš„ä¿¡æ¯è„‰ç»œå›¾ï¼š

{{
    "personal_info": {{
        "name": "å§“å",
        "name_en": "è‹±æ–‡å",
        "nationality": "å›½ç±",
        "current_location": "å½“å‰æ‰€åœ¨åœ°",
        "contact": "è”ç³»æ–¹å¼",
        "source": "[æ¥æºä¿¡æ¯]"
    }},
    "education": [
        {{
            "degree": "å­¦ä½",
            "major": "ä¸“ä¸š",
            "school": "å­¦æ ¡åç§°",
            "school_en": "å­¦æ ¡è‹±æ–‡å",
            "period": "æ—¶é—´æ®µ",
            "highlights": ["äº®ç‚¹1", "äº®ç‚¹2"],
            "source": "[æ¥æºä¿¡æ¯]"
        }}
    ],
    "career_timeline": [
        {{
            "company": "å…¬å¸åç§°",
            "company_en": "å…¬å¸è‹±æ–‡å",
            "role": "èŒä½",
            "role_en": "è‹±æ–‡èŒä½",
            "period": "æ—¶é—´æ®µ",
            "department": "éƒ¨é—¨",
            "responsibilities": ["èŒè´£1", "èŒè´£2"],
            "highlights": ["äº®ç‚¹1", "äº®ç‚¹2"],
            "source": "[æ¥æºä¿¡æ¯]"
        }}
    ],
    "technical_expertise": [
        {{
            "domain": "æŠ€æœ¯é¢†åŸŸ",
            "skills": ["æŠ€èƒ½1", "æŠ€èƒ½2"],
            "proficiency": "ç†Ÿç»ƒç¨‹åº¦",
            "evidence": ["è¯æ®1", "è¯æ®2"],
            "source": "[æ¥æºä¿¡æ¯]"
        }}
    ],
    "achievements": [
        {{
            "type": "æˆå°±ç±»å‹ï¼ˆä¸“åˆ©/è®ºæ–‡/å¥–é¡¹/é¡¹ç›®/å¼€æºè´¡çŒ®ç­‰ï¼‰",
            "title": "æˆå°±æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "date": "æ—¥æœŸ",
            "impact": "å½±å“åŠ›/æ•°æ®",
            "source": "[æ¥æºä¿¡æ¯]"
        }}
    ],
    "connections": {{
        "recommenders": [
            {{
                "name": "æ¨èäººå§“å",
                "title": "èŒä½",
                "organization": "æœºæ„",
                "relationship": "ä¸ç”³è¯·äººå…³ç³»",
                "source": "[æ¥æºä¿¡æ¯]"
            }}
        ],
        "industry_contacts": [
            {{
                "name": "è”ç³»äººå§“å",
                "context": "è®¤è¯†èƒŒæ™¯",
                "source": "[æ¥æºä¿¡æ¯]"
            }}
        ]
    }},
    "raw_analysis": {{
        "key_strengths": ["æ ¸å¿ƒä¼˜åŠ¿1", "æ ¸å¿ƒä¼˜åŠ¿2"],
        "unique_selling_points": ["ç‹¬ç‰¹å–ç‚¹1", "ç‹¬ç‰¹å–ç‚¹2"],
        "potential_gaps": ["æ½œåœ¨ä¸è¶³1"],
        "gtv_pathway_suggestion": "å»ºè®®çš„ç”³è¯·è·¯å¾„ï¼ˆExceptional Talent/Promiseï¼‰"
    }}
}}

è¯·ç¡®ä¿ï¼š
1. å°½å¯èƒ½å®Œæ•´åœ°æå–æ‰€æœ‰ä¿¡æ¯
2. ä¿ç•™åŸå§‹å‡ºå¤„æ ‡æ³¨
3. æŒ‰æ—¶é—´é¡ºåºæ’åˆ—èŒä¸šç»å†ï¼ˆæœ€è¿‘çš„åœ¨å‰ï¼‰
4. çªå‡ºå¯¹GTVç”³è¯·æœ‰ä»·å€¼çš„ä¿¡æ¯
5. å¦‚æœæŸé¡¹ä¿¡æ¯ä¸æ˜ç¡®ï¼Œå¯ä»¥æ ‡æ³¨"å¾…ç¡®è®¤"

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
            
            response = self.llm_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=4000,
                temperature=0.3
            )
            
            result_text = response.choices[0].message.content
            
            # è§£æJSON
            import re
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                profile_data = json.loads(json_match.group())
                logger.info(f"AIæˆåŠŸç”Ÿæˆå®¢æˆ·ä¿¡æ¯è„‰ç»œå›¾")
                return profile_data
            
            return None
            
        except Exception as e:
            logger.error(f"AIç”Ÿæˆä¿¡æ¯è„‰ç»œå›¾å¤±è´¥: {e}")
            return None
    
    def _rule_based_profile_analysis(self, context: str, client_name: str) -> Dict:
        """åŸºäºè§„åˆ™çš„ä¿¡æ¯è„‰ç»œå›¾åˆ†æï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        profile = {
            "personal_info": {
                "name": client_name,
                "source": "é¡¹ç›®ä¿¡æ¯"
            },
            "education": [],
            "career_timeline": [],
            "technical_expertise": [],
            "achievements": [],
            "connections": {
                "recommenders": [],
                "industry_contacts": []
            },
            "raw_analysis": {
                "key_strengths": [],
                "unique_selling_points": [],
                "potential_gaps": ["éœ€è¦AIåˆ†ææˆ–æ‰‹åŠ¨è¡¥å……è¯¦ç»†ä¿¡æ¯"],
                "gtv_pathway_suggestion": "å¾…ç¡®å®š"
            }
        }
        
        # ç®€å•çš„å…³é”®è¯æå–
        lines = context.split('\n')
        current_source = ""
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æå–æ¥æºæ ‡æ³¨
            if "[æ¥æº:" in line:
                import re
                source_match = re.search(r'\[æ¥æº:[^\]]+\]', line)
                if source_match:
                    current_source = source_match.group()
            
            # æ£€æµ‹æ•™è‚²ä¿¡æ¯
            edu_keywords = ["å¤§å­¦", "å­¦é™¢", "university", "college", "ç¡•å£«", "åšå£«", "å­¦å£«", "Bachelor", "Master", "PhD"]
            if any(kw in line.lower() for kw in [k.lower() for k in edu_keywords]):
                profile["education"].append({
                    "description": line[:200],
                    "source": current_source
                })
            
            # æ£€æµ‹å·¥ä½œç»å†
            work_keywords = ["å…¬å¸", "é›†å›¢", "Corp", "Inc", "Ltd", "æœ‰é™å…¬å¸", "ç»ç†", "å·¥ç¨‹å¸ˆ", "æ€»ç›‘", "CEO", "CTO"]
            if any(kw in line for kw in work_keywords):
                profile["career_timeline"].append({
                    "description": line[:200],
                    "source": current_source
                })
            
            # æ£€æµ‹æˆå°±
            achievement_keywords = ["ä¸“åˆ©", "è®ºæ–‡", "å¥–", "å‘è¡¨", "å‘æ˜", "Patent", "Paper", "Award", "Publication"]
            if any(kw in line for kw in achievement_keywords):
                profile["achievements"].append({
                    "description": line[:200],
                    "source": current_source
                })
        
        return profile
    
    def _generate_profile_mindmap(self, profile_data: Dict, client_name: str) -> Dict:
        """ç”Ÿæˆä¿¡æ¯è„‰ç»œå›¾çš„æ€ç»´å¯¼å›¾å¯è§†åŒ–æ•°æ®"""
        mindmap = {
            "id": "profile_root",
            "label": f"ğŸ“‹ {client_name} - ä¿¡æ¯è„‰ç»œå›¾",
            "type": "root",
            "children": []
        }
        
        # 1. ä¸ªäººä¿¡æ¯
        personal = profile_data.get("personal_info", {})
        if personal:
            personal_node = {
                "id": "personal",
                "label": "ğŸ‘¤ ä¸ªäººä¿¡æ¯",
                "type": "category",
                "status": "info",
                "children": []
            }
            for key, value in personal.items():
                if key != "source" and value:
                    personal_node["children"].append({
                        "id": f"personal_{key}",
                        "label": f"{key}: {value}",
                        "type": "item"
                    })
            if personal_node["children"]:
                mindmap["children"].append(personal_node)
        
        # 2. æ•™è‚²èƒŒæ™¯
        education = profile_data.get("education", [])
        if education:
            edu_node = {
                "id": "education",
                "label": f"ğŸ“ æ•™è‚²èƒŒæ™¯ ({len(education)})",
                "type": "category",
                "status": "info",
                "children": []
            }
            for i, edu in enumerate(education[:5]):
                if isinstance(edu, dict):
                    label = f"{edu.get('degree', '')} - {edu.get('school', edu.get('description', '')[:30])}"
                    details = f"{edu.get('period', '')} {edu.get('major', '')}"
                else:
                    label = str(edu)[:50]
                    details = ""
                
                edu_node["children"].append({
                    "id": f"edu_{i}",
                    "label": label,
                    "type": "item",
                    "details": details
                })
            mindmap["children"].append(edu_node)
        
        # 3. èŒä¸šç»å†
        career = profile_data.get("career_timeline", [])
        if career:
            career_node = {
                "id": "career",
                "label": f"ğŸ’¼ èŒä¸šç»å† ({len(career)})",
                "type": "category",
                "status": "info",
                "children": []
            }
            for i, job in enumerate(career[:8]):
                if isinstance(job, dict):
                    label = f"{job.get('role', '')} @ {job.get('company', job.get('description', '')[:30])}"
                    details = job.get('period', '')
                    highlights = job.get('highlights', [])
                else:
                    label = str(job)[:50]
                    details = ""
                    highlights = []
                
                job_node = {
                    "id": f"career_{i}",
                    "label": label,
                    "type": "item",
                    "details": details,
                    "children": []
                }
                
                for j, h in enumerate(highlights[:3]):
                    job_node["children"].append({
                        "id": f"career_{i}_h{j}",
                        "label": h[:50],
                        "type": "highlight"
                    })
                
                career_node["children"].append(job_node)
            mindmap["children"].append(career_node)
        
        # 4. æŠ€æœ¯ä¸“é•¿
        tech = profile_data.get("technical_expertise", [])
        if tech:
            tech_node = {
                "id": "tech",
                "label": f"ğŸ”§ æŠ€æœ¯ä¸“é•¿ ({len(tech)})",
                "type": "category",
                "status": "info",
                "children": []
            }
            for i, t in enumerate(tech[:6]):
                if isinstance(t, dict):
                    label = t.get('domain', str(t)[:30])
                    skills = t.get('skills', [])
                else:
                    label = str(t)[:50]
                    skills = []
                
                t_node = {
                    "id": f"tech_{i}",
                    "label": label,
                    "type": "item",
                    "children": []
                }
                
                for j, skill in enumerate(skills[:5]):
                    t_node["children"].append({
                        "id": f"tech_{i}_s{j}",
                        "label": skill,
                        "type": "skill"
                    })
                
                tech_node["children"].append(t_node)
            mindmap["children"].append(tech_node)
        
        # 5. æˆå°±
        achievements = profile_data.get("achievements", [])
        if achievements:
            ach_node = {
                "id": "achievements",
                "label": f"ğŸ† æˆå°± ({len(achievements)})",
                "type": "category",
                "status": "success",
                "children": []
            }
            for i, ach in enumerate(achievements[:10]):
                if isinstance(ach, dict):
                    label = f"{ach.get('type', '')} - {ach.get('title', ach.get('description', '')[:30])}"
                    details = ach.get('impact', ach.get('description', ''))
                else:
                    label = str(ach)[:50]
                    details = ""
                
                ach_node["children"].append({
                    "id": f"ach_{i}",
                    "label": label,
                    "type": "item",
                    "details": details[:100] if details else ""
                })
            mindmap["children"].append(ach_node)
        
        # 6. äººè„‰å…³ç³»
        connections = profile_data.get("connections", {})
        recommenders = connections.get("recommenders", [])
        if recommenders:
            conn_node = {
                "id": "connections",
                "label": f"ğŸ¤ æ¨èäºº/äººè„‰ ({len(recommenders)})",
                "type": "category",
                "status": "info",
                "children": []
            }
            for i, rec in enumerate(recommenders[:5]):
                if isinstance(rec, dict):
                    label = f"{rec.get('name', 'æ¨èäºº')} - {rec.get('title', '')}"
                    details = f"{rec.get('organization', '')} | {rec.get('relationship', '')}"
                else:
                    label = str(rec)[:50]
                    details = ""
                
                conn_node["children"].append({
                    "id": f"rec_{i}",
                    "label": label,
                    "type": "item",
                    "details": details
                })
            mindmap["children"].append(conn_node)
        
        # 7. åˆ†ææ€»ç»“
        analysis = profile_data.get("raw_analysis", {})
        if analysis:
            analysis_node = {
                "id": "analysis",
                "label": "ğŸ“Š åˆ†ææ€»ç»“",
                "type": "category",
                "status": "warning",
                "children": []
            }
            
            strengths = analysis.get("key_strengths", [])
            if strengths:
                analysis_node["children"].append({
                    "id": "strengths",
                    "label": "æ ¸å¿ƒä¼˜åŠ¿",
                    "type": "item",
                    "children": [{"id": f"s_{i}", "label": s, "type": "point"} for i, s in enumerate(strengths[:5])]
                })
            
            gaps = analysis.get("potential_gaps", [])
            if gaps:
                analysis_node["children"].append({
                    "id": "gaps",
                    "label": "å¾…æ”¹è¿›",
                    "type": "item",
                    "children": [{"id": f"g_{i}", "label": g, "type": "point"} for i, g in enumerate(gaps[:3])]
                })
            
            pathway = analysis.get("gtv_pathway_suggestion", "")
            if pathway:
                analysis_node["children"].append({
                    "id": "pathway",
                    "label": f"å»ºè®®è·¯å¾„: {pathway}",
                    "type": "item"
                })
            
            if analysis_node["children"]:
                mindmap["children"].append(analysis_node)
        
        return mindmap

    def generate_mindmap_data(self, framework: Dict, project_name: str = "", materials: List[Dict] = None) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„æ€ç»´å¯¼å›¾æ•°æ®ç»“æ„"""
        
        def get_status(collected_count: int) -> str:
            if collected_count >= 2:
                return "success"
            elif collected_count > 0:
                return "warning"
            return "error"
        
        mindmap = {
            "id": "root",
            "label": project_name or "GTVç”³è¯·æ¡†æ¶",
            "type": "root",
            "children": []
        }
        
        # 1. é¢†åŸŸå®šä½
        domain_node = {
            "id": "domain",
            "label": "ğŸ¯ é¢†åŸŸå®šä½",
            "type": "category",
            "status": "info",
            "children": []
        }
        domain_data = framework.get("é¢†åŸŸå®šä½", {}).get("children", {})
        domain_items = [
            ("è¯„ä¼°æœºæ„", "Tech Nation"),
            ("ç»†åˆ†é¢†åŸŸ", domain_data.get("ç»†åˆ†é¢†åŸŸ", "å¾…ç¡®å®š")),
            ("å²—ä½å®šä½", domain_data.get("å²—ä½å®šä½", "å¾…ç¡®å®š")),
            ("æ ¸å¿ƒè®ºç‚¹", domain_data.get("æ ¸å¿ƒè®ºç‚¹", "å¾…ç¡®å®š"))
        ]
        for key, value in domain_items:
            domain_node["children"].append({
                "id": f"domain_{key}",
                "label": key,
                "type": "criteria",
                "details": value if value else "å¾…å¡«å†™"
            })
        mindmap["children"].append(domain_node)
        
        # 2. MCå¿…é€‰æ ‡å‡†ï¼ˆé€’äº¤ææ–™æ¡†æ¶ï¼‰
        mc_node = {
            "id": "mc",
            "label": "ğŸ“‹ MCå¿…é€‰æ ‡å‡† (Mandatory Criteria)",
            "type": "category",
            "children": []
        }
        
        mc_definitions = {
            "MC1_äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›": {
                "full_name": "MC1: äº§å“/å›¢é˜Ÿé¢†å¯¼åŠ›",
                "description": "é¢†å¯¼äº§å“å¯¼å‘çš„æ•°å­—ç§‘æŠ€å…¬å¸/äº§å“/å›¢é˜Ÿå¢é•¿çš„è¯æ®",
                "evidence_hints": ["æ¨èä¿¡", "äº§å“æè¿°", "æ–°é—»æŠ¥é“", "ä»£ç è´¡çŒ®"]
            },
            "MC2_å•†ä¸šå‘å±•": {
                "full_name": "MC2: å•†ä¸š/è¥é”€å‘å±•",
                "description": "é¢†å¯¼è¥é”€æˆ–ä¸šåŠ¡å¼€å‘ï¼Œå®ç°æ”¶å…¥/å®¢æˆ·å¢é•¿çš„è¯æ®",
                "evidence_hints": ["é”€å”®åˆåŒ", "å®¢æˆ·åè®®", "æ”¶å…¥å¢é•¿æ•°æ®"]
            },
            "MC3_éè¥åˆ©/ç¤¾ä¼šä¼ä¸š": {
                "full_name": "MC3: éè¥åˆ©ç»„ç»‡é¢†å¯¼",
                "description": "é¢†å¯¼æ•°å­—ç§‘æŠ€é¢†åŸŸéè¥åˆ©ç»„ç»‡æˆ–ç¤¾ä¼šä¼ä¸šçš„è¯æ®",
                "evidence_hints": ["è˜ä¹¦", "æ´»åŠ¨è¯æ˜", "åª’ä½“æŠ¥é“"]
            },
            "MC4_ä¸“å®¶è¯„å®¡è§’è‰²": {
                "full_name": "MC4: ä¸“å®¶è¯„å®¡è§’è‰²",
                "description": "æ‹…ä»»è¯„å®¡åŒè¡Œå·¥ä½œçš„é‡è¦ä¸“å®¶è§’è‰²çš„è¯æ®",
                "evidence_hints": ["è¯„å®¡é‚€è¯·", "è¯„å§”è¯ä¹¦", "ä¸“å®¶è˜ä¹¦"]
            }
        }
        
        mc_data = framework.get("MC_å¿…é€‰æ ‡å‡†", {}).get("children", {})
        for key, definition in mc_definitions.items():
            data = mc_data.get(key, {})
            collected = data.get("collected", [])
            status = get_status(len(collected))
            
            child = {
                "id": f"mc_{key}",
                "label": definition["full_name"],
                "type": "criteria",
                "status": status,
                "details": definition["description"],
                "fileCount": len(collected),
                "children": []
            }
            
            # æ·»åŠ è¯æ®æ–‡ä»¶
            for ev in collected[:8]:
                child["children"].append({
                    "id": f"mc_{key}_{ev.get('file_id', '')}",
                    "label": ev.get("file_name", "æœªçŸ¥æ–‡ä»¶")[:50],
                    "type": "file",
                    "details": f"åˆ†ç±»: {ev.get('category', '')}"
                })
            
            if len(collected) > 8:
                child["children"].append({
                    "id": f"mc_{key}_more",
                    "label": f"+{len(collected) - 8} æ›´å¤šæ–‡ä»¶",
                    "type": "file"
                })
            
            mc_node["children"].append(child)
        
        mindmap["children"].append(mc_node)
        
        # 3. OCå¯é€‰æ ‡å‡†
        oc_node = {
            "id": "oc",
            "label": "ğŸ“Š OCå¯é€‰æ ‡å‡† (Optional Criteria)",
            "type": "category",
            "children": []
        }
        
        oc_definitions = {
            "OC1_åˆ›æ–°": {
                "full_name": "OC1: åˆ›æ–°/äº§å“å¼€å‘",
                "description": "åˆ›æ–°/äº§å“å¼€å‘è¯æ®ï¼Œå¸‚åœºéªŒè¯åŠæ”¶å…¥è¯æ˜",
                "evidence_hints": ["ä¸“åˆ©è¯ä¹¦", "äº§å“æˆªå›¾", "è´¢åŠ¡æŠ¥è¡¨", "é‡‡è´­åˆåŒ"]
            },
            "OC2_è¡Œä¸šè®¤å¯": {
                "full_name": "OC2: è¡Œä¸šä¸“å®¶è®¤å¯",
                "description": "ä½œä¸ºé¢†åŸŸä¸“å®¶è·å¾—çš„è®¤å¯è¯æ®",
                "evidence_hints": ["æ¼”è®²é‚€è¯·", "åª’ä½“é‡‡è®¿", "è¡Œä¸šå¥–é¡¹", "è®ºæ–‡å‘è¡¨"]
            },
            "OC3_é‡å¤§è´¡çŒ®": {
                "full_name": "OC3: é‡å¤§æŠ€æœ¯/å•†ä¸šè´¡çŒ®",
                "description": "å¯¹æ•°å­—æŠ€æœ¯äº§å“çš„é‡å¤§æŠ€æœ¯ã€å•†ä¸šæˆ–åˆ›ä¸šè´¡çŒ®",
                "evidence_hints": ["ä»£ç è´¡çŒ®", "æŠ€æœ¯æ–‡æ¡£", "æŠ•èµ„å†³ç­–", "å•†ä¸šæˆæœ"]
            },
            "OC4_å­¦æœ¯è´¡çŒ®": {
                "full_name": "OC4: å­¦æœ¯è´¡çŒ®",
                "description": "åœ¨æ•°å­—æŠ€æœ¯é¢†åŸŸçš„å­¦æœ¯è´¡çŒ®",
                "evidence_hints": ["è®ºæ–‡", "å¼•ç”¨æ•°æ®", "å­¦æœ¯ä¼šè®®", "ç ”ç©¶é¡¹ç›®"]
            }
        }
        
        oc_data = framework.get("OC_å¯é€‰æ ‡å‡†", {}).get("children", {})
        for key, definition in oc_definitions.items():
            data = oc_data.get(key, {})
            collected = data.get("collected", [])
            status = get_status(len(collected))
            
            child = {
                "id": f"oc_{key}",
                "label": definition["full_name"],
                "type": "criteria",
                "status": status,
                "details": definition["description"],
                "fileCount": len(collected),
                "children": []
            }
            
            for ev in collected[:8]:
                child["children"].append({
                    "id": f"oc_{key}_{ev.get('file_id', '')}",
                    "label": ev.get("file_name", "æœªçŸ¥æ–‡ä»¶")[:50],
                    "type": "file",
                    "details": f"åˆ†ç±»: {ev.get('category', '')}"
                })
            
            if len(collected) > 8:
                child["children"].append({
                    "id": f"oc_{key}_more",
                    "label": f"+{len(collected) - 8} æ›´å¤šæ–‡ä»¶",
                    "type": "file"
                })
            
            oc_node["children"].append(child)
        
        mindmap["children"].append(oc_node)
        
        # 4. æ¨èä¿¡
        ref_node = {
            "id": "reference",
            "label": "âœ‰ï¸ ä¸‰å°æ¨èä¿¡",
            "type": "category",
            "children": []
        }
        ref_data = framework.get("æ¨èä¿¡", {}).get("children", {})
        
        recommenders = [
            ("æ¨èäºº1", "è¡Œä¸šä¸“å®¶æ¨è"),
            ("æ¨èäºº2", "å­¦æœ¯/æŠ€æœ¯æ¨è"),
            ("æ¨èäºº3", "å•†ä¸š/åˆä½œæ¨è")
        ]
        
        for key, hint in recommenders:
            data = ref_data.get(key, {})
            status = "success" if data.get("status") == "å·²æ”¶é›†" else "error"
            files = data.get("files", [])
            
            ref_child = {
                "id": f"ref_{key}",
                "label": key,
                "type": "criteria",
                "status": status,
                "details": f"{hint} - {data.get('name', 'å¾…ç¡®å®š')}",
                "children": []
            }
            
            if files:
                for f in files[:3]:
                    ref_child["children"].append({
                        "id": f"ref_{key}_{f}",
                        "label": f,
                        "type": "file"
                    })
            
            ref_node["children"].append(ref_child)
        
        mindmap["children"].append(ref_node)
        
        return mindmap


# æµ‹è¯•
if __name__ == "__main__":
    analyzer = MaterialAnalyzer()
    result = analyzer.analyze_project_materials("TEST001")
    print(json.dumps(result, ensure_ascii=False, indent=2))
