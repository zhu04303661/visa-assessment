#!/usr/bin/env python3
"""
GTVè¯„åˆ†Agent - ç»Ÿä¸€ç‰ˆæœ¬
ç»“åˆLangGraphçš„ç»“æ„åŒ–æ–¹å¼å’Œè½»é‡çº§å®ç°çš„ç®€æ´æ€§
æ”¯æŒåˆ†é˜¶æ®µLLMè°ƒç”¨ï¼šå®˜æ–¹è¦æ±‚åˆ†æ â†’ åå·®åˆ†æ â†’ ç»“æœæ•´åˆ
"""

import json
import logging
import os
import time
from typing import Any, Dict, List, Optional
from datetime import datetime
from enum import Enum

try:
    from langchain_openai import ChatOpenAI
    HAS_LANGCHAIN = True
except ImportError:
    HAS_LANGCHAIN = False
    logging.warning("âš ï¸ LangChain not properly installed, using mock mode")

# ============================================================================
# æ—¥å¿—é…ç½®
# ============================================================================

logger = logging.getLogger(__name__)

class ScoringAgentLogger:
    """è¯„åˆ†Agentæ—¥å¿—è®°å½•å™¨"""
    
    @staticmethod
    def setup_logger(name: str = __name__, level: str = "INFO") -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(name)
        logger.setLevel(getattr(logging, level.upper(), logging.INFO))
        
        # å¦‚æœå·²ç»æœ‰å¤„ç†å™¨ï¼Œå°±ä¸å†æ·»åŠ 
        if logger.handlers:
            return logger
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(getattr(logging, level.upper(), logging.INFO))
        
        # æ—¥å¿—æ ¼å¼
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        return logger

# åˆå§‹åŒ–æ—¥å¿—
log_level = os.getenv('LOG_LEVEL', 'INFO')
logger = ScoringAgentLogger.setup_logger(__name__, log_level)

# ============================================================================
# æ•°æ®ç»“æ„å®šä¹‰
# ============================================================================

class AnalysisPhase(Enum):
    """åˆ†æé˜¶æ®µ"""
    OFFICIAL_REQUIREMENT = "å®˜æ–¹è¦æ±‚åˆ†æ"
    DEVIATION_ANALYSIS = "åå·®åˆ†æ"
    FINALIZE = "ç»“æœæ•´åˆ"

class OfficialRequirement:
    """å®˜æ–¹è¦æ±‚æ•°æ®"""
    def __init__(self, data: Dict[str, Any]):
        self.level = data.get("level", "æ¨èæ ‡å‡†")
        self.description = data.get("description", "")
        self.examples = data.get("examples", [])
        self.gtv_official_basis = data.get("gtv_official_basis", "")
        self.reasoning = data.get("reasoning", "")
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "level": self.level,
            "description": self.description,
            "examples": self.examples,
            "gtv_official_basis": self.gtv_official_basis,
            "reasoning": self.reasoning,
        }

class DeviationAnalysis:
    """åå·®åˆ†ææ•°æ®"""
    def __init__(self, data: Dict[str, Any]):
        self.gap = data.get("gap", 0)
        self.type = data.get("type", "meet")
        self.distance = data.get("distance", "")
        self.industry_context = data.get("industry_context", "")
        self.gtv_rules_alignment = data.get("gtv_rules_alignment", "")
        self.user_specific_analysis = data.get("user_specific_analysis", "")
        self.improvement_steps = data.get("improvement_steps", [])
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "gap": self.gap,
            "type": self.type,
            "distance": self.distance,
            "industry_context": self.industry_context,
            "gtv_rules_alignment": self.gtv_rules_alignment,
            "user_specific_analysis": self.user_specific_analysis,
            "improvement_steps": self.improvement_steps,
        }

class ScoringResult:
    """è¯„åˆ†ç»“æœ"""
    def __init__(self):
        self.official_requirement: Optional[OfficialRequirement] = None
        self.deviation_analysis: Optional[DeviationAnalysis] = None
        self.analysis_history: List[str] = []
        self.errors: List[str] = []
        self.execution_time: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'official_requirement': self.official_requirement.to_dict() if self.official_requirement else None,
            'deviation_analysis': self.deviation_analysis.to_dict() if self.deviation_analysis else None,
            'analysis_history': self.analysis_history,
            'errors': self.errors if self.errors else None,
            'execution_time_ms': round(self.execution_time * 1000, 2),
        }

# ============================================================================
# LLM æç¤ºè¯æ¨¡æ¿
# ============================================================================

OFFICIAL_REQUIREMENT_PROMPT = """
You are an expert in UK Global Talent Visa (GTV) assessment.

Analyze the OFFICIAL GTV requirements for this scoring item:

Item: {item_name}
Current Value: {item_value}

Provide ONLY valid JSON (no markdown, no explanation) with these exact fields:
- level: string (æœ€ä½è¦æ±‚/æ¨èæ ‡å‡†/ç†æƒ³æ ‡å‡†)
- description: string (GTVå®˜æ–¹è¦æ±‚æè¿°ï¼Œè¯¦ç»†è¯´æ˜)
- examples: array of 3-4 strings (å…·ä½“çœŸå®ä¾‹å­)
- gtv_official_basis: string (GTVå®˜æ–¹ä¾æ®å’Œæ ‡å‡†)
- reasoning: string (ä¸ºä»€ä¹ˆè¿™æ˜¯å®˜æ–¹è¦æ±‚)

JSON Output ONLY:
"""

DEVIATION_ANALYSIS_PROMPT = """
You are an expert in GTV assessment analyzing applicant profiles.

Analyze how the applicant's materials deviate from official requirements:

Item: {item_name}
Applicant Value: {item_value}
Current Score: {score}/{max_score}
Compliance Percentage: {percentage}%

Official Requirement:
- Level: {official_level}
- Description: {official_description}

Applicant Background:
{applicant_background}

Provide ONLY valid JSON (no markdown, no explanation) with these exact fields:
- gap: integer (0-100, where 100 = fully compliant)
- type: string (exceed/meet/gap)
- distance: string (specific gap explanation or distance from requirement)
- industry_context: string (how does applicant's background compare in their industry?)
- gtv_rules_alignment: string (how does it align with GTV assessment criteria?)
- user_specific_analysis: string (analysis specific to this applicant's profile)
- improvement_steps: array of 3-5 strings (concrete, actionable improvement steps)

JSON Output ONLY:
"""

# ============================================================================
# è¯„åˆ†Agentç±» - ç»Ÿä¸€ç‰ˆæœ¬
# ============================================================================

class ScoringAgent:
    """
    GTVè¯„åˆ†Agent - ç»Ÿä¸€ç‰ˆæœ¬
    
    æ”¯æŒåˆ†é˜¶æ®µLLMè°ƒç”¨ï¼š
    1. å®˜æ–¹è¦æ±‚åˆ†æ - è·å–GTVæ ‡å‡†å’Œå®˜æ–¹ä¾æ®
    2. åå·®åˆ†æ - åˆ†æç”³è¯·äººä¸è¦æ±‚çš„å·®è·
    3. ç»“æœæ•´åˆ - åˆå¹¶æ‰€æœ‰åˆ†ææ•°æ®
    """
    
    def __init__(self, openai_api_key: Optional[str] = None):
        """åˆå§‹åŒ–Agent"""
        logger.info("ğŸš€ åˆå§‹åŒ– ScoringAgent (ç»Ÿä¸€ç‰ˆæœ¬)...")
        
        self.api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.llm = None
        
        if HAS_LANGCHAIN and self.api_key:
            try:
                logger.debug(f"ğŸ“¡ æ­£åœ¨è¿æ¥ OpenAI API...")
                self.llm = ChatOpenAI(
                    api_key=self.api_key,
                    model="gpt-4-turbo-preview",
                    temperature=0.7,
                )
                logger.info("âœ… LLM åˆå§‹åŒ–æˆåŠŸ (GPT-4-turbo-preview)")
            except Exception as e:
                logger.error(f"âŒ LLMåˆå§‹åŒ–å¤±è´¥: {e}")
                self.llm = None
        else:
            logger.warning("âš ï¸ LLM ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ Mock æ¨¡å¼ç”Ÿæˆæ•°æ®")
    
    # ========================================================================
    # é˜¶æ®µ1ï¼šå®˜æ–¹è¦æ±‚åˆ†æ
    # ========================================================================
    
    def _phase1_official_requirement(
        self,
        item_name: str,
        item_value: Any,
        applicant_background: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        é˜¶æ®µ1ï¼šåˆ†æå®˜æ–¹è¦æ±‚
        
        ä½¿ç”¨LLMç”Ÿæˆï¼š
        - GTVå®˜æ–¹æ ‡å‡†
        - å®˜æ–¹ä¾æ®
        - å…·ä½“ä¾‹å­
        - æ¨ç†è¿‡ç¨‹
        """
        start_time = time.time()
        logger.info(f"ğŸ“œ [é˜¶æ®µ1] åˆ†æå®˜æ–¹è¦æ±‚: {item_name}")
        logger.debug(f"   é¡¹ç›®å€¼: {item_value}")
        
        # å¦‚æœæ²¡æœ‰LLMï¼Œä½¿ç”¨Mockæ•°æ®
        if not self.llm:
            logger.debug("   ä½¿ç”¨Mockæ•°æ®ç”Ÿæˆ...")
            result = self._mock_official_requirement(item_name, item_value)
            elapsed = time.time() - start_time
            logger.info(f"âœ… å®˜æ–¹è¦æ±‚åˆ†æå®Œæˆ (Mockæ¨¡å¼, {elapsed:.2f}ç§’)")
            return result
        
        try:
            logger.debug("   æ­£åœ¨è°ƒç”¨LLM...")
            prompt = OFFICIAL_REQUIREMENT_PROMPT.format(
                item_name=item_name,
                item_value=item_value,
            )
            
            response = self.llm.invoke(prompt)
            
            try:
                result = json.loads(response.content)
                elapsed = time.time() - start_time
                logger.info(f"âœ… å®˜æ–¹è¦æ±‚åˆ†æå®Œæˆ ({elapsed:.2f}ç§’)")
                logger.debug(f"   ç­‰çº§: {result.get('level')}")
                logger.debug(f"   ä¾æ®: {result.get('gtv_official_basis')}")
                return result
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ LLMå“åº”ä¸æ˜¯æœ‰æ•ˆJSON: {e}")
                logger.debug("   ä½¿ç”¨Mockæ•°æ®ä½œä¸ºå¤‡ä»½...")
                return self._mock_official_requirement(item_name, item_value)
                
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e} (è€—æ—¶: {elapsed:.2f}ç§’)")
            logger.debug("   ä½¿ç”¨Mockæ•°æ®ä½œä¸ºå¤‡ä»½...")
            return self._mock_official_requirement(item_name, item_value)
    
    # ========================================================================
    # é˜¶æ®µ2ï¼šåå·®åˆ†æ
    # ========================================================================
    
    def _phase2_deviation_analysis(
        self,
        item_name: str,
        item_value: Any,
        score: int,
        max_score: int,
        percentage: int,
        official_requirement: Dict[str, Any],
        applicant_background: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        é˜¶æ®µ2ï¼šåˆ†æåå·®ç¨‹åº¦
        
        ä½¿ç”¨LLMç”Ÿæˆï¼š
        - ç¬¦åˆåº¦è¯„åˆ† (0-100)
        - ç¬¦åˆç±»å‹ (exceed/meet/gap)
        - å…·ä½“å·®è·è¯´æ˜
        - è¡Œä¸šèƒŒæ™¯åˆ†æ
        - æ”¹è¿›æ­¥éª¤
        """
        start_time = time.time()
        logger.info(f"âš ï¸ [é˜¶æ®µ2] åˆ†æåå·®ç¨‹åº¦: {item_name}")
        logger.debug(f"   å½“å‰åˆ†æ•°: {score}/{max_score} ({percentage}%)")
        
        # å¦‚æœæ²¡æœ‰LLMï¼Œä½¿ç”¨Mockæ•°æ®
        if not self.llm:
            logger.debug("   ä½¿ç”¨Mockæ•°æ®ç”Ÿæˆ...")
            result = self._mock_deviation_analysis(item_name, percentage)
            elapsed = time.time() - start_time
            logger.info(f"âœ… åå·®åˆ†æå®Œæˆ (Mockæ¨¡å¼, {elapsed:.2f}ç§’)")
            return result
        
        try:
            bg_str = json.dumps(applicant_background, ensure_ascii=False, indent=2)
            
            logger.debug("   æ­£åœ¨è°ƒç”¨LLM...")
            prompt = DEVIATION_ANALYSIS_PROMPT.format(
                item_name=item_name,
                item_value=item_value,
                score=score,
                max_score=max_score,
                percentage=percentage,
                official_level=official_requirement.get('level', ''),
                official_description=official_requirement.get('description', ''),
                applicant_background=bg_str,
            )
            
            response = self.llm.invoke(prompt)
            
            try:
                result = json.loads(response.content)
                elapsed = time.time() - start_time
                logger.info(f"âœ… åå·®åˆ†æå®Œæˆ ({elapsed:.2f}ç§’)")
                logger.debug(f"   ç¬¦åˆåº¦: {result.get('gap')}%")
                logger.debug(f"   ç±»å‹: {result.get('type')}")
                logger.debug(f"   æ”¹è¿›æ­¥éª¤æ•°: {len(result.get('improvement_steps', []))}")
                return result
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ LLMå“åº”ä¸æ˜¯æœ‰æ•ˆJSON: {e}")
                logger.debug("   ä½¿ç”¨Mockæ•°æ®ä½œä¸ºå¤‡ä»½...")
                return self._mock_deviation_analysis(item_name, percentage)
                
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e} (è€—æ—¶: {elapsed:.2f}ç§’)")
            logger.debug("   ä½¿ç”¨Mockæ•°æ®ä½œä¸ºå¤‡ä»½...")
            return self._mock_deviation_analysis(item_name, percentage)
    
    # ========================================================================
    # é˜¶æ®µ3ï¼šç»“æœæ•´åˆ
    # ========================================================================
    
    def _phase3_finalize(
        self,
        item_name: str,
        official_requirement: Optional[OfficialRequirement],
        deviation_analysis: Optional[DeviationAnalysis],
    ) -> None:
        """
        é˜¶æ®µ3ï¼šæ•´åˆæ‰€æœ‰åˆ†æç»“æœ
        
        - éªŒè¯æ•°æ®å®Œæ•´æ€§
        - å‡†å¤‡æœ€ç»ˆè¾“å‡º
        - è®°å½•åˆ†æå†å²
        """
        logger.info(f"ğŸ¯ [é˜¶æ®µ3] æ•´åˆåˆ†æç»“æœ: {item_name}")
        
        # éªŒè¯æ•°æ®
        if official_requirement:
            logger.debug(f"   âœ“ å®˜æ–¹è¦æ±‚å·²ç”Ÿæˆ")
        if deviation_analysis:
            logger.debug(f"   âœ“ åå·®åˆ†æå·²ç”Ÿæˆ")
        
        logger.info(f"âœ… {item_name} åˆ†æå®Œæˆ")
    
    # ========================================================================
    # ä¸»è¦å…¬å…±æ–¹æ³•
    # ========================================================================
    
    def analyze_item(
        self,
        item_name: str,
        item_value: Any,
        score: int,
        max_score: int,
        percentage: int,
        applicant_background: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªè¯„åˆ†é¡¹ - æ‰§è¡Œå®Œæ•´çš„ä¸‰é˜¶æ®µåˆ†æ
        
        Args:
            item_name: é¡¹ç›®åç§°
            item_value: é¡¹ç›®å€¼
            score: å½“å‰åˆ†æ•°
            max_score: æœ€é«˜åˆ†
            percentage: ç¬¦åˆåº¦ç™¾åˆ†æ¯”
            applicant_background: ç”³è¯·äººèƒŒæ™¯ä¿¡æ¯
        
        Returns:
            åŒ…å«å®˜æ–¹è¦æ±‚å’Œåå·®åˆ†æçš„ç»“æœå­—å…¸
        """
        overall_start = time.time()
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ¯ å¼€å§‹åˆ†æè¯„åˆ†é¡¹: {item_name}")
        logger.info(f"{'='*80}")
        logger.debug(f"ç”³è¯·äºº: {applicant_background.get('name', 'æœªçŸ¥')}")
        
        result = ScoringResult()
        
        try:
            # é˜¶æ®µ1: å®˜æ–¹è¦æ±‚åˆ†æ
            logger.info("")
            phase1_start = time.time()
            official_req_data = self._phase1_official_requirement(
                item_name, item_value, applicant_background
            )
            result.official_requirement = OfficialRequirement(official_req_data)
            phase1_time = time.time() - phase1_start
            result.analysis_history.append(
                f"âœ“ å®Œæˆå®˜æ–¹è¦æ±‚åˆ†æ: {item_name} ({phase1_time:.2f}ç§’)"
            )
            
            # é˜¶æ®µ2: åå·®åˆ†æ
            logger.info("")
            phase2_start = time.time()
            deviation_data = self._phase2_deviation_analysis(
                item_name, item_value, score, max_score, percentage,
                official_req_data, applicant_background
            )
            result.deviation_analysis = DeviationAnalysis(deviation_data)
            phase2_time = time.time() - phase2_start
            result.analysis_history.append(
                f"âœ“ å®Œæˆåå·®åˆ†æ: {item_name} (ç¬¦åˆåº¦: {deviation_data.get('gap', 0)}%) ({phase2_time:.2f}ç§’)"
            )
            
            # é˜¶æ®µ3: ç»“æœæ•´åˆ
            logger.info("")
            self._phase3_finalize(item_name, result.official_requirement, result.deviation_analysis)
            result.analysis_history.append(f"âœ“ å®Œæˆ{item_name}çš„å®Œæ•´åˆ†æ")
            
            overall_time = time.time() - overall_start
            result.execution_time = overall_time
            
            logger.info(f"âœ… {item_name} åˆ†æå®Œæˆ")
            logger.info(f"   æ€»è€—æ—¶: {overall_time:.2f}ç§’ (P1: {phase1_time:.2f}s, P2: {phase2_time:.2f}s)")
            logger.debug(f"   åˆ†ææ­¥éª¤: {len(result.analysis_history)} æ­¥")
            logger.info(f"{'='*80}\n")
            
        except Exception as e:
            overall_time = time.time() - overall_start
            logger.error(f"âŒ åˆ†æå¤±è´¥: {e} (è€—æ—¶: {overall_time:.2f}ç§’)")
            result.errors.append(str(e))
            result.execution_time = overall_time
        
        return result.to_dict()
    
    def analyze_dimension(
        self,
        dimension_name: str,
        items: List[Dict[str, Any]],
        applicant_background: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        åˆ†ææ•´ä¸ªç»´åº¦çš„æ‰€æœ‰é¡¹ç›®
        
        Args:
            dimension_name: ç»´åº¦åç§°
            items: è¦è¯„åˆ†çš„é¡¹ç›®åˆ—è¡¨
            applicant_background: ç”³è¯·äººèƒŒæ™¯ä¿¡æ¯
        
        Returns:
            åŒ…å«æ‰€æœ‰é¡¹ç›®åˆ†æç»“æœçš„ç»´åº¦å­—å…¸
        """
        logger.info(f"\n{'#'*80}")
        logger.info(f"ğŸ“Š å¼€å§‹åˆ†æç»´åº¦: {dimension_name}")
        logger.info(f"{'#'*80}")
        logger.info(f"   åŒ…å« {len(items)} ä¸ªé¡¹ç›®")
        logger.debug(f"   ç”³è¯·äºº: {applicant_background.get('name', 'æœªçŸ¥')}")
        
        dimension_start = time.time()
        results = []
        
        for i, item in enumerate(items, 1):
            logger.info(f"\n   [{i}/{len(items)}] åˆ†æ: {item['name']}")
            
            result = self.analyze_item(
                item_name=item['name'],
                item_value=item['value'],
                score=item['score'],
                max_score=item['maxScore'],
                percentage=item['percentage'],
                applicant_background=applicant_background,
            )
            results.append(result)
            
            # æ˜¾ç¤ºè¿›åº¦
            if result.get('deviation_analysis'):
                gap = result['deviation_analysis']['gap']
                logger.info(f"       âœ“ ç¬¦åˆåº¦: {gap}%")
        
        dimension_time = time.time() - dimension_start
        logger.info(f"\nâœ… ç»´åº¦åˆ†æå®Œæˆ: {dimension_name}")
        logger.info(f"   æ€»è€—æ—¶: {dimension_time:.2f}ç§’ ({len(items)}é¡¹)")
        logger.info(f"{'#'*80}\n")
        
        return {
            'dimension': dimension_name,
            'items': results,
            'analyzed_at': datetime.now().isoformat(),
            'execution_time_ms': round(dimension_time * 1000, 2),
        }
    
    # ========================================================================
    # Mock æ•°æ®ç”Ÿæˆï¼ˆæ— ç½‘ç»œæ—¶ä½¿ç”¨ï¼‰
    # ========================================================================
    
    @staticmethod
    def _mock_official_requirement(item_name: str, item_value: Any) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„å®˜æ–¹è¦æ±‚"""
        logger.debug(f"   ç”ŸæˆMockå®˜æ–¹è¦æ±‚æ•°æ®...")
        return {
            "level": "æ¨èæ ‡å‡†",
            "description": f"GTVå®˜æ–¹æ¨è{item_name}åº”è¾¾åˆ°{item_value}æˆ–æ›´é«˜æ ‡å‡†",
            "examples": [
                f"ç¤ºä¾‹1: {item_value}",
                "ç¤ºä¾‹2: æ›´é«˜æ°´å¹³",
                "ç¤ºä¾‹3: å›½é™…è®¤å¯",
                "ç¤ºä¾‹4: è¡Œä¸šé¢†å…ˆ"
            ],
            "gtv_official_basis": "UK Global Talent Visa Assessment Guidelines",
            "reasoning": f"åŸºäºGTVå®˜æ–¹æ ‡å‡†ï¼Œ{item_name}æ˜¯è¯„ä¼°ç”³è¯·äººèƒ½åŠ›çš„é‡è¦æŒ‡æ ‡ã€‚"
        }
    
    @staticmethod
    def _mock_deviation_analysis(item_name: str, percentage: int) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„åå·®åˆ†æ"""
        logger.debug(f"   ç”ŸæˆMockåå·®åˆ†ææ•°æ®...")
        if percentage >= 90:
            type_val = "exceed"
            distance = "å®Œå…¨ç¬¦åˆæˆ–è¶…å‡ºå®˜æ–¹è¦æ±‚æ ‡å‡†"
        elif percentage >= 70:
            type_val = "meet"
            distance = "ç¬¦åˆå®˜æ–¹è¦æ±‚æ ‡å‡†"
        else:
            type_val = "gap"
            distance = "ä½äºå®˜æ–¹è¦æ±‚æ ‡å‡†ï¼Œéœ€è¦æ”¹è¿›"
        
        return {
            "gap": percentage,
            "type": type_val,
            "distance": distance,
            "industry_context": "åœ¨ç›¸å…³è¡Œä¸šä¸­ï¼Œç”³è¯·äººçš„èƒŒæ™¯ä»£è¡¨è¯¥é¢†åŸŸçš„æ°´å¹³ã€‚",
            "gtv_rules_alignment": "ç”³è¯·äººçš„ææ–™ç¬¦åˆGTVè¯„ä¼°çš„ç›¸å…³æ ‡å‡†ã€‚",
            "user_specific_analysis": "åŸºäºç”³è¯·äººçš„ä¸ªäººèƒŒæ™¯å’Œç»å†çš„ç‰¹å®šåˆ†æã€‚",
            "improvement_steps": [
                "ç¬¬ä¸€æ­¥ï¼šç»§ç»­å‘å±•ç›¸å…³é¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†",
                "ç¬¬äºŒæ­¥ï¼šè·å¾—è¡Œä¸šè®¤å¯å’Œè¯ä¹¦",
                "ç¬¬ä¸‰æ­¥ï¼šå»ºç«‹è¯¥é¢†åŸŸçš„é¢†å¯¼åœ°ä½"
            ]
        }


# ============================================================================
# æµ‹è¯•å‡½æ•°
# ============================================================================

def test_scoring_agent():
    """æµ‹è¯•ScoringAgent"""
    logger.info("\n" + "â–ˆ"*80)
    logger.info("â–ˆ  GTVè¯„åˆ†Agent - ç»Ÿä¸€ç‰ˆæœ¬åŠŸèƒ½æµ‹è¯•")
    logger.info("â–ˆ"*80)
    
    # åˆå§‹åŒ–Agent
    agent = ScoringAgent()
    
    # ç¤ºä¾‹ç”³è¯·äººèƒŒæ™¯
    applicant_bg = {
        "name": "å¼ ä¸‰",
        "education": {
            "university": "æ¸…åå¤§å­¦",
            "degree": "ç¡•å£«",
            "major": "è®¡ç®—æœºç§‘å­¦",
            "gpa": 3.8,
        },
        "work_experience": {
            "company": "é˜¿é‡Œå·´å·´",
            "position": "é«˜çº§å·¥ç¨‹å¸ˆ",
            "years": 8,
        },
        "certifications": ["ACEè®¤è¯", "Kubernetesè®¤è¯"],
        "awards": ["å¹´åº¦æœ€ä½³å·¥ç¨‹å¸ˆ"],
    }
    
    # ç¤ºä¾‹é¡¹ç›®
    items = [
        {
            "name": "æœ€é«˜å­¦å†",
            "value": "è®¡ç®—æœºç§‘å­¦ç¡•å£«",
            "score": 5,
            "maxScore": 5,
            "percentage": 100,
        },
        {
            "name": "å·¥ä½œå¹´é™",
            "value": "8å¹´",
            "score": 5,
            "maxScore": 5,
            "percentage": 100,
        },
    ]
    
    # åˆ†æç»´åº¦
    result = agent.analyze_dimension(
        dimension_name="æ•™è‚²èƒŒæ™¯å’Œå·¥ä½œç»éªŒ",
        items=items,
        applicant_background=applicant_bg,
    )
    
    # è¾“å‡ºç»“æœ
    logger.info("\n" + "â–ˆ"*80)
    logger.info("â–ˆ  åˆ†æç»“æœ")
    logger.info("â–ˆ"*80)
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    return result


if __name__ == "__main__":
    test_scoring_agent()
