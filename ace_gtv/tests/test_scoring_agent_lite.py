#!/usr/bin/env python3
"""
GTVè¯„åˆ†Agentè½»é‡çº§ç‰ˆæœ¬ - åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ScoringAgentçš„æ ¸å¿ƒåŠŸèƒ½
"""

import json
import logging
import sys
from scoring_agent_lite import ScoringAgent

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def print_section(title):
    """æ‰“å°åˆ†éš”ç¬¦"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80)


def test_agent_initialization():
    """æµ‹è¯•Agentåˆå§‹åŒ–"""
    print_section("æµ‹è¯•1: Agentåˆå§‹åŒ–")
    
    try:
        agent = ScoringAgent()
        print(f"âœ… Agentåˆå§‹åŒ–æˆåŠŸ")
        print(f"   LLMå¯ç”¨: {agent.llm is not None}")
        if not agent.llm:
            print(f"   â„¹ï¸  å°†ä½¿ç”¨Mockæ¨¡å¼ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰")
        return agent
    except Exception as e:
        print(f"âŒ Agentåˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)


def test_single_item_analysis(agent):
    """æµ‹è¯•å•ä¸ªé¡¹ç›®åˆ†æ"""
    print_section("æµ‹è¯•2: å•ä¸ªè¯„åˆ†é¡¹åˆ†æ")
    
    applicant_bg = {
        "name": "å¼ ä¸‰",
        "education": {
            "university": "æ¸…åå¤§å­¦",
            "degree": "ç¡•å£«",
            "major": "è®¡ç®—æœºç§‘å­¦",
        },
        "work_experience": {
            "company": "é˜¿é‡Œå·´å·´",
            "position": "é«˜çº§å·¥ç¨‹å¸ˆ",
            "years": 8,
        },
    }
    
    try:
        print("\nğŸ“ åˆ†æé¡¹ç›®: å¤§å­¦ç­‰çº§")
        result = agent.analyze_item(
            item_name="å¤§å­¦ç­‰çº§",
            item_value="top_country",
            score=5,
            max_score=5,
            percentage=100,
            applicant_background=applicant_bg,
        )
        
        print(f"\nâœ… åˆ†æå®Œæˆ")
        print(f"\n   å®˜æ–¹è¦æ±‚åˆ†æ:")
        if result.get('official_requirement'):
            req = result['official_requirement']
            print(f"   - ç­‰çº§: {req.get('level')}")
            print(f"   - æè¿°: {req.get('description')[:60]}...")
            print(f"   - å®˜æ–¹ä¾æ®: {req.get('gtv_official_basis')}")
        
        print(f"\n   åå·®åˆ†æ:")
        if result.get('deviation_analysis'):
            dev = result['deviation_analysis']
            print(f"   - ç¬¦åˆåº¦: {dev.get('gap')}%")
            print(f"   - ç±»å‹: {dev.get('type')}")
            print(f"   - è·ç¦»è¯´æ˜: {dev.get('distance')}")
        
        print(f"\n   åˆ†æå†å²: {len(result.get('analysis_history', []))} æ­¥")
        for step in result.get('analysis_history', []):
            print(f"   - {step}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_dimension_analysis(agent):
    """æµ‹è¯•ç»´åº¦åˆ†æ"""
    print_section("æµ‹è¯•3: ç»´åº¦åˆ†æ")
    
    applicant_bg = {
        "name": "ç‹å››",
        "education": {
            "university": "æ¸…åå¤§å­¦",
            "degree": "ç¡•å£«",
        },
        "work_experience": {
            "company": "è…¾è®¯",
            "years": 6,
        },
    }
    
    items = [
        {
            "name": "å¤§å­¦ç­‰çº§",
            "value": "top_country",
            "score": 5,
            "maxScore": 5,
            "percentage": 100,
        },
        {
            "name": "å­¦ä½ç­‰çº§",
            "value": "master",
            "score": 4,
            "maxScore": 5,
            "percentage": 80,
        },
        {
            "name": "ä¸“ä¸šç›¸å…³æ€§",
            "value": "highly_relevant",
            "score": 5,
            "maxScore": 5,
            "percentage": 100,
        },
    ]
    
    try:
        print("\nğŸ“ åˆ†æç»´åº¦: æ•™è‚²èƒŒæ™¯")
        print(f"   åŒ…å« {len(items)} ä¸ªé¡¹ç›®")
        
        result = agent.analyze_dimension(
            dimension_name="æ•™è‚²èƒŒæ™¯",
            items=items,
            applicant_background=applicant_bg,
        )
        
        print(f"\nâœ… ç»´åº¦åˆ†æå®Œæˆ")
        print(f"\n   ç»´åº¦: {result.get('dimension')}")
        print(f"   é¡¹ç›®æ•°: {len(result.get('items', []))}")
        print(f"   åˆ†ææ—¶é—´: {result.get('analyzed_at')}")
        
        for i, item_result in enumerate(result.get('items', []), 1):
            print(f"\n   é¡¹ç›® {i}:")
            if item_result.get('official_requirement'):
                print(f"   - å®˜æ–¹è¦æ±‚åˆ†æ: âœ“ å®Œæˆ")
            if item_result.get('deviation_analysis'):
                print(f"   - åå·®åˆ†æ: âœ“ å®Œæˆ (ç¬¦åˆåº¦: {item_result['deviation_analysis'].get('gap')}%)")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç»´åº¦åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_mock_mode(agent):
    """æµ‹è¯•Mockæ¨¡å¼"""
    print_section("æµ‹è¯•4: Mockæ¨¡å¼")
    
    try:
        print("\nğŸ“ æµ‹è¯•Mockæ•°æ®ç”Ÿæˆ")
        
        mock_req = agent._mock_official_requirement("å·¥ä½œå¹´é™", 8)
        print(f"\nâœ… Mockå®˜æ–¹è¦æ±‚ç”ŸæˆæˆåŠŸ")
        print(f"   - ç­‰çº§: {mock_req.get('level')}")
        print(f"   - ç¤ºä¾‹æ•°: {len(mock_req.get('examples', []))}")
        
        mock_dev = agent._mock_deviation_analysis("å·¥ä½œå¹´é™", 100)
        print(f"\nâœ… Mockåå·®åˆ†æç”ŸæˆæˆåŠŸ")
        print(f"   - ç¬¦åˆåº¦: {mock_dev.get('gap')}%")
        print(f"   - ç±»å‹: {mock_dev.get('type')}")
        print(f"   - æ”¹è¿›æ­¥éª¤æ•°: {len(mock_dev.get('improvement_steps', []))}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Mockæ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_data_structure():
    """æµ‹è¯•æ•°æ®ç»“æ„"""
    print_section("æµ‹è¯•5: æ•°æ®ç»“æ„éªŒè¯")
    
    try:
        from scoring_agent_lite import ScoringResult
        
        print("\nğŸ“ æµ‹è¯•ScoringResultæ•°æ®ç»“æ„")
        result = ScoringResult()
        result.official_requirement = {"level": "test"}
        result.deviation_analysis = {"gap": 90}
        result.analysis_history.append("Step 1")
        
        result_dict = result.to_dict()
        
        print(f"âœ… æ•°æ®ç»“æ„éªŒè¯æˆåŠŸ")
        print(f"   - official_requirement: {result_dict['official_requirement'] is not None}")
        print(f"   - deviation_analysis: {result_dict['deviation_analysis'] is not None}")
        print(f"   - analysis_history: {len(result_dict['analysis_history'])} æ¡")
        print(f"   - errors: {result_dict['errors'] is None}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®ç»“æ„éªŒè¯å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "â–ˆ"*80)
    print("â–ˆ  GTVè¯„åˆ†Agentè½»é‡çº§ç‰ˆæœ¬ - åŠŸèƒ½æµ‹è¯•")
    print("â–ˆ"*80)
    
    results = {}
    
    # æµ‹è¯•1: åˆå§‹åŒ–
    agent = test_agent_initialization()
    results['åˆå§‹åŒ–'] = agent is not None
    
    # æµ‹è¯•2: å•ä¸ªé¡¹ç›®åˆ†æ
    results['å•ä¸ªé¡¹ç›®åˆ†æ'] = test_single_item_analysis(agent)
    
    # æµ‹è¯•3: ç»´åº¦åˆ†æ
    results['ç»´åº¦åˆ†æ'] = test_dimension_analysis(agent)
    
    # æµ‹è¯•4: Mockæ¨¡å¼
    results['Mockæ¨¡å¼'] = test_mock_mode(agent)
    
    # æµ‹è¯•5: æ•°æ®ç»“æ„
    results['æ•°æ®ç»“æ„'] = test_data_structure()
    
    # æ€»ç»“
    print_section("æµ‹è¯•æ€»ç»“")
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for test_name, passed_flag in results.items():
        status = "âœ… é€šè¿‡" if passed_flag else "âŒ å¤±è´¥"
        print(f"{status} - {test_name}")
    
    print(f"\næ€»ä½“: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå·²å°±ç»ªã€‚")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())
