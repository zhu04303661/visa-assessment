#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å†å¤„ç†å™¨ç‹¬ç«‹æµ‹è¯•è„šæœ¬
å¯ä»¥å•ç‹¬è¿è¡Œï¼Œæµ‹è¯•ç®€å†å¤„ç†å™¨çš„å„ä¸ªåŠŸèƒ½æ¨¡å—
"""

import os
import sys
import json
import logging
import tempfile
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime
from dotenv import load_dotenv

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# åŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„.env.localé…ç½®æ–‡ä»¶
project_root = current_dir.parent
env_local_path = project_root / ".env.local"
if env_local_path.exists():
    load_dotenv(env_local_path)
    print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {env_local_path}")
    
    # å…¼å®¹æ€§å¤„ç†ï¼šæ”¯æŒAI_PROVIDERå’ŒLLM_PROVIDERä¸¤ç§é…ç½®æ–¹å¼
    ai_provider = os.getenv("AI_PROVIDER", "").lower()
    llm_provider = os.getenv("LLM_PROVIDER", "").upper()
    
    if ai_provider and not llm_provider:
        # å°†AI_PROVIDERæ˜ å°„åˆ°LLM_PROVIDER
        if ai_provider == "openai":
            os.environ["LLM_PROVIDER"] = "OPENAI"
        elif ai_provider == "azure":
            os.environ["LLM_PROVIDER"] = "AZURE"
        elif ai_provider == "anthropic":
            os.environ["LLM_PROVIDER"] = "ANTHROPIC"
        print(f"ğŸ”„ è‡ªåŠ¨æ˜ å°„AI_PROVIDER={ai_provider} -> LLM_PROVIDER={os.environ['LLM_PROVIDER']}")
    
    # å…¼å®¹æ€§å¤„ç†ï¼šæ”¯æŒAZURE_API_KEYå’ŒAZURE_OPENAI_API_KEY
    azure_api_key = os.getenv("AZURE_API_KEY")
    azure_openai_api_key = os.getenv("AZURE_OPENAI_API_KEY")
    if azure_api_key and not azure_openai_api_key:
        os.environ["AZURE_OPENAI_API_KEY"] = azure_api_key
        print("ğŸ”„ è‡ªåŠ¨æ˜ å°„AZURE_API_KEY -> AZURE_OPENAI_API_KEY")
    
    # å…¼å®¹æ€§å¤„ç†ï¼šæ”¯æŒAZURE_OPENAI_DEPLOYMENT_NAMEå’ŒAZURE_OPENAI_DEPLOYMENT
    azure_deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
    azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
    if azure_deployment_name and not azure_deployment:
        os.environ["AZURE_OPENAI_DEPLOYMENT"] = azure_deployment_name
        print(f"ğŸ”„ è‡ªåŠ¨æ˜ å°„AZURE_OPENAI_DEPLOYMENT_NAME -> AZURE_OPENAI_DEPLOYMENT")
        
else:
    print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {env_local_path}")
    print("ğŸ’¡ æç¤º: è¯·ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•å­˜åœ¨ .env.local æ–‡ä»¶")

# å¯¼å…¥ç®€å†å¤„ç†å™¨æ¨¡å—
try:
    from resume_processor import (
        extract_text_from_file,
        call_ai_for_extraction,
        _extract_with_local_rules,
        create_personal_knowledge_base,
        update_main_knowledge_base,
        _get_llm_client,
        safe_preview
    )
    print("âœ… ç®€å†å¤„ç†å™¨æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ ç®€å†å¤„ç†å™¨æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# é…ç½®æµ‹è¯•æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(filename)s:%(lineno)d %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('test_resume_processor.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class ResumeProcessorTester:
    """ç®€å†å¤„ç†å™¨æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.test_data_dir = Path("test_data")
        self.test_data_dir.mkdir(exist_ok=True)
        self.test_results = []
    
    def _read_file_content(self, file_path: str) -> str:
        """å®‰å…¨è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼"""
        try:
            if file_path.endswith(('.docx', '.pdf')):
                # å¯¹äºäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œä½¿ç”¨extract_text_from_file
                return extract_text_from_file(file_path)
            else:
                # å¯¹äºæ–‡æœ¬æ–‡ä»¶ï¼Œå°è¯•å¤šç§ç¼–ç 
                encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']
                for encoding in encodings:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            return f.read()
                    except UnicodeDecodeError:
                        continue
                # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨é”™è¯¯å¿½ç•¥æ¨¡å¼
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return ""
        
    def create_test_files(self):
        """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
        logger.info("ğŸ“ å‡†å¤‡æµ‹è¯•æ–‡ä»¶...")
        
        # ä½¿ç”¨çœŸå®çš„ç®€å†æ–‡ä»¶
        real_resume_file = Path("resumes/20251020_132537_ZHU_Enqings_resume_-202506.docx")
        if real_resume_file.exists():
            logger.info(f"âœ… æ‰¾åˆ°çœŸå®ç®€å†æ–‡ä»¶: {real_resume_file}")
            test_files = {
                "real": str(real_resume_file),
                "detailed": str(real_resume_file),  # ä½¿ç”¨çœŸå®æ–‡ä»¶ä½œä¸ºè¯¦ç»†æµ‹è¯•
                "simple": str(real_resume_file)     # ä½¿ç”¨çœŸå®æ–‡ä»¶ä½œä¸ºç®€å•æµ‹è¯•
            }
        else:
            logger.warning(f"âš ï¸  çœŸå®ç®€å†æ–‡ä»¶ä¸å­˜åœ¨: {real_resume_file}")
            logger.info("ğŸ“ åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ–‡ä»¶...")
            
            # åˆ›å»ºæµ‹è¯•ç®€å†æ–‡æœ¬æ–‡ä»¶
            test_resume_content = """å¼ ä¸‰
é«˜çº§AIå·¥ç¨‹å¸ˆ

è”ç³»æ–¹å¼ï¼š
é‚®ç®±ï¼šzhangsan@example.com
ç”µè¯ï¼š+86 138 0000 0000

å·¥ä½œç»éªŒï¼š
2020-2025 é«˜çº§AIå·¥ç¨‹å¸ˆ - è…¾è®¯ç§‘æŠ€
- è´Ÿè´£æœºå™¨å­¦ä¹ å¹³å°æ¶æ„è®¾è®¡
- ä¸»å¯¼äº†åƒä¸‡çº§ç”¨æˆ·æ¨èç³»ç»Ÿé¡¹ç›®
- å›¢é˜Ÿè§„æ¨¡ï¼š15äºº

2018-2020 æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ - å­—èŠ‚è·³åŠ¨
- å¼€å‘äº†æ™ºèƒ½æ¨èç®—æ³•
- ä¼˜åŒ–äº†æ¨¡å‹è®­ç»ƒæ•ˆç‡30%
- å‚ä¸è¿‡å¤šä¸ªAIäº§å“å¼€å‘

æ•™è‚²èƒŒæ™¯ï¼š
2016-2018 æ¸…åå¤§å­¦ è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ ç¡•å£«
2012-2016 åŒ—äº¬å¤§å­¦ è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ å­¦å£«

æŠ€èƒ½ï¼š
- Python, Java, C++
- TensorFlow, PyTorch, Scikit-learn
- æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , è‡ªç„¶è¯­è¨€å¤„ç†
- Docker, Kubernetes, AWS

æˆå°±ï¼š
- å‘è¡¨3ç¯‡SCIè®ºæ–‡
- è·å¾—2é¡¹å‘æ˜ä¸“åˆ©
- ä¸»å¯¼è¿‡åƒä¸‡çº§AIé¡¹ç›®
- è·å¾—å…¬å¸å¹´åº¦æœ€ä½³å‘˜å·¥å¥–

é¡¹ç›®ç»éªŒï¼š
- æ™ºèƒ½æ¨èç³»ç»Ÿï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„ä¸ªæ€§åŒ–æ¨è
- æœºå™¨å­¦ä¹ å¹³å°ï¼šæ”¯æŒå¤šç§Ÿæˆ·çš„MLOpså¹³å°
- è‡ªç„¶è¯­è¨€å¤„ç†ï¼šå¤šè¯­è¨€æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿ

è¯­è¨€èƒ½åŠ›ï¼š
- ä¸­æ–‡ï¼šæ¯è¯­
- è‹±è¯­ï¼šæµåˆ©ï¼ˆCET-6ï¼‰
- æ—¥è¯­ï¼šåŸºç¡€

è®¤è¯ï¼š
- AWSæœºå™¨å­¦ä¹ ä¸“ä¸šè®¤è¯
- Google Cloud AIè®¤è¯
- åä¸ºäº‘AIå·¥ç¨‹å¸ˆè®¤è¯
"""
            
            # ä¿å­˜æµ‹è¯•ç®€å†æ–‡ä»¶
            test_resume_file = self.test_data_dir / "test_resume.txt"
            with open(test_resume_file, 'w', encoding='utf-8') as f:
                f.write(test_resume_content)
            logger.info(f"âœ… åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•ç®€å†æ–‡ä»¶: {test_resume_file}")
            
            # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç®€å†
            simple_resume_content = """æå››
è½¯ä»¶å·¥ç¨‹å¸ˆ
é‚®ç®±ï¼šlisi@test.com
ç”µè¯ï¼š138-0000-0000
æŠ€èƒ½ï¼šPython, Java, React
ç»éªŒï¼š3å¹´è½¯ä»¶å¼€å‘ç»éªŒ
æ•™è‚²ï¼šè®¡ç®—æœºç§‘å­¦å­¦å£«
"""
            
            simple_resume_file = self.test_data_dir / "simple_resume.txt"
            with open(simple_resume_file, 'w', encoding='utf-8') as f:
                f.write(simple_resume_content)
            logger.info(f"âœ… åˆ›å»ºç®€åŒ–æµ‹è¯•ç®€å†æ–‡ä»¶: {simple_resume_file}")
            
            test_files = {
                "detailed": str(test_resume_file),
                "simple": str(simple_resume_file)
            }
        
        return test_files
    
    def test_text_extraction(self, test_files: Dict[str, str]) -> bool:
        """æµ‹è¯•æ–‡æœ¬æå–åŠŸèƒ½"""
        logger.info("ğŸ§ª æµ‹è¯•æ–‡æœ¬æå–åŠŸèƒ½...")
        
        try:
            # æµ‹è¯•è¯¦ç»†ç®€å†
            detailed_content = extract_text_from_file(test_files["detailed"])
            if not detailed_content:
                logger.error("âŒ è¯¦ç»†ç®€å†æ–‡æœ¬æå–å¤±è´¥")
                return False
            logger.info(f"âœ… è¯¦ç»†ç®€å†æ–‡æœ¬æå–æˆåŠŸï¼Œé•¿åº¦: {len(detailed_content)} å­—ç¬¦")
            
            # æµ‹è¯•ç®€åŒ–ç®€å†
            simple_content = extract_text_from_file(test_files["simple"])
            if not simple_content:
                logger.error("âŒ ç®€åŒ–ç®€å†æ–‡æœ¬æå–å¤±è´¥")
                return False
            logger.info(f"âœ… ç®€åŒ–ç®€å†æ–‡æœ¬æå–æˆåŠŸï¼Œé•¿åº¦: {len(simple_content)} å­—ç¬¦")
            
            # éªŒè¯å†…å®¹åŒ…å«å…³é”®ä¿¡æ¯ï¼ˆä½¿ç”¨çœŸå®ç®€å†æ–‡ä»¶æ—¶è°ƒæ•´éªŒè¯é€»è¾‘ï¼‰
            if "æœ±æ©åº†" in detailed_content or "å¼ ä¸‰" in detailed_content:
                logger.info("âœ… è¯¦ç»†ç®€å†å†…å®¹éªŒè¯é€šè¿‡ï¼ˆåŒ…å«å§“åä¿¡æ¯ï¼‰")
            else:
                logger.warning("âš ï¸  è¯¦ç»†ç®€å†å†…å®¹éªŒè¯ï¼šæœªæ‰¾åˆ°é¢„æœŸçš„å§“åä¿¡æ¯")
                
            if "æœ±æ©åº†" in simple_content or "æå››" in simple_content:
                logger.info("âœ… ç®€åŒ–ç®€å†å†…å®¹éªŒè¯é€šè¿‡ï¼ˆåŒ…å«å§“åä¿¡æ¯ï¼‰")
            else:
                logger.warning("âš ï¸  ç®€åŒ–ç®€å†å†…å®¹éªŒè¯ï¼šæœªæ‰¾åˆ°é¢„æœŸçš„å§“åä¿¡æ¯")
                
            logger.info("âœ… æ–‡æœ¬æå–åŠŸèƒ½æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ–‡æœ¬æå–åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_local_rules_extraction(self, test_files: Dict[str, str]) -> bool:
        """æµ‹è¯•æœ¬åœ°è§„åˆ™ä¿¡æ¯æå–"""
        logger.info("ğŸ§ª æµ‹è¯•æœ¬åœ°è§„åˆ™ä¿¡æ¯æå–...")
        
        try:
            # è¯»å–æµ‹è¯•æ–‡ä»¶å†…å®¹
            content = self._read_file_content(test_files["detailed"])
            
            # ä½¿ç”¨æœ¬åœ°è§„åˆ™æå–
            extracted_info = _extract_with_local_rules(content)
            
            if not extracted_info:
                logger.error("âŒ æœ¬åœ°è§„åˆ™æå–è¿”å›ç©ºç»“æœ")
                return False
                
            logger.info(f"âœ… æœ¬åœ°è§„åˆ™æå–æˆåŠŸ: {extracted_info}")
            
            # éªŒè¯æå–çš„ä¿¡æ¯
            required_fields = ["name", "email", "phone", "experience", "education", "skills"]
            for field in required_fields:
                if field not in extracted_info:
                    logger.error(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    return False
                    
            logger.info("âœ… æœ¬åœ°è§„åˆ™ä¿¡æ¯æå–æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°è§„åˆ™ä¿¡æ¯æå–æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_llm_client(self) -> bool:
        """æµ‹è¯•LLMå®¢æˆ·ç«¯é…ç½®"""
        logger.info("ğŸ§ª æµ‹è¯•LLMå®¢æˆ·ç«¯é…ç½®...")
        
        try:
            client = _get_llm_client()
            if client is None:
                logger.warning("âš ï¸  LLMå®¢æˆ·ç«¯æœªé…ç½®ï¼Œè·³è¿‡AIæå–æµ‹è¯•")
                return True  # ä¸ç®—ä½œå¤±è´¥ï¼Œåªæ˜¯è·³è¿‡
                
            logger.info(f"âœ… LLMå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: {type(client).__name__}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ LLMå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_ai_extraction(self, test_files: Dict[str, str]) -> bool:
        """æµ‹è¯•AIä¿¡æ¯æå–"""
        logger.info("ğŸ§ª æµ‹è¯•AIä¿¡æ¯æå–...")
        
        try:
            # è¯»å–æµ‹è¯•æ–‡ä»¶å†…å®¹
            content = self._read_file_content(test_files["detailed"])
            
            # ä½¿ç”¨AIæå–ä¿¡æ¯
            extracted_info = call_ai_for_extraction(content)
            
            if not extracted_info:
                logger.error("âŒ AIä¿¡æ¯æå–è¿”å›ç©ºç»“æœ")
                return False
                
            logger.info(f"âœ… AIä¿¡æ¯æå–æˆåŠŸ: {extracted_info}")
            
            # éªŒè¯æå–çš„ä¿¡æ¯ç»“æ„
            required_fields = ["name", "email", "phone", "experience", "education", "skills"]
            for field in required_fields:
                if field not in extracted_info:
                    logger.error(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    return False
                    
            logger.info("âœ… AIä¿¡æ¯æå–æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ AIä¿¡æ¯æå–æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_knowledge_base_creation(self, test_files: Dict[str, str]) -> bool:
        """æµ‹è¯•çŸ¥è¯†åº“åˆ›å»º"""
        logger.info("ğŸ§ª æµ‹è¯•çŸ¥è¯†åº“åˆ›å»º...")
        
        try:
            # è¯»å–æµ‹è¯•æ–‡ä»¶å†…å®¹
            content = self._read_file_content(test_files["detailed"])
            
            # æå–ä¿¡æ¯
            extracted_info = call_ai_for_extraction(content)
            if not extracted_info:
                logger.error("âŒ æ— æ³•æå–ä¿¡æ¯ç”¨äºçŸ¥è¯†åº“åˆ›å»º")
                return False
            
            # åˆ›å»ºä¸ªäººçŸ¥è¯†åº“
            name = extracted_info.get("name", "æµ‹è¯•ç”¨æˆ·")
            personal_kb_path = create_personal_knowledge_base(name, extracted_info)
            
            if not personal_kb_path:
                logger.error("âŒ ä¸ªäººçŸ¥è¯†åº“åˆ›å»ºå¤±è´¥")
                return False
                
            logger.info(f"âœ… ä¸ªäººçŸ¥è¯†åº“åˆ›å»ºæˆåŠŸ: {personal_kb_path}")
            
            # éªŒè¯çŸ¥è¯†åº“æ–‡ä»¶
            personal_file = Path(personal_kb_path) / "personal_info.json"
            if not personal_file.exists():
                logger.error("âŒ ä¸ªäººçŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨")
                return False
                
            with open(personal_file, 'r', encoding='utf-8') as f:
                personal_info = json.load(f)
                
            if "knowledge_bullets" not in personal_info:
                logger.error("âŒ ä¸ªäººçŸ¥è¯†åº“ç¼ºå°‘knowledge_bulletså­—æ®µ")
                return False
                
            logger.info(f"âœ… ä¸ªäººçŸ¥è¯†åº“åŒ…å« {len(personal_info['knowledge_bullets'])} ä¸ªçŸ¥è¯†æ¡ç›®")
            logger.info("âœ… çŸ¥è¯†åº“åˆ›å»ºæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†åº“åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_main_knowledge_base_update(self, test_files: Dict[str, str]) -> bool:
        """æµ‹è¯•ä¸»çŸ¥è¯†åº“æ›´æ–°"""
        logger.info("ğŸ§ª æµ‹è¯•ä¸»çŸ¥è¯†åº“æ›´æ–°...")
        
        try:
            # è¯»å–æµ‹è¯•æ–‡ä»¶å†…å®¹
            content = self._read_file_content(test_files["detailed"])
            
            # æå–ä¿¡æ¯
            extracted_info = call_ai_for_extraction(content)
            if not extracted_info:
                logger.error("âŒ æ— æ³•æå–ä¿¡æ¯ç”¨äºçŸ¥è¯†åº“æ›´æ–°")
                return False
            
            # åˆ›å»ºä¸ªäººçŸ¥è¯†åº“
            name = extracted_info.get("name", "æµ‹è¯•ç”¨æˆ·")
            personal_kb_path = create_personal_knowledge_base(name, extracted_info)
            
            if not personal_kb_path:
                logger.error("âŒ ä¸ªäººçŸ¥è¯†åº“åˆ›å»ºå¤±è´¥")
                return False
            
            # æ›´æ–°ä¸»çŸ¥è¯†åº“
            update_result = update_main_knowledge_base(personal_kb_path, name)
            
            if not update_result:
                logger.error("âŒ ä¸»çŸ¥è¯†åº“æ›´æ–°å¤±è´¥")
                return False
                
            logger.info("âœ… ä¸»çŸ¥è¯†åº“æ›´æ–°æˆåŠŸ")
            
            # éªŒè¯ä¸»çŸ¥è¯†åº“æ–‡ä»¶
            main_kb_file = Path("data/playbook.json")
            if main_kb_file.exists():
                with open(main_kb_file, 'r', encoding='utf-8') as f:
                    main_kb = json.load(f)
                    
                if "bullets" in main_kb and len(main_kb["bullets"]) > 0:
                    logger.info(f"âœ… ä¸»çŸ¥è¯†åº“åŒ…å« {len(main_kb['bullets'])} ä¸ªæ¡ç›®")
                else:
                    logger.warning("âš ï¸  ä¸»çŸ¥è¯†åº“ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
            
            logger.info("âœ… ä¸»çŸ¥è¯†åº“æ›´æ–°æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¸»çŸ¥è¯†åº“æ›´æ–°æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_safe_preview(self) -> bool:
        """æµ‹è¯•å®‰å…¨é¢„è§ˆåŠŸèƒ½"""
        logger.info("ğŸ§ª æµ‹è¯•å®‰å…¨é¢„è§ˆåŠŸèƒ½...")
        
        try:
            # æµ‹è¯•æ­£å¸¸æ–‡æœ¬
            normal_text = "è¿™æ˜¯ä¸€ä¸ªæ­£å¸¸çš„æ–‡æœ¬"
            preview = safe_preview(normal_text)
            if preview != normal_text:
                logger.error(f"âŒ æ­£å¸¸æ–‡æœ¬é¢„è§ˆå¤±è´¥: æœŸæœ› '{normal_text}', å®é™… '{preview}'")
                return False
                
            # æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡æœ¬
            special_text = "åŒ…å«\x00ç©ºå­—ç¬¦å’Œ\x01æ§åˆ¶å­—ç¬¦çš„æ–‡æœ¬"
            preview = safe_preview(special_text)
            # ç‰¹æ®Šå­—ç¬¦åº”è¯¥è¢«æ›¿æ¢ä¸º'.'
            expected_preview = "åŒ…å«.ç©ºå­—ç¬¦å’Œ.æ§åˆ¶å­—ç¬¦çš„æ–‡æœ¬"
            if preview != expected_preview:
                logger.error(f"âŒ ç‰¹æ®Šå­—ç¬¦å¤„ç†å¤±è´¥: æœŸæœ› '{expected_preview}', å®é™… '{preview}'")
                return False
                
            # æµ‹è¯•è¶…é•¿æ–‡æœ¬
            long_text = "a" * 300
            preview = safe_preview(long_text, max_len=100)
            if len(preview) > 103:  # 100 + "..."
                logger.error(f"âŒ é•¿åº¦é™åˆ¶å¤±è´¥: é•¿åº¦ {len(preview)} > 103")
                return False
                
            # æµ‹è¯•è¶…é•¿æ–‡æœ¬åº”è¯¥ä»¥"..."ç»“å°¾
            if not preview.endswith("..."):
                logger.error(f"âŒ è¶…é•¿æ–‡æœ¬æœªæ­£ç¡®æˆªæ–­: '{preview}'")
                return False
                
            logger.info("âœ… å®‰å…¨é¢„è§ˆåŠŸèƒ½æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å®‰å…¨é¢„è§ˆåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œç®€å†å¤„ç†å™¨æµ‹è¯•å¥—ä»¶...")
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_files = self.create_test_files()
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        tests = [
            ("æ–‡æœ¬æå–åŠŸèƒ½", lambda: self.test_text_extraction(test_files)),
            ("æœ¬åœ°è§„åˆ™ä¿¡æ¯æå–", lambda: self.test_local_rules_extraction(test_files)),
            ("LLMå®¢æˆ·ç«¯é…ç½®", self.test_llm_client),
            ("AIä¿¡æ¯æå–", lambda: self.test_ai_extraction(test_files)),
            ("çŸ¥è¯†åº“åˆ›å»º", lambda: self.test_knowledge_base_creation(test_files)),
            ("ä¸»çŸ¥è¯†åº“æ›´æ–°", lambda: self.test_main_knowledge_base_update(test_files)),
            ("å®‰å…¨é¢„è§ˆåŠŸèƒ½", self.test_safe_preview),
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            logger.info(f"\n{'='*50}")
            logger.info(f"ğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
            logger.info(f"{'='*50}")
            
            try:
                result = test_func()
                if result:
                    logger.info(f"âœ… {test_name} - é€šè¿‡")
                    passed += 1
                else:
                    logger.error(f"âŒ {test_name} - å¤±è´¥")
            except Exception as e:
                logger.error(f"âŒ {test_name} - å¼‚å¸¸: {e}")
        
        # è¾“å‡ºæµ‹è¯•ç»“æœ
        logger.info(f"\n{'='*50}")
        logger.info(f"ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
        logger.info(f"{'='*50}")
        logger.info(f"æ€»æµ‹è¯•æ•°: {total}")
        logger.info(f"é€šè¿‡æ•°: {passed}")
        logger.info(f"å¤±è´¥æ•°: {total - passed}")
        logger.info(f"é€šè¿‡ç‡: {passed/total*100:.1f}%")
        
        if passed == total:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            logger.warning(f"âš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        
        return passed == total
    
    def cleanup_test_data(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®...")
        
        try:
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            if self.test_data_dir.exists():
                import shutil
                shutil.rmtree(self.test_data_dir)
                logger.info("âœ… æµ‹è¯•æ–‡ä»¶æ¸…ç†å®Œæˆ")
            
            # æ¸…ç†ä¸ªäººçŸ¥è¯†åº“
            personal_kb_dir = Path("personal_kb")
            if personal_kb_dir.exists():
                for kb_dir in personal_kb_dir.iterdir():
                    if kb_dir.is_dir() and "æµ‹è¯•" in kb_dir.name:
                        shutil.rmtree(kb_dir)
                        logger.info(f"âœ… æ¸…ç†ä¸ªäººçŸ¥è¯†åº“: {kb_dir}")
            
            # æ¸…ç†ä¸»çŸ¥è¯†åº“ï¼ˆå¯é€‰ï¼‰
            main_kb_file = Path("data/playbook.json")
            if main_kb_file.exists():
                with open(main_kb_file, 'r', encoding='utf-8') as f:
                    main_kb = json.load(f)
                
                # ç§»é™¤æµ‹è¯•ç›¸å…³çš„æ¡ç›®
                if "bullets" in main_kb:
                    test_bullets = [k for k in main_kb["bullets"].keys() if "æµ‹è¯•" in k or "test" in k.lower()]
                    for bullet_id in test_bullets:
                        del main_kb["bullets"][bullet_id]
                        logger.info(f"âœ… æ¸…ç†æµ‹è¯•æ¡ç›®: {bullet_id}")
                
                # ä¿å­˜æ¸…ç†åçš„ä¸»çŸ¥è¯†åº“
                with open(main_kb_file, 'w', encoding='utf-8') as f:
                    json.dump(main_kb, f, ensure_ascii=False, indent=2)
                logger.info("âœ… ä¸»çŸ¥è¯†åº“æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸  æ¸…ç†æµ‹è¯•æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª ç®€å†å¤„ç†å™¨ç‹¬ç«‹æµ‹è¯•è„šæœ¬")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    logger.info("ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    
    # æ£€æŸ¥å¿…è¦çš„ç›®å½•
    required_dirs = ["data", "personal_kb"]
    for dir_name in required_dirs:
        Path(dir_name).mkdir(exist_ok=True)
        logger.info(f"âœ… ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_name}")
    
    # åˆ›å»ºæµ‹è¯•å™¨å®ä¾‹
    tester = ResumeProcessorTester()
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        success = tester.run_all_tests()
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†æµ‹è¯•æ•°æ®
        print("\n" + "=" * 50)
        cleanup = input("æ˜¯å¦æ¸…ç†æµ‹è¯•æ•°æ®ï¼Ÿ(y/N): ").strip().lower()
        if cleanup in ['y', 'yes']:
            tester.cleanup_test_data()
        
        # è¾“å‡ºæœ€ç»ˆç»“æœ
        if success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç®€å†å¤„ç†å™¨åŠŸèƒ½æ­£å¸¸ã€‚")
            sys.exit(0)
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ã€‚")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿è¡Œå¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
